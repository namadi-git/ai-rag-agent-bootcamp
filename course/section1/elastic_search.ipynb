{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d46a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bddc49b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc201df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Install Docker (Docker Desktop on Mac/Windows; Docker Engine on Linux).\n",
    "\n",
    "Run Elasticsearch (this creates a container from the official image):\n",
    "\n",
    "docker run -it --rm --name elasticsearch \\\n",
    "  -m 4GB \\\n",
    "  -p 9200:9200 -p 9300:9300 \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -e \"xpack.security.enabled=false\" \\\n",
    "  -v es9_data:/usr/share/elasticsearch/data \\\n",
    "  docker.elastic.co/elasticsearch/elasticsearch:9.1.1\n",
    "\n",
    "\n",
    "This pulls the image if you don’t have it yet, then starts a container.\n",
    "\n",
    "The named volume es9_data keeps your data between restarts.\n",
    "\n",
    "Security is off here for local testing (don’t do this in prod).\n",
    "\n",
    "Check it’s up:\n",
    "\n",
    "curl http://localhost:9200\n",
    "\n",
    "\n",
    "You should see version info in JSON.\n",
    "\n",
    "Use it from Python (install the client and try a ping):\n",
    "\n",
    "pip install elasticsearch==9.1.1\n",
    "python - <<'PY'\n",
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "print(\"Ping:\", es.ping())\n",
    "PY\n",
    "\n",
    "\n",
    "Stop it (and remove the container):\n",
    "\n",
    "docker stop elasticsearch\n",
    "\n",
    "\n",
    "Your data is still in the es9_data volume. Start again with the same docker run and it reuses the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed6c98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "curl: (7) Failed to connect to localhost port 9200 after 2222 ms: Could not connect to server\n"
     ]
    }
   ],
   "source": [
    "! curl http://localhost:9200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27de7347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "curl: (52) Empty reply from server\n"
     ]
    }
   ],
   "source": [
    "! curl http://localhost:9200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad72a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b3df58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"08e5a81db022\",\n",
      "  \"cluster_name\" : \"docker-cluster\",\n",
      "  \"cluster_uuid\" : \"fwrm0e9mSViPmADLW4Vcqw\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"9.1.1\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"docker\",\n",
      "    \"build_hash\" : \"5e94055934defa56e454868b7783b2a3b683785e\",\n",
      "    \"build_date\" : \"2025-08-05T01:07:31.959947279Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"10.2.2\",\n",
      "    \"minimum_wire_compatibility_version\" : \"8.19.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"8.0.0\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   540  100   540    0     0   2236      0 --:--:-- --:--:-- --:--:--  2231\n"
     ]
    }
   ],
   "source": [
    "! curl http://localhost:9200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0efae317",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # 384-d embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e6a9b",
   "metadata": {},
   "source": [
    "# Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73a0b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "video_id = 'ph1PxZIkz1o'\n",
    "\n",
    "ytt_api = YouTubeTranscriptApi()\n",
    "transcript = ytt_api.fetch(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5cfb4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "youtube_transcript_api._transcripts.FetchedTranscript"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e0b1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1407"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d901770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FetchedTranscriptSnippet(text='So hi everyone. Uh today we are going to', start=0.0, duration=5.04)\n",
      "FetchedTranscriptSnippet(text='talk about our upcoming course. The', start=2.96, duration=3.52)\n",
      "FetchedTranscriptSnippet(text='upcoming course is called machine', start=5.04, duration=5.92)\n",
      "FetchedTranscriptSnippet(text='learning zoom camp. And um this is', start=6.48, duration=5.92)\n",
      "FetchedTranscriptSnippet(text='already I put the link in the', start=10.96, duration=3.599)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(transcript[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c78a012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the transcript into a single string\n",
    "def format_timestamp(seconds: float) -> str:\n",
    "    \"\"\"Convert seconds to H:MM:SS if > 1 hour, else M:SS\"\"\"\n",
    "    total_seconds = int(seconds)\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, secs = divmod(remainder, 60)\n",
    "\n",
    "    if hours > 0:\n",
    "        return f\"{hours}:{minutes:02}:{secs:02}\"\n",
    "    else:\n",
    "        return f\"{minutes}:{secs:02}\"\n",
    "\n",
    "def make_subtitles(transcript) -> str:\n",
    "    lines = []\n",
    "\n",
    "    for entry in transcript:\n",
    "        ts = format_timestamp(entry.start)\n",
    "        text = entry.text.replace('\\n', ' ')\n",
    "        lines.append(ts + ' ' + text)\n",
    "\n",
    "    return '\\n'.join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "282735f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subtitles = make_subtitles(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a28d9202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00 So hi everyone. Uh today we are going to\n",
      "0:02 talk about our upcoming course. The\n",
      "0:05 upcoming course is called machine\n",
      "0:06 learning zoom camp. And um this is\n",
      "0:10 already I put the link in the\n",
      "0:12 description. So if you're watching um\n",
      "0:14 this video in recording or you're\n",
      "0:17 watching it live, you go here in the\n",
      "0:19 description after under this video and\n",
      "0:21 then you see a link course. uh click on\n",
      "0:25 that link and this bring you will bring\n",
      "0:27 you to\n",
      "0:29 this website this GitHub\n"
     ]
    }
   ],
   "source": [
    "print(subtitles[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9120d986",
   "metadata": {},
   "source": [
    "## User def function (sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8972e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(seq, size, step):\n",
    "    \"\"\"Create overlapping chunks using sliding window approach.\"\"\"\n",
    "    if size <= 0 or step <= 0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "\n",
    "    n = len(seq)\n",
    "    result = []\n",
    "    for i in range(0, n, step):\n",
    "        batch = seq[i:i+size]\n",
    "        result.append(batch)\n",
    "        if i + size >= n:\n",
    "            break\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def join_lines(transcript) -> str:\n",
    "    \"\"\"Join transcript entries into continuous text.\"\"\"\n",
    "    lines = []\n",
    "\n",
    "    for entry in transcript:\n",
    "        text = entry.text.replace('\\n', ' ')\n",
    "        lines.append(text)\n",
    "\n",
    "    return ' '.join(lines)\n",
    "\n",
    "def format_chunk(chunk):\n",
    "    \"\"\"Format a chunk with start/end timestamps and text.\"\"\"\n",
    "    time_start = format_timestamp(chunk[0].start)\n",
    "    time_end = format_timestamp(chunk[-1].start)\n",
    "    text = join_lines(chunk)\n",
    "\n",
    "    return {\n",
    "        'start': time_start,\n",
    "        'end': time_end,\n",
    "        'text': text\n",
    "    }\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07fc5cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 46 chunks\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "\n",
    "# Experiment with different values: try (30, 10) for more granular chunks\n",
    "for chunk in sliding_window(transcript, 60, 30):\n",
    "    processed = format_chunk(chunk)\n",
    "    chunks.append(processed)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "474cf673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': '0:00',\n",
       " 'end': '2:38',\n",
       " 'text': \"So hi everyone. Uh today we are going to talk about our upcoming course. The upcoming course is called machine learning zoom camp. And um this is already I put the link in the description. So if you're watching um this video in recording or you're watching it live, you go here in the description after under this video and then you see a link course. uh click on that link and this bring you will bring you to this website this GitHub page. This GitHub page is the main entry point to our course and um yeah I think it's more or less self-explanatory. If you want to sign up this is the button you click and the actual course starts in on September 15th. it means that it's uh slightly less than one one month before the course starts and the purpose of today's um session is to just answer your questions. So you have some questions and uh you can ask these questions using uh you can ask your questions using the pinned link. So there's a pinned link in the live chat. Click on that link um and there ask your questions. So yeah, this is how it looks like and I am just going to uh use this thing. So we can also go to SLO and use ML Zoom camp and I'm going to use that for answering questions. Uh one thing though, so before we start, I just wanted to mention that um this course has been running for uh this will be the fifth edition of this course. So we've been doing this course for quite some time. Many people already graduated from this course and um most of the content we use here is the content I uh recorded like four years ago but we are updating the content so cuz u back then everyone was using Python 3.8 eight or nine something like. So yeah, we are re-recording some of the things in particular. Module one, two, three, four will uh stay the same cuz uh this uh these are the fundamentals. They didn't change. But module five we uh will update. Module 6 will stay the same. Module 8 we will update. Module 9 update update. And this we will not include like we only include it once and this thing get outdated very fast. So we just I just didn't bother updating this at all and it's pretty advanced material. So we will update like four out of 10 modules. So that's the plan. Uh and we already had some workshops for\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9724c7b6",
   "metadata": {},
   "source": [
    "# Lexical search (BM25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb266c8",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cedfafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'docs_lex'})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"docs_lex\"\n",
    "\n",
    "# delete if exists (for repeatable demos)\n",
    "if es_client.indices.exists(index=index_name):\n",
    "    es_client.indices.delete(index=index_name)\n",
    "\n",
    "es_client.indices.create(\n",
    "    index=index_name,\n",
    "    settings={\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"my_english\": {\n",
    "                    \"type\": \"standard\",\n",
    "                    \"stopwords\": \"_english_\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"start\":  {\"type\": \"keyword\"},\n",
    "            \"end\": { \"type\": \"text\"},\n",
    "            \"text\": {\"type\": \"text\",  \"analyzer\": \"my_english\"}\n",
    "        }\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1235e418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecd6048e6e643e396d4b6703991265d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for d in tqdm(chunks):\n",
    "    es_client.index(index=index_name, id= d['start'],document=d, refresh=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6492e2a",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a21b2978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.574486 want to build tools for trading. Um then we also have a AI dev tools zoom camp which is not here yet because this is still work in progress. This is course for engineers who want to use AI to become uh more proficient. Okay, let me share this link too. Okay, I think I was answering this question. Now, are you going to teach something new this time or we just have to watch old videos? Um, I think I explained it. uh yes you'll have to watch old videos but there is also new material so I uh this year I am updating some of the uh things some of the modules so you will have to watch well I don't like to say have to nobody's forcing you but if you wish to learn something you can decide to watch all videos yes but uh trust me these videos are going to be very useful to you um as they have been very useful to many people before you. Uh but also yeah there will be new things too. Uh what do you recommend for taking the course for the official repo and working or uh I would recommend creating a new one and adding I think maybe I do have examples here. Yeah, I would recommend to create a separate repo and then put all your homeworks there. um put your uh for projects I would recommend for each project to create a several ripple I don't have any programming skill would it be a challenge yes it will be a challenge but there are some people who finish the course despite that it just depends on how it just depends on your motivation how much time you have how much extra you're willing to learn cuz you will need to learn a lot so it will not be easy it will be very difficult so it will be a challenge but still you can overcome this challenge. If you're motivated, if you want to get into machine learning and if you want to get into machine learning, you have to learn programming. So, it doesn't matter if you want to become a data scientist or a male engineer, you will have to learn programming. So, there's no way around that. So, better start earlier, sooner than later. So, you can start now. Uh the end of the cohort, what level of machine learning mastery will we have reached? Um depends how you measure it. So what I wanted to cover in this course is the 20% that will give you 80% of the results right but still there is much much much more out there that you need\n",
      "5.3527036 updated. Uh if not can we begin accessing them beforehand? Yes, you can access them beforehand. Um, only two more modules will be updated. Um, so uh this one this this this will stay the same. I'm not going to update them. This one is already updated. I just need to put this in the description. But this one was the UV and fast API module uh workshop. I'll just simply include the link to the workshop here. That will be all the update. So this is going to stay the same. In this we will uh add extra material on PyTorch. So the TensorFlow part will stay the same. So what you can do is now you go go through TensorFlow part but then we will show how to do exactly the same thing with uh PyTorch. So we will not do any theory. We will just do practice with PyTorch because the theoretical part is recorded with TensorFlow and it will stay the same. This one is updated and this one is going to be updated. Uh some of the fundamentals are still valid. It's just we are not going to use TensorFlow serving. Um but yeah, you can watch the course. Uh actually I think TensorFlow serving is still good. So yeah, we'll just need to use uh newer versions. Uh but I also want to record any some extra things here. Uh some extra things here. So you but um to answer your question you can go ahead and watch the videos right now. There will be some updates but by watching the videos um so the updates will be extra materials right so you can already just watch what we have. Would you do a math for AI zoom camp or boot camp? No. Um detailed timeline. I talked about this. We talked about this. Um would you share any assignments or problems after each module? Uh yes, we have homework and we also have um like solutions. We publish the solutions. If I miss cohorts, will I not get the certificate? Do you miss if you do you mean if you miss uh a homework? If you miss a homework, you will still get a certificate. If you miss the entire cohort, you will not get the certificate, of course. uh answered. So the homeworks will be different but you can check the past homeworks. Yeah. Um any resource tutorials to sharpen my Python skills? Chad GPT is really good.\n",
      "5.1830983 zoom camp, machine learning zoom camp, llm zoom camp. So ML uh ML zoom camp this course is for ML engineers and data scientists. Um MLOps uh zoom camp is for ML engineers again slightly more advanced course than this one. Um so there is also a role called MLOps engineer but it may mean very different things for different companies. So um yeah we teach some uh automation some things like that like make files and so on. Um but yeah so in some cases MLOps engineer is somebody who builds platform for ML engineers then this is not about building platform but it will it talks about different steps and procedures of the ML process. Uh data engineer zoom camp is of course for data engineers uh also for data scientists who want to become better at building pipelines and then LM zoom camp is for AI engineers and data scientists. Then we also have analytics and stock market zoom camp. This is not a course I teach. So this is uh this is done by Ivan who's u like who's leading the course. Um so for him uh the for his course the target audience like it's for people who want to build um who want to trade and who want to build tools for trading. Um then we also have a AI dev tools zoom camp which is not here yet because this is still work in progress. This is course for engineers who want to use AI to become uh more proficient. Okay, let me share this link too. Okay, I think I was answering this question. Now, are you going to teach something new this time or we just have to watch old videos? Um, I think I explained it. uh yes you'll have to watch old videos but there is also new material so I uh this year I am updating some of the uh things some of the modules so you will have to watch well I don't like to say have to nobody's forcing you but if you wish to learn something you can decide to watch all videos yes but uh trust me these videos are going to be very useful to you um as they have been very useful to many people before you. Uh but also yeah there will be new things too. Uh what do you recommend for taking the course for the official repo and working or uh I would recommend creating a new one and adding I think maybe I do have examples here. Yeah, I would recommend to create a separate repo and then put\n",
      "4.8634415 places where you can volunteer. So put your skills into practice and then by doing this you will again do this project based learning that I um talked about and then it will force you to learn new things in order to solve a problem you have and then you build a portfolio of things and then it will make you even more job ready. Um yeah so I wouldn't recommend taking another course of course you can do a melops course that we have you can find a lot of courses like we have this page yeah wait no not this one 23 free online courses on machine learning so there are a lot of courses not just our course there are so many other courses but um I wouldn't recommend to spend too much time on learning things I would just say I mean on learning through courses. Courses are useful and important and for me personally courses were super helpful in my career but just don't do don't do just courses right so I would suggest to start involve being involved in different projects as soon as possible. Um you said the course videos are pre-recorded so the ones already available on the platform they will be updated. Uh if not can we begin accessing them beforehand? Yes, you can access them beforehand. Um, only two more modules will be updated. Um, so uh this one this this this will stay the same. I'm not going to update them. This one is already updated. I just need to put this in the description. But this one was the UV and fast API module uh workshop. I'll just simply include the link to the workshop here. That will be all the update. So this is going to stay the same. In this we will uh add extra material on PyTorch. So the TensorFlow part will stay the same. So what you can do is now you go go through TensorFlow part but then we will show how to do exactly the same thing with uh PyTorch. So we will not do any theory. We will just do practice with PyTorch because the theoretical part is recorded with TensorFlow and it will stay the same. This one is updated and this one is going to be updated. Uh some of the fundamentals are still valid. It's just we are not going to use TensorFlow serving. Um but yeah, you can watch the course. Uh actually I think TensorFlow serving is still good. So\n",
      "4.364994 sense to actually keep it open right because you can see the solutions and simply copy it. So yeah, so there are deadlines to keep you to help you um um with um sticking to the schedule. Then we also have a leaderboard where I think Alexander this is the person who wrote uh this article, right? It's actually he wrote too. Cool. Um so uh yeah we have this uh leaderboard and then uh you get points by um solving homeworks correctly and by sharing your progress in public. So we encourage learning in public. Um yeah we will talk about this more on the course lounge. But we encourage everything you learn to uh to share in public. And I I think I can um also share this thing. Do I have the same thing? Oh, so just yesterday I interviewed one of the students uh pastor. So pastor um he finished first on the leaderboard I think it was two years ago. So he shares his experience and also how public learning helped him. So I think this is a really cool episode, really cool interview. I will share it with you. Uh and then um inter view with pastor. So many good things happened to pastor after he shared the the learning after he learned in public. So uh we encourage you to do this and then we have this leaderboard. Okay. So yeah, once the course starts, you will have um these lessons with deadlines. Uh these deadlines will change as we go along the course because some things happen. Um sometimes there are delays. Uh yeah, but at the beginning we give you a rough uh schedule. So then you can some do some planning. Are there zoom lectures or live sessions on YouTube and learning while learning and what time? So all the things are pre-recorded. We will have one live stream for the launch and that's it. So we used to have um we used to have office hours. Right now I don't see any point in uh doing these office hours cuz we have done these office hours in the past. All the questions that people had I answered. So you can just rewatch the old office hours videos. Uh so there will be no live sessions. Um, you just watch pre-recorded videos and\n"
     ]
    }
   ],
   "source": [
    "q = \"How can I access old videos?\"\n",
    "resp = es_client.search(\n",
    "    index=index_name,\n",
    "    query={\"match\": {\"text\": q}},\n",
    "    size=5\n",
    ")\n",
    "for hit in resp[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_score\"], hit[\"_source\"][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9266f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query, num_results=5):\n",
    "    es_query = {\n",
    "        \"size\": num_results,\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"type\": \"best_fields\",\n",
    "                \"fields\": [\"start\", \"end\", \"text^3\"],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=es_query)\n",
    "\n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec3aa632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': '5:13',\n",
       "  'end': '7:44',\n",
       "  'text': \"update this to pytorch so this year you'll have two options you can go with tensorflow you can also go with pytorch um but yeah it will be basics so we will not go deep so this is not a computer vision class this is a machine learning engineering class so we will just have one lesson And we will focus a lot on deployment not on the theory part. We do not cover rack at all. So for rack if you're interested in rack there is another course called LLM Zoom camp. It has almost finished but all the materials are available for self-studying. Um so yeah here's you can check it. So we don't cover a rock in machine learning course but there's another course where we go pretty deep into this maybe not super deep but like we cover a lot of things when it comes to AI engineering. Uh are there any prerequisites to get the most out of the boot camp? Yes, you need to be uh comfortable with programming and with command line. So some basic linear algebra will help but this is not super important. So you we um provide all the say refreshment materials here. So we talk about linear algebra and numpy and we illustrate everything with code. So even if you never took linear algeb algebra class uh the concepts we explained here they are there enough. So the main prerequisite is knowing how to program. If you don't know Python, you should be able to uh pick it quickly. And if you know any other programming language like Java, JavaScript, whatever, R, you shouldn't be it shouldn't be difficult for you to pick up Python. And then where's actually our prerequisites? Yeah, here. And then uh starting with uh starting from module number five, we will use command line a lot. And this is um where this experience with prior experience using command line will help. Of course, not everyone has this experience. So you can pick it up too. But expect that uh here when we go from module 4 to module 5. So um if um for you software engineering is something you don't do regularly then it's going to take the model number five is going to take um significantly more time than the first four and this is based on what\"},\n",
       " {'start': '58:58',\n",
       "  'end': '1:01:34',\n",
       "  'text': \"haven't experimented with that but typically for me I just hey this is not detailed enough. I have an example actually from one of the workshops I gave. So let's say this coding agent. So in this um new workshop I was showing how to create a Django template even though like it wasn't about Django. So, I didn't want to spend time uh on explaining jungle stuff. And I think I just showed where is it? Think somewhere is a link build from scratch. Yeah. I don't know. chat GPT did I not post it? Okay, weird. Uh I think it was a different document. Anyways, um so what I did is I just um posted where so all these things like building the jungle app from scratch and I just edited this copied this to jungo and said hey this is the tutorial I don't understand explain it line by line and then it gave me some explanation but I say okay this explanation is not detailed enough I don't understand this step and then it explained me this step so this is how you can approach that Um yeah, so I I need to run now. I have another meeting right now. So um well I still I I managed to answer quite a few questions. So thanks a lot for uh joining me today for asking your questions. Uh this was an amazing session. Thanks a lot for all these questions. And what I can do is I still see that there are some questions. You can keep asking these questions and we will cover uh these questions on our next stream which will be um on September 15th when we launch the course. So there will be a section for Q&A where I will continue answering the questions you have. So if your question was not answered um I'll try to address this next time. So thanks a lot for joining. You have to run now. Um, so yeah, see you around and all the links are in the description if you're interested in enrolling into this course. Um, yeah, there's a sign up button. Click on that and you will receive an email and we will start on September 15th. So, bye everyone. See you soon.\"},\n",
       " {'start': '3:52',\n",
       "  'end': '6:24',\n",
       "  'text': \"we cover scikitlearn um like simplest model models and then we go deeper on the deployment side. So this is the area where many data scientists um don't know or not they know but like maybe this is their weak areas. So this is we we're going a little deeper in this side. That's why it's more like an engineering program, ML engineering program. And with these skills, usually people don't have any problems finding a job. How deep are we going into computer vision and rack? Okay. So we don't go deep into computer vision. We have one module on deep learning and in this deep learning module we uh do we build an image classifier. So this is a model that can classify different types of clothes into images of of clothes into 10 different categories like pants, like shirts, like t-shirts, stuff like that. So this is as uh deep as we go to computer vision. So that's only one module about that. And we also talk about deploying neural networks. So in the serverless model we talked about how okay you have a model how to deploy it and by the way speaking of the deep learning model uh previously we used tensorflow so we are going to update this to pytorch so this year you'll have two options you can go with tensorflow you can also go with pytorch um but yeah it will be basics so we will not go deep so this is not a computer vision class this is a machine learning engineering class so we will just have one lesson And we will focus a lot on deployment not on the theory part. We do not cover rack at all. So for rack if you're interested in rack there is another course called LLM Zoom camp. It has almost finished but all the materials are available for self-studying. Um so yeah here's you can check it. So we don't cover a rock in machine learning course but there's another course where we go pretty deep into this maybe not super deep but like we cover a lot of things when it comes to AI engineering. Uh are there any prerequisites to get the most out of the boot camp? Yes, you need to be uh comfortable with programming and with command line. So some basic linear algebra will help but this is not super important. So you we um provide all the\"},\n",
       " {'start': '52:34',\n",
       "  'end': '55:07',\n",
       "  'text': \"project I submitted was a fake course project. So there was nothing that's why I didn't get any points. Uh the reason I got uh nine uh is uh cuz I evaluated other peers. So that's why um like for each evalation I get three points. But this is how it's done. So the we evaluate projects by doing peer review and peer review is mandatory to complete the project. So if you submit a project but you don't do peer reviewing you fail the project and if you fail a project you fail the course. Right? So this very important to do peer reviews. Uh will the course make one job ready? Yes. If you put effort in the the the course and if you make a good project, if you also follow our recommendations to learn in public, this will definitely make you job ready. Uh what's the next path to follow after the completing the course? Uh to step into advanced stuff, find a job. That's the best way. Um cuz you can do courses forever, but I think you need to work on projects. This is where the real experience comes from. So you need to find something that is a job. Maybe at the beginning could be difficult but then find a volunteering job. I don't know there are so many places where you can volunteer. So put your skills into practice and then by doing this you will again do this project based learning that I um talked about and then it will force you to learn new things in order to solve a problem you have and then you build a portfolio of things and then it will make you even more job ready. Um yeah so I wouldn't recommend taking another course of course you can do a melops course that we have you can find a lot of courses like we have this page yeah wait no not this one 23 free online courses on machine learning so there are a lot of courses not just our course there are so many other courses but um I wouldn't recommend to spend too much time on learning things I would just say I mean on learning through courses. Courses are useful and important and for me personally courses were super helpful in my career but just don't do don't do just courses right so I would suggest to start involve being involved in different projects as soon as possible. Um you said the course videos are pre-recorded so the ones already available on the platform they will be\"},\n",
       " {'start': '42:34',\n",
       "  'end': '45:04',\n",
       "  'text': \"show how to do how to do deployment with AWS Lambda and we talk about Kubernetes where we show how to do deployment with Kubernetes. So once you have once you package things in your Docker container, you can deploy it virtually everywhere anywhere you want, right? Fly IO, uh AWS services, Kubernetes, whatever. Okay. Will we learn how to handle ML model monitoring and model retraining workflows like in production systems? No. This is something you we cover in MLOps zoom camp not in this one. Uh will taking the course be useful for aspiring data engineers? I think I answered this questions. Um so if your goal is to become a data engineer, this course will not be useful. So this course is for ML engineers well not for data engineers. Why do we get more points if we deploy the model to the cloud? Cuz um this is extra work, right? If you don't deploy, you don't get points. If you deploy, you get points. That's it. Um, Al, hi Al. I'm an engineering manager for some years in classical system building. Would you recommend this course for me? Well, Al, I need to know a little more about you to say if I can recommend this course to you. Uh, the question I have to you is if you're interested in machine learning. If the answer is yes, then I definitely can recommend this course. If the answer is no, I don't know what you're doing here. How often are live sessions and what's a typical schedule this week? So, we don't have live section live sessions. We only have pre-recorded. Well, when I say we don't, it doesn't mean we don't have them at all because right now is last live session, right? We will have another one when the course when we launch the course, but that will be the only one. Uh I don't think we I I don't plan any other live sessions. Um uh will there will be some um workshops too because I want to update some of the modules but there will be separate announcements. Uh most of the material is pre-recorded so uh you just watch those. So yeah uh I will do a live session on Kubernetes and a live session on PyTorch and these live sessions become the course materials. So next year when we um launch the sixth cohort of this course, I will simply use the materials\"}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"When would the next class start?\"\n",
    "elastic_search(query, num_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011767ea",
   "metadata": {},
   "source": [
    "## How to append new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16028825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_index': 'docs_lex', '_id': '500', '_version': 1, 'result': 'created', 'forced_refresh': True, '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 46, '_primary_term': 1})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.index(index=index_name, id=\"500\", document={\"start\":\"500\",'end':\"6000\",\"text\":\"Nelson is from nigeria Nelson is from nigeria Nelson is from nigeria\"}, refresh=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12dba0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': '500',\n",
       "  'end': '6000',\n",
       "  'text': 'Nelson is from nigeria Nelson is from nigeria Nelson is from nigeria'},\n",
       " {'start': '58:58',\n",
       "  'end': '1:01:34',\n",
       "  'text': \"haven't experimented with that but typically for me I just hey this is not detailed enough. I have an example actually from one of the workshops I gave. So let's say this coding agent. So in this um new workshop I was showing how to create a Django template even though like it wasn't about Django. So, I didn't want to spend time uh on explaining jungle stuff. And I think I just showed where is it? Think somewhere is a link build from scratch. Yeah. I don't know. chat GPT did I not post it? Okay, weird. Uh I think it was a different document. Anyways, um so what I did is I just um posted where so all these things like building the jungle app from scratch and I just edited this copied this to jungo and said hey this is the tutorial I don't understand explain it line by line and then it gave me some explanation but I say okay this explanation is not detailed enough I don't understand this step and then it explained me this step so this is how you can approach that Um yeah, so I I need to run now. I have another meeting right now. So um well I still I I managed to answer quite a few questions. So thanks a lot for uh joining me today for asking your questions. Uh this was an amazing session. Thanks a lot for all these questions. And what I can do is I still see that there are some questions. You can keep asking these questions and we will cover uh these questions on our next stream which will be um on September 15th when we launch the course. So there will be a section for Q&A where I will continue answering the questions you have. So if your question was not answered um I'll try to address this next time. So thanks a lot for joining. You have to run now. Um, so yeah, see you around and all the links are in the description if you're interested in enrolling into this course. Um, yeah, there's a sign up button. Click on that and you will receive an email and we will start on September 15th. So, bye everyone. See you soon.\"}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Where is nelson from?\"\n",
    "elastic_search(query, num_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfc1228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0976063",
   "metadata": {},
   "source": [
    "# KNN Search (vector search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0708b93",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641b429c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'docs_vec'})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VINDEX = \"docs_vec\"\n",
    "\n",
    "if es_client.indices.exists(index=VINDEX):\n",
    "    es_client.indices.delete(index=VINDEX)\n",
    "\n",
    "es_client.indices.create(\n",
    "    index=VINDEX,\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"start\":   {\"type\": \"keyword\"},\n",
    "            \"end\":   {\"type\": \"text\"},\n",
    "            \"text\": {\"type\": \"text\"},  # optional if you also want lexical\n",
    "            \"emb\":  {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,                # enable k-NN\n",
    "                \"similarity\": \"cosine\"        # or \"dot_product\" / \"l2_norm\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56294925",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in chunks:\n",
    "    vec = model.encode(d[\"text\"]).tolist()  # 384 floats\n",
    "    body = {\"id\": d[\"start\"], \"text\": d[\"text\"], \"emb\": vec}\n",
    "    es_client.index(index=VINDEX, id=d[\"start\"], document=body, refresh=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd9614",
   "metadata": {},
   "source": [
    "## How to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6837b97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7220858 zoom camp, machine learning zoom camp, llm zoom camp. So ML uh ML zoom camp this course is for ML engineers and data scientists. Um MLOps uh zoom camp is for ML engineers again slightly more advanced course than this one. Um so there is also a role called MLOps engineer but it may mean very different things for different companies. So um yeah we teach some uh automation some things like that like make files and so on. Um but yeah so in some cases MLOps engineer is somebody who builds platform for ML engineers then this is not about building platform but it will it talks about different steps and procedures of the ML process. Uh data engineer zoom camp is of course for data engineers uh also for data scientists who want to become better at building pipelines and then LM zoom camp is for AI engineers and data scientists. Then we also have analytics and stock market zoom camp. This is not a course I teach. So this is uh this is done by Ivan who's u like who's leading the course. Um so for him uh the for his course the target audience like it's for people who want to build um who want to trade and who want to build tools for trading. Um then we also have a AI dev tools zoom camp which is not here yet because this is still work in progress. This is course for engineers who want to use AI to become uh more proficient. Okay, let me share this link too. Okay, I think I was answering this question. Now, are you going to teach something new this time or we just have to watch old videos? Um, I think I explained it. uh yes you'll have to watch old videos but there is also new material so I uh this year I am updating some of the uh things some of the modules so you will have to watch well I don't like to say have to nobody's forcing you but if you wish to learn something you can decide to watch all videos yes but uh trust me these videos are going to be very useful to you um as they have been very useful to many people before you. Uh but also yeah there will be new things too. Uh what do you recommend for taking the course for the official repo and working or uh I would recommend creating a new one and adding I think maybe I do have examples here. Yeah, I would recommend to create a separate repo and then put\n",
      "0.7086036 they needed um I think they had some external um keyboard board. But anyways, like all you need is motivation to finish. Um, and internet. Yeah, internet is also important. Can we use chip or other lamps? Yeah, you can like I I would actually recommend using them every time you see a piece of code you don't understand. You just copy it to charge and ask it to explain. And that works really well cuz you can uh if you still don't understand some of the explanations, you can continue uh you can keep asking it until you understand. So this is really good. I do recommend to use chbpt for everything, not just common uh lines in Python, for all the things uh that in the course. I recommend using it because for me it helps me personally tremendously for not just courses but also for other things that I learn for other things that I explore or my interests. So I recommend that you use it too. Um uh yeah I think I answered this question about prerequisites is the zoom cup will be helpful to target these roles ML ops or AI platform engineering data infrastructure cloud and engineer infrastructure engineer oh yeah you have quite a lot of things uh I don't think this zoom camp will be helpful for any of those roles so for mlops um so what we have we also have a course called emlops zoom So let me share this link with you if you're interested. So we have this course but for me this MLOps course is just a so let's say this one is more for beginner ML engineers and MLOps course is more like intermediate ML engineers. So it's still about ML engineering. So we don't really talk about um you know classical ops uh in terms of DevOps uh but we show how to streamline uh operations right. Right. So this is what envelops is about like how to automate some things. Uh so this uh neither of these courses is good for cloud engineers or data infrastructure engineers or yeah like any infrastructure engineers or uh DevOps in general but these two courses will teach you how to become a good ML engineer. Um now I don't know what exactly you mean by MLOps because people may mean different things by this\n",
      "0.7050539 to um learn. So let's say after finishing this course you will not be able to win a Kaggle competition but after finishing this course you will be able to put an end to end machine learning project. So um I don't know get a data set um decide what kind of model you want to train train this model and then serve this model. So it will be an end to- end project that you will be able to accomplish which is enough to get hired but this is uh in no way um how to say mastery right so the path to mastery is very long and will require a lot of work so you will not be a senior ML engineer by the end of by the end you finish by the time you finish the course but uh you'll have enough knowledge to be an entry- level ML engineer um Yeah. So, you'll be able to independently create some things. Will we have any certificates to put on LinkedIn? Yes, you will. I think we even have an example. Do we? Let me check. Uh yeah, actually we have uh like if you go to the articles, we have some success stories from previous uh students. Um does he share his certificate? Yeah, this is the model he built now. So what I will do is I will just share these articles with you and you can check them out. I see that there are some questions in the chat. So, it's better to use the slider link cuz for me it's very difficult to keep track of the questions in the live chat. So, let's see here. Do we have I think we somewhere had an example of a certificate but yeah there will be a certificate. So I just wanted to show it but uh I don't think I can easily buy Oh actually I think I can so certificates. Yeah, here is an example. So this is how certificates will look like. So this is something you can upload to LinkedIn and we actually have instructions of how you can add this to LinkedIn. What does life cohort look like? Are there any deadlines? Yes. Um so the um we do this everything in a live cohort. There are deadlines. So um this is uh the platform we are going to use for learning. And let's take a look at the last year.\n",
      "0.70375353 is useful and when I was a data scientist for me knowing how to deploy things were quite nice. Is there a recommended companion book for the course? Yes. Uh so actually this course is based on a book I wrote machine learning book amp. So this is the book website. Uh I think I can share it here. Yeah. And then let me put it also here. So this course is based on the book. Uh but the book was written more than 5 years ago or like it was finished around uh maybe half a year before the course or maybe a year before the course was recorded. Um so yeah the some of the some parts of the book are slightly outdated. So this is what I'm going to fix right now um with this course. In this course we are reording some of the materials. So because the book is outdated you will find the examples you have in this course uh before the update. So we still use u flask there. Instead of fast fast API for example we use tensorflow there. Instead of PyTorch, we use Python 3.7 maybe like a relatively old uh Python instead of 3.13 and so on. But um the the course is largely based on the book and all the examples we have here uh in this course they are from the book. So yeah, this is a recommended book uh for this course. Yeah. Do you need to have to learn any prerequisites like math? Not necessarily. Um, knowing linear algebra will help. Um, but as I said, all the linear algebra you need to know, I cover here in this linear algebra uh unit. Maybe you can check it right now to see how much of this is still not clear after you watch the videos. I try to illustrate everything with u numpy. So for me as a developer, seeing things in code really helps. So maybe for you too. So check it out and um like if you understand what's happening here then I think you're good uh to with math when it comes to math. So you only need um some basic linear algebra. We use this linear algebra in module number two when we implement linear regression ourselves. But then starting from module number three, we don't use any mathematics at all cuz uh we start using scikitlearn and uh scikitlearn um implements everything we need right so we don't really need to uh worry\n",
      "0.7016486 yeah, we'll just need to use uh newer versions. Uh but I also want to record any some extra things here. Uh some extra things here. So you but um to answer your question you can go ahead and watch the videos right now. There will be some updates but by watching the videos um so the updates will be extra materials right so you can already just watch what we have. Would you do a math for AI zoom camp or boot camp? No. Um detailed timeline. I talked about this. We talked about this. Um would you share any assignments or problems after each module? Uh yes, we have homework and we also have um like solutions. We publish the solutions. If I miss cohorts, will I not get the certificate? Do you miss if you do you mean if you miss uh a homework? If you miss a homework, you will still get a certificate. If you miss the entire cohort, you will not get the certificate, of course. uh answered. So the homeworks will be different but you can check the past homeworks. Yeah. Um any resource tutorials to sharpen my Python skills? Chad GPT is really good. So just use CHP. Does the course cover fundamental mathematics needed for machine learning? No, we don't cover these things. Just a little bit of algebra. I want to learn artificial intelligence, machine learning. Um I think I answered that question. You can see this from the syllabus what we cover and what we don't. This is not a replacement for MLOps course. Um uh answered question from Alex. So maybe this is the last question I'm going to take. How do you maximize learning with LM? You let it explain to you but take care to do things that you're learning manually. So the easiest way um you can do so let's say uh there is um this piece of code you don't understand uh let's see so let's say you're struggling with docker and then you don't understand what's happening here so then what you can do is you can copy paste these things to chip and say hey please explain midline by line what happens here and then chaptt is doing quite a good job at that So this is uh what I'm mean mostly but uh I think it has this learning mode that they published recently. Uh I\n"
     ]
    }
   ],
   "source": [
    "q = \"What tool will this course teach?\"\n",
    "qv = model.encode(q).tolist()\n",
    "\n",
    "resp = es_client.search(\n",
    "    index=VINDEX,\n",
    "    knn={\n",
    "        \"field\": \"emb\",\n",
    "        \"query_vector\": qv,\n",
    "        \"k\": 5,                 # return top-k\n",
    "        \"num_candidates\": 100   # search breadth (↑ recall, ↑ latency)\n",
    "    }\n",
    ")\n",
    "for hit in resp[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_score\"], hit[\"_source\"][\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc9bba5",
   "metadata": {},
   "source": [
    "## How to append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbb802f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_index': 'docs_vec', '_id': '5000', '_version': 1, 'result': 'created', 'forced_refresh': True, '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 46, '_primary_term': 1})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Nelson is from Nigeria\"\n",
    "emb  = model.encode(text).tolist()\n",
    "es_client.index(index=VINDEX, id=\"5000\", document={\"id\":\"4\",\"text\":text,\"emb\":emb}, refresh=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff20637e",
   "metadata": {},
   "source": [
    "Deletions/updates: use es.delete(...) or re-index the doc with the same id.\n",
    "For high-throughput ingestion, prefer bulk API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af0f6bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82654715 Nelson is from Nigeria\n",
      "0.55061954 like if you're uh an engineer, if you know how to program, then for you this is enough. Do I need a efficient workstation? Like probably asked you asked, do you need a good computer to uh work on this um course? No. Um actually what you can use is um a code space I think. Oh wait, I think code spaces GitHub code spaces. If you go to here environment here I show how to um configure GitHub code spaces and actually the environment you get there for code spaces is relatively is very not powerful it just have has two CPUs and I don't know how I don't remember how many how much RAM but yeah this is not um very powerful um so then what you need to have is just a computer with Python or computer with internet if you don't if you cannot install some things or maybe you I know some students uh from Nigeria uh that we have that we had in the past they didn't even have a computer they just had a tablet they could still finish the course so they could use um this code spaces they could connect to code spaces from their tablet and then they could program everything they needed um I think they had some external um keyboard board. But anyways, like all you need is motivation to finish. Um, and internet. Yeah, internet is also important. Can we use chip or other lamps? Yeah, you can like I I would actually recommend using them every time you see a piece of code you don't understand. You just copy it to charge and ask it to explain. And that works really well cuz you can uh if you still don't understand some of the explanations, you can continue uh you can keep asking it until you understand. So this is really good. I do recommend to use chbpt for everything, not just common uh lines in Python, for all the things uh that in the course. I recommend using it because for me it helps me personally tremendously for not just courses but also for other things that I learn for other things that I explore or my interests. So I recommend that you use it too. Um uh yeah I think I answered this question about prerequisites is the zoom cup will be helpful to\n",
      "0.5373078 zoom camp, machine learning zoom camp, llm zoom camp. So ML uh ML zoom camp this course is for ML engineers and data scientists. Um MLOps uh zoom camp is for ML engineers again slightly more advanced course than this one. Um so there is also a role called MLOps engineer but it may mean very different things for different companies. So um yeah we teach some uh automation some things like that like make files and so on. Um but yeah so in some cases MLOps engineer is somebody who builds platform for ML engineers then this is not about building platform but it will it talks about different steps and procedures of the ML process. Uh data engineer zoom camp is of course for data engineers uh also for data scientists who want to become better at building pipelines and then LM zoom camp is for AI engineers and data scientists. Then we also have analytics and stock market zoom camp. This is not a course I teach. So this is uh this is done by Ivan who's u like who's leading the course. Um so for him uh the for his course the target audience like it's for people who want to build um who want to trade and who want to build tools for trading. Um then we also have a AI dev tools zoom camp which is not here yet because this is still work in progress. This is course for engineers who want to use AI to become uh more proficient. Okay, let me share this link too. Okay, I think I was answering this question. Now, are you going to teach something new this time or we just have to watch old videos? Um, I think I explained it. uh yes you'll have to watch old videos but there is also new material so I uh this year I am updating some of the uh things some of the modules so you will have to watch well I don't like to say have to nobody's forcing you but if you wish to learn something you can decide to watch all videos yes but uh trust me these videos are going to be very useful to you um as they have been very useful to many people before you. Uh but also yeah there will be new things too. Uh what do you recommend for taking the course for the official repo and working or uh I would recommend creating a new one and adding I think maybe I do have examples here. Yeah, I would recommend to create a separate repo and then put\n",
      "0.5348889 whatever reasons um do the cloud thing then you can just deploy locally you will just get fewer points but we do show how to deploy to the cloud not just locally. I am a data engineer and I want to become a male engineer. Will this course help? If yes, how much? Yes, it will. Um, I don't know how to answer the second like very much. Yeah, well, it will help you. Yeah. Um, what is the better job for the future? Data engineer, data scientist or how do you measure better like um um the way I would rephrase it, what is the better job for me in the future? Do I enjoy doing data engineering, data science or machine learning? So once you have the answer then you have the answer for this question cuz the the point is to do what you enjoy most like if let's say somebody says oh yeah data engineers are more in more demand cuz there are more vacancies but then you hate data engineering you don't like it like so does it mean you have to do it or maybe there are fewer ML engineering jobs but you just like it more so then just go with this so yeah and then who knows maybe AI will replace all of them. So yeah, I'm I'm joking. I don't think it will replace but um yeah, in terms of better like you define better and then yeah, you just select it for yourself. Is there a leaderboard? Yeah, we talked about the leaderboard. Will anyone with zero technical background uh where is Hendrick to get this? Yeah, I I think I answered that. So if you have the motivation, if you have the time and if you're willing to put the time and energy into this then you will be able to finish. Uh so there will be three projects and in order to get a certificate you will need to finish two out of three at least. So you can finish three of course but you need to finish at least two. So it will be a midterm project and uh so midterm project will happen between um let me check uh yeah so you see we have module number six and then module number eight so we kind of jump so there is no module number seven so what happens here is the midterm project and then we will also have after the Kubernetes module we will have two more projects so out of these\n",
      "0.5323376 haven't experimented with that but typically for me I just hey this is not detailed enough. I have an example actually from one of the workshops I gave. So let's say this coding agent. So in this um new workshop I was showing how to create a Django template even though like it wasn't about Django. So, I didn't want to spend time uh on explaining jungle stuff. And I think I just showed where is it? Think somewhere is a link build from scratch. Yeah. I don't know. chat GPT did I not post it? Okay, weird. Uh I think it was a different document. Anyways, um so what I did is I just um posted where so all these things like building the jungle app from scratch and I just edited this copied this to jungo and said hey this is the tutorial I don't understand explain it line by line and then it gave me some explanation but I say okay this explanation is not detailed enough I don't understand this step and then it explained me this step so this is how you can approach that Um yeah, so I I need to run now. I have another meeting right now. So um well I still I I managed to answer quite a few questions. So thanks a lot for uh joining me today for asking your questions. Uh this was an amazing session. Thanks a lot for all these questions. And what I can do is I still see that there are some questions. You can keep asking these questions and we will cover uh these questions on our next stream which will be um on September 15th when we launch the course. So there will be a section for Q&A where I will continue answering the questions you have. So if your question was not answered um I'll try to address this next time. So thanks a lot for joining. You have to run now. Um, so yeah, see you around and all the links are in the description if you're interested in enrolling into this course. Um, yeah, there's a sign up button. Click on that and you will receive an email and we will start on September 15th. So, bye everyone. See you soon.\n"
     ]
    }
   ],
   "source": [
    "q = \"Who is from Nigeria?\"\n",
    "qv = model.encode(q).tolist()\n",
    "\n",
    "resp = es_client.search(\n",
    "    index=VINDEX,\n",
    "    knn={\n",
    "        \"field\": \"emb\",\n",
    "        \"query_vector\": qv,\n",
    "        \"k\": 5,                 # return top-k\n",
    "        \"num_candidates\": 100   # search breadth (↑ recall, ↑ latency)\n",
    "    }\n",
    ")\n",
    "for hit in resp[\"hits\"][\"hits\"]:\n",
    "    print(hit[\"_score\"], hit[\"_source\"][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38782b8",
   "metadata": {},
   "source": [
    "How persistence works\n",
    "\n",
    "Elasticsearch persists data to disk automatically (indices live on data nodes). You don’t “save” an index from your app.\n",
    "\n",
    "For backups / disaster recovery, use the Snapshot & Restore API:\n",
    "\n",
    "Register a snapshot repository (e.g., to an S3 bucket).\n",
    "\n",
    "Create snapshots on a schedule.\n",
    "\n",
    "Restore from a snapshot when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4.1 register a repo (example: shared filesystem; for S3 use the S3 repo plugin)\n",
    "# PUT _snapshot/my_repo\n",
    "# {\n",
    "#   \"type\": \"fs\",\n",
    "#   \"settings\": { \"location\": \"/mnt/es_backups\" }\n",
    "# }\n",
    "\n",
    "# # 4.2 take a snapshot of both indices\n",
    "# PUT _snapshot/my_repo/snap_2025_10_18?wait_for_completion=true\n",
    "# {\n",
    "#   \"indices\": \"docs_lex,docs_vec\",\n",
    "#   \"ignore_unavailable\": true,\n",
    "#   \"include_global_state\": false\n",
    "# }\n",
    "\n",
    "# # 4.3 list snapshots\n",
    "# GET _snapshot/my_repo/_all\n",
    "\n",
    "# # 4.4 restore later\n",
    "# POST _snapshot/my_repo/snap_2025_10_18/_restore\n",
    "# {\n",
    "#   \"indices\": \"docs_lex,docs_vec\",\n",
    "#   \"include_global_state\": false\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64486b43",
   "metadata": {},
   "source": [
    "# Hybrid search (BM25 + vector) in Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f01be6",
   "metadata": {},
   "source": [
    "Run both searches, then fuse results with Reciprocal Rank Fusion (RRF) or a weighted sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4343ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "q = \"Who is the speaker?\"\n",
    "qv = model.encode(q).tolist()\n",
    "\n",
    "bm25 = es_client.search(index=index_name, query={\"match\": {\"text\": q}}, size=5)\n",
    "knn  = es_client.search(index=VINDEX, knn={\"field\":\"emb\",\"query_vector\":qv,\"k\":5,\"num_candidates\":200})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a81173ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankmap(hits, score_key=\"_score\"):\n",
    "    return {h[\"_id\"]: r+1 for r, h in enumerate(sorted(hits[\"hits\"][\"hits\"], key=lambda x: -x[score_key]))}\n",
    "\n",
    "r_bm25 = rankmap(bm25)\n",
    "r_knn  = rankmap(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e309c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20:46': 1, '22:08': 2, '47:40': 3, '10:26': 4, '48:54': 5}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c517acff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5000': 1, '30:30': 2, '0:00': 3, '27:30': 4, '31:59': 5}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2dfe0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrf(doc_id, k=7):\n",
    "    return (1/(k + r_bm25.get(doc_id, 10**9))) + (1/(k + r_knn.get(doc_id, 10**9)))\n",
    "\n",
    "ids = {h[\"_id\"] for h in bm25[\"hits\"][\"hits\"]} | {h[\"_id\"] for h in knn[\"hits\"][\"hits\"]}\n",
    "fused = sorted(ids, key=lambda i: -rrf(i))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c2039be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0:00',\n",
       " '10:26',\n",
       " '20:46',\n",
       " '22:08',\n",
       " '27:30',\n",
       " '30:30',\n",
       " '31:59',\n",
       " '47:40',\n",
       " '48:54',\n",
       " '5000'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "009fd0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20:46',\n",
       " '5000',\n",
       " '30:30',\n",
       " '22:08',\n",
       " '47:40',\n",
       " '0:00',\n",
       " '27:30',\n",
       " '10:26',\n",
       " '48:54',\n",
       " '31:59']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "074bb23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:46 {'start': '20:46', 'end': '23:24', 'text': \"but yeah so this is for ML engineering. Uh for data engineering uh do you recommend taking this course depends on your goals. If your goal is to learn data engineering then no I do not recommend. If you're a data engineer who work with machine learners, machine learning engineers and with data scientists and you want to understand what what is happening, what they are doing, this course will be very helpful. When it comes to data engineering, we actually have a course called data engineering zoom camp that is focused specifically on data engineering. So this is what you should take instead if you are interested in data engineering. So this course will be tangentally useful just to broaden your horizons. Uh if you work with ML teams uh yes it will be helpful to understand what they are doing but for you as data engineer for your career uh unless you plan to work with ML it will not be very useful. Please explain what jobs are suitable for each course in Zoom camp. Okay, let's try now we have courses. So these are the courses. So the courses we have MLOps zoom camp, data engineer zoom camp, machine learning zoom camp, llm zoom camp. So ML uh ML zoom camp this course is for ML engineers and data scientists. Um MLOps uh zoom camp is for ML engineers again slightly more advanced course than this one. Um so there is also a role called MLOps engineer but it may mean very different things for different companies. So um yeah we teach some uh automation some things like that like make files and so on. Um but yeah so in some cases MLOps engineer is somebody who builds platform for ML engineers then this is not about building platform but it will it talks about different steps and procedures of the ML process. Uh data engineer zoom camp is of course for data engineers uh also for data scientists who want to become better at building pipelines and then LM zoom camp is for AI engineers and data scientists. Then we also have analytics and stock market zoom camp. This is not a course I teach. So this is uh this is done by Ivan who's u like who's leading the course. Um so for him uh the for his course the target audience like it's for people who want to build um who want to trade and who\"}\n",
      "5000 {'id': '4', 'text': 'Nelson is from Nigeria', 'emb': [-0.06134345754981041, 0.06070413812994957, -0.045191604644060135, 0.037542276084423065, 0.03564036637544632, 0.03285927325487137, 0.040513377636671066, 0.012586659751832485, -0.024192558601498604, 0.0839650109410286, -0.013404334895312786, -0.0825342908501625, -0.020551417022943497, -0.0244991946965456, 0.008343546651303768, 0.05822533741593361, 0.020784351974725723, 0.018567616119980812, 0.024290479719638824, -0.03780616447329521, -0.005828116554766893, 0.031247977167367935, 0.02983907423913479, -0.017494171857833862, 0.005783000960946083, 0.006703789811581373, -0.0043338146060705185, -0.03336276486515999, 0.08661135286092758, -0.01109305489808321, 0.05559230223298073, -0.03392999619245529, 0.05276830494403839, 0.013164492323994637, 0.046766430139541626, -0.004265771713107824, 0.058426935225725174, 0.014128603041172028, 0.06626871228218079, 0.0078779561445117, 0.044702716171741486, 0.05438585206866264, 0.019418202340602875, -0.01990688405930996, 0.048947256058454514, 0.026904035359621048, -0.0055932654067873955, 0.09921799600124359, 0.005872318521142006, -0.02802629955112934, -0.04563101381063461, 0.047222789376974106, -0.04179012402892113, -0.10989030450582504, 0.01870501972734928, -0.030842194333672523, -0.05100994557142258, -0.05633781477808952, 0.04968997463583946, 0.021693114191293716, 0.014037150889635086, 0.03680843487381935, -0.009222613647580147, 0.01685740053653717, -0.030873501673340797, 0.009259657002985477, -0.0026419591158628464, -0.032620713114738464, 0.040031760931015015, -0.030491983518004417, 0.07928343862295151, -0.029306290671229362, 0.0021215644665062428, -0.015551355667412281, -0.05272793024778366, -0.05117829516530037, 0.04919715225696564, 0.006045622751116753, -0.07336784899234772, 0.049415748566389084, -0.05748055875301361, -0.06174294650554657, 0.015582301653921604, -0.10961991548538208, -0.02020302228629589, -0.01983909122645855, -0.02260817028582096, -0.02234172634780407, -0.018759600818157196, -0.057787492871284485, 0.024008693173527718, -0.00802841130644083, 0.005042461212724447, 0.07853453606367111, -0.049963295459747314, -0.029998529702425003, 0.06380975246429443, 0.07215899974107742, -0.022760318592190742, 0.15012206137180328, -0.07121967524290085, 0.0002484635915607214, 0.012985236942768097, -0.0102074658498168, -0.025171684101223946, 0.11888338625431061, 0.009287403896450996, 0.08539973199367523, 0.03316134586930275, 0.03165780007839203, -0.07574314624071121, 0.09423331916332245, -0.06047294661402702, 0.11433764547109604, 0.00876657385379076, -0.02280534990131855, -0.046964120119810104, -0.010975458659231663, 0.0406121090054512, 0.06155010312795639, 0.020320750772953033, -0.011386241763830185, -0.07879918068647385, 0.06740061193704605, -0.0770605057477951, -0.03788723424077034, 0.06018451601266861, -2.5910415458137792e-33, -0.017203088849782944, 0.002318092854693532, 0.08073066920042038, -0.01503375917673111, -0.04255978763103485, 0.07129614055156708, -0.023527655750513077, -0.012666543014347553, -0.07687217742204666, 0.024145012721419334, 0.0020669838413596153, -0.020037813112139702, 0.03162134811282158, 0.00022801342129241675, -0.07737820595502853, 0.06543836742639542, -0.06261860579252243, 0.011004035361111164, 0.040674082934856415, 0.01877220720052719, 0.02990168333053589, 0.051791056990623474, 0.022181306034326553, 0.0027301828376948833, 0.04492702707648277, 0.03161928057670593, 0.016178613528609276, -0.017935574054718018, 0.1103985533118248, 0.05032067373394966, 0.013725314289331436, -0.009794198907911777, -0.02788379043340683, -0.04018770530819893, -0.029414847493171692, 0.023235678672790527, -0.020419223234057426, -0.10183937102556229, -0.08469107002019882, 0.003931804560124874, 0.03402639180421829, 0.047827597707509995, -0.05406522750854492, 0.027674121782183647, -0.11376429349184036, -0.028481394052505493, 0.06071976199746132, -0.017306404188275337, 0.05003001540899277, -0.054457202553749084, -0.09857991337776184, -0.03544725477695465, -0.06415265798568726, -0.0028538601472973824, 0.07030460238456726, -0.11357259750366211, -0.02524482272565365, 0.06816109269857407, 0.0768526941537857, -0.02130703441798687, 0.037816841155290604, -0.08012990653514862, -0.007172841578722, 0.006245794240385294, 0.025744400918483734, -0.11613120883703232, 0.015436474233865738, 0.038423970341682434, 0.047334037721157074, -0.13822369277477264, 0.04429004713892937, 0.013430314138531685, 0.04212870076298714, 0.05788138136267662, -0.048567995429039, -0.025314750149846077, 0.004226461052894592, -0.009447856806218624, 0.006305919960141182, 0.08531655371189117, -0.047119662165641785, 0.0008641148451715708, -0.03899868577718735, -0.04561777412891388, -0.05216337740421295, 0.0577576719224453, -0.009249495342373848, -0.05336057394742966, -0.01665513403713703, 0.030284376814961433, -0.040614426136016846, -0.012755749747157097, -0.02915501594543457, -0.01463735569268465, -0.02123255282640457, 6.7286371116372785e-34, -0.03220022842288017, 0.011780664324760437, 0.04258927330374718, -0.007495356258004904, 0.08223418891429901, -0.08041220158338547, 0.11083558946847916, 0.09817428886890411, 0.009302005171775818, 0.0007928236154839396, 0.02037113718688488, -0.12356773763895035, 0.04707275331020355, -0.04535600543022156, -0.017353439703583717, -0.00489029148593545, 0.0573459193110466, 0.06185454875230789, -0.03524884581565857, -0.009098794311285019, -0.038874551653862, 8.485429862048477e-05, -0.05572645738720894, -0.03842860087752342, -0.02409154735505581, 0.04832381010055542, -0.07435958832502365, -0.003500171471387148, -0.11207839101552963, 0.01285290252417326, -0.0575440376996994, 0.0886751189827919, -0.057210735976696014, 0.06262233853340149, -0.0699511170387268, 0.06960900872945786, -0.08415946364402771, 0.07141385227441788, 0.06290317326784134, 0.04426557198166847, 0.045444462448358536, 0.07506498694419861, -0.00617727916687727, 0.02390681952238083, -0.008013883605599403, 0.07800301164388657, 0.015100346878170967, 0.05768566206097603, 0.006357587408274412, -0.07911820709705353, -0.031173711642622948, 0.033345770090818405, -0.08791542798280716, -0.05553433671593666, 0.06655477732419968, -0.03569912910461426, -0.032500214874744415, -0.006521979346871376, 0.021197667345404625, 0.02257588878273964, 0.05973372980952263, 0.03544292971491814, 0.01044808141887188, -0.04499875754117966, 0.04566456004977226, 0.08881361037492752, -0.09074430167675018, 0.019006429240107536, 0.08537255972623825, 0.08169464766979218, 0.008622445166110992, -0.06379426270723343, -0.04806134104728699, 0.028069233521819115, -0.05756397917866707, 0.0905667245388031, -0.07879970222711563, -0.029480714350938797, -0.07102197408676147, -0.11406634002923965, -0.028213679790496826, -0.1055770292878151, -0.05214926227927208, 0.08829783648252487, -0.05543253943324089, 0.05391961336135864, 0.05583057552576065, -0.03226780891418457, 0.02323429472744465, 0.04704506695270538, -0.055645860731601715, -0.031465645879507065, -0.04082435742020607, -0.025742504745721817, 0.026004143059253693, -1.2542225036327181e-08, -0.031593773514032364, 0.02617673948407173, 0.009831110015511513, 0.030333291739225388, -0.058276787400245667, 0.1509888768196106, 0.029146814718842506, -0.053804945200681686, -0.007286397740244865, 0.04744664207100868, -0.0006257459754124284, 0.0072658550925552845, 0.024707455188035965, -0.04453874006867409, 0.010153195820748806, -0.026456860825419426, -0.10589230805635452, -0.002430905355140567, 0.05018036067485809, 0.0028507995884865522, 0.028934381902217865, 0.03152763843536377, 0.05490413308143616, -0.018001336604356766, 0.010699231177568436, -0.02248266525566578, 0.014659498818218708, 0.07269074767827988, -0.005290067754685879, -0.03958039730787277, 0.003314653178676963, 0.04604962095618248, -0.03340274468064308, 0.011746027506887913, 0.09554705023765564, 0.0018191075650975108, -0.022025614976882935, -0.05036325007677078, -0.07426553219556808, -0.07704182714223862, 0.02534819394350052, 0.05558646097779274, -0.03360525146126747, 0.022528598085045815, 0.009413955733180046, -0.011034962721168995, 0.017751382663846016, 0.07300911843776703, -0.03531657159328461, -0.08392712473869324, -0.029020028188824654, -0.044310905039310455, -0.04486366733908653, 0.021085096523165703, -0.033647239208221436, -0.021076850593090057, -0.08150742948055267, -0.01971808262169361, 0.01639651693403721, -0.018287193030118942, 0.050149768590927124, -0.1120978444814682, -0.031840331852436066, -0.06597095727920532]}\n",
      "30:30 {'start': '30:30', 'end': '33:15', 'text': \"sense to actually keep it open right because you can see the solutions and simply copy it. So yeah, so there are deadlines to keep you to help you um um with um sticking to the schedule. Then we also have a leaderboard where I think Alexander this is the person who wrote uh this article, right? It's actually he wrote too. Cool. Um so uh yeah we have this uh leaderboard and then uh you get points by um solving homeworks correctly and by sharing your progress in public. So we encourage learning in public. Um yeah we will talk about this more on the course lounge. But we encourage everything you learn to uh to share in public. And I I think I can um also share this thing. Do I have the same thing? Oh, so just yesterday I interviewed one of the students uh pastor. So pastor um he finished first on the leaderboard I think it was two years ago. So he shares his experience and also how public learning helped him. So I think this is a really cool episode, really cool interview. I will share it with you. Uh and then um inter view with pastor. So many good things happened to pastor after he shared the the learning after he learned in public. So uh we encourage you to do this and then we have this leaderboard. Okay. So yeah, once the course starts, you will have um these lessons with deadlines. Uh these deadlines will change as we go along the course because some things happen. Um sometimes there are delays. Uh yeah, but at the beginning we give you a rough uh schedule. So then you can some do some planning. Are there zoom lectures or live sessions on YouTube and learning while learning and what time? So all the things are pre-recorded. We will have one live stream for the launch and that's it. So we used to have um we used to have office hours. Right now I don't see any point in uh doing these office hours cuz we have done these office hours in the past. All the questions that people had I answered. So you can just rewatch the old office hours videos. Uh so there will be no live sessions. Um, you just watch pre-recorded videos and\"}\n",
      "22:08 {'start': '22:08', 'end': '24:54', 'text': \"zoom camp, machine learning zoom camp, llm zoom camp. So ML uh ML zoom camp this course is for ML engineers and data scientists. Um MLOps uh zoom camp is for ML engineers again slightly more advanced course than this one. Um so there is also a role called MLOps engineer but it may mean very different things for different companies. So um yeah we teach some uh automation some things like that like make files and so on. Um but yeah so in some cases MLOps engineer is somebody who builds platform for ML engineers then this is not about building platform but it will it talks about different steps and procedures of the ML process. Uh data engineer zoom camp is of course for data engineers uh also for data scientists who want to become better at building pipelines and then LM zoom camp is for AI engineers and data scientists. Then we also have analytics and stock market zoom camp. This is not a course I teach. So this is uh this is done by Ivan who's u like who's leading the course. Um so for him uh the for his course the target audience like it's for people who want to build um who want to trade and who want to build tools for trading. Um then we also have a AI dev tools zoom camp which is not here yet because this is still work in progress. This is course for engineers who want to use AI to become uh more proficient. Okay, let me share this link too. Okay, I think I was answering this question. Now, are you going to teach something new this time or we just have to watch old videos? Um, I think I explained it. uh yes you'll have to watch old videos but there is also new material so I uh this year I am updating some of the uh things some of the modules so you will have to watch well I don't like to say have to nobody's forcing you but if you wish to learn something you can decide to watch all videos yes but uh trust me these videos are going to be very useful to you um as they have been very useful to many people before you. Uh but also yeah there will be new things too. Uh what do you recommend for taking the course for the official repo and working or uh I would recommend creating a new one and adding I think maybe I do have examples here. Yeah, I would recommend to create a separate repo and then put\"}\n",
      "47:40 {'start': '47:40', 'end': '50:10', 'text': \"engineering inclined. um doesn't mean there these roles are set in stone. Um I know some ML engineers who are pretty good at modeling. So they do this. Uh the reason I the reason we have these modules here cuz I think this is still important for ML engineers to be able to create a simple model. Uh but you will not as I said you will not win a Kaggle competition with this knowledge. Right? So these are pretty basics. Um so I have to disappoint you here. here we don't really have a lot of math but also as a data scientist I didn't need to really use a lot of math to be honest how we should balance learning uh the tools versus understanding the core concepts what should come first in practice so for me uh I was an engineer I used to work as a dove developer and then I switched to machine learning the way I did this the way I structured My learning was on by doing projects. So I had a project in mind and then I learned just enough to deliver this project and then sometimes some things were interesting for me so I would dig deeper into some of the topics. But for me as an engineer the approach of focusing the project of having an end in mind really helped to stay focused and this is the approach we use here in the course. So here um let's say for this for this the third uh module uh the problem we have is term prediction right so there are some people we are working in a telecom company there are some people who canceling their contract with the company with our company so we want to detect u people who are about to cancel and prevent them from doing this so we want to send them an a promotional email saying hey uh like here's a discount don't please don't go. Um so in hope that we will retain these customers. So here's the project description and we cover just enough theory to finish the project right and you don't need more and this project based learning I think it's the best um learning because otherwise you risk of going too deep into some things and spend too much time on that. So this is how I think you should balance learning. So you kind of need both tools and\"}\n",
      "0:00 {'start': '0:00', 'end': '2:38', 'text': \"So hi everyone. Uh today we are going to talk about our upcoming course. The upcoming course is called machine learning zoom camp. And um this is already I put the link in the description. So if you're watching um this video in recording or you're watching it live, you go here in the description after under this video and then you see a link course. uh click on that link and this bring you will bring you to this website this GitHub page. This GitHub page is the main entry point to our course and um yeah I think it's more or less self-explanatory. If you want to sign up this is the button you click and the actual course starts in on September 15th. it means that it's uh slightly less than one one month before the course starts and the purpose of today's um session is to just answer your questions. So you have some questions and uh you can ask these questions using uh you can ask your questions using the pinned link. So there's a pinned link in the live chat. Click on that link um and there ask your questions. So yeah, this is how it looks like and I am just going to uh use this thing. So we can also go to SLO and use ML Zoom camp and I'm going to use that for answering questions. Uh one thing though, so before we start, I just wanted to mention that um this course has been running for uh this will be the fifth edition of this course. So we've been doing this course for quite some time. Many people already graduated from this course and um most of the content we use here is the content I uh recorded like four years ago but we are updating the content so cuz u back then everyone was using Python 3.8 eight or nine something like. So yeah, we are re-recording some of the things in particular. Module one, two, three, four will uh stay the same cuz uh this uh these are the fundamentals. They didn't change. But module five we uh will update. Module 6 will stay the same. Module 8 we will update. Module 9 update update. And this we will not include like we only include it once and this thing get outdated very fast. So we just I just didn't bother updating this at all and it's pretty advanced material. So we will update like four out of 10 modules. So that's the plan. Uh and we already had some workshops for\"}\n",
      "27:30 {'start': '27:30', 'end': '30:28', 'text': \"Um does he share his certificate? Yeah, this is the model he built now. So what I will do is I will just share these articles with you and you can check them out. I see that there are some questions in the chat. So, it's better to use the slider link cuz for me it's very difficult to keep track of the questions in the live chat. So, let's see here. Do we have I think we somewhere had an example of a certificate but yeah there will be a certificate. So I just wanted to show it but uh I don't think I can easily buy Oh actually I think I can so certificates. Yeah, here is an example. So this is how certificates will look like. So this is something you can upload to LinkedIn and we actually have instructions of how you can add this to LinkedIn. What does life cohort look like? Are there any deadlines? Yes. Um so the um we do this everything in a live cohort. There are deadlines. So um this is uh the platform we are going to use for learning. And let's take a look at the last year. So you see we have homework and then we have deadline for this homework right for each homework we have deadlines you have to finish the homework before the deadline and all the interactions happen in slack so in slack there are other fellow learners with who you can interact uh also the course instructors are there in slack so we help you too but mostly you interact with other learners um and yeah so every week or sometimes for some modules we have two weeks uh per model. Just a second. For some weeks we have two weeks per model. For some uh for some modules we have one week per module. Um and then everyone works at the same time at the same thing. Right? So that's the main idea. Then um last year we also had a competition a competition on Kaggle. So this year we might have something too. And then also projects are here. So everything uh we work on is here on this platform and yeah we have some deadlines after the deadline passed you will not be able to submit the homework. So usually after the deadline we score all the homeworks we publish the solutions that's why after the deadline once the solutions are published it doesn't make\"}\n",
      "10:26 {'start': '10:26', 'end': '12:53', 'text': \"expect you to know this uh prior to the course. So we don't expect you to know any machine learning. Uh we're here to actually teach you machine learning. So you're here to learn machine learning. So that's why we start from like really basic things and then progress to more difficult ones. So you don't need to know any scikitlearn. You will learn psychit learn here. You do not need to learn uh so for example here we teach docker you don't need to have prior experience with docker here we teach uh we talk about virtual environments you don't need to have this experience working with virtual environments. So we all um we teach all these things here but of course if you already worked with Python and know what virtual environments are uh then good for you. So then for you model number five will be like the easiest and same applies with uh deep learning. So if you already used um PyTorch then for you probably the module about deep learning will be easy cuz if you use PyTorch you probably know everything already. So we um this is for people who don't know PyTorch and TensorFlow. Uh is ML zoom camp for people who want to become data scientists or ML engineers? Kind of both but targeted more for ML engineers because we have a lot of uh again let me open it a lot of topics are engineering. So deployment uh serverless kubernetes they are engineering topics. Uh typically data scientists they are exposed to these things to small extent than uh than ML engineers. uh that's why this is ML engineering an ML engineering course and then K surf uh yeah we don't really um cover it here but this is also an engineering topic so I think uh the content is still useful but it's kind of very outdated because these things change very fast and I don't have opportunity to keep it up to date every year but anyways um so we have a lot of engineering topics so I I would say this is more uh g this is more tailored to um those who want to become MEL engineers but data scientists will also um find it useful. Many data scientists said okay yeah like I already knew um like I know module number one 2 4 6 8 this was already like I already knew things but module five uh 9 and 10 were super useful. So for data scientists this information\"}\n",
      "48:54 {'start': '48:54', 'end': '51:21', 'text': \"into some of the topics. But for me as an engineer the approach of focusing the project of having an end in mind really helped to stay focused and this is the approach we use here in the course. So here um let's say for this for this the third uh module uh the problem we have is term prediction right so there are some people we are working in a telecom company there are some people who canceling their contract with the company with our company so we want to detect u people who are about to cancel and prevent them from doing this so we want to send them an a promotional email saying hey uh like here's a discount don't please don't go. Um so in hope that we will retain these customers. So here's the project description and we cover just enough theory to finish the project right and you don't need more and this project based learning I think it's the best um learning because otherwise you risk of going too deep into some things and spend too much time on that. So this is how I think you should balance learning. So you kind of need both tools and understanding the core ML concepts but you need just enough to reach the goal you have in mind but then you do this you complete the project and you have another project and then you kind of continue right um for me also Kaggle helped. So on Kaggle uh the goal was to compete in the in a competition right to have a good model and then for that I needed to learn things and because um you also have a job so you cannot spend a lot of time on Kaggle so your time is restricted and you try to do okay what is the most efficient use of my time right so for me it was personally it for me personally it was super helpful to uh and there I also balanced learning the tools versus understanding the corl concept cuz I was really focusing on the competition. Uh both homeworks and projects are mandatory to receive the certificate. No. Uh so only projects are mandatory for the certificates. The homeworks are not. It's up to you if you want to spend time on them or not. Um the homeworks are graded automatically. So the homeworks they're typically multiple choice questions. So this is how they or\"}\n",
      "31:59 {'start': '31:59', 'end': '34:46', 'text': \"view with pastor. So many good things happened to pastor after he shared the the learning after he learned in public. So uh we encourage you to do this and then we have this leaderboard. Okay. So yeah, once the course starts, you will have um these lessons with deadlines. Uh these deadlines will change as we go along the course because some things happen. Um sometimes there are delays. Uh yeah, but at the beginning we give you a rough uh schedule. So then you can some do some planning. Are there zoom lectures or live sessions on YouTube and learning while learning and what time? So all the things are pre-recorded. We will have one live stream for the launch and that's it. So we used to have um we used to have office hours. Right now I don't see any point in uh doing these office hours cuz we have done these office hours in the past. All the questions that people had I answered. So you can just rewatch the old office hours videos. Uh so there will be no live sessions. Um, you just watch pre-recorded videos and then you interact with others in Slack. Uh, yeah, I think I just answered that. Is it best to use a Kaggle data set or to find one ourselves? Is it a question about the project? Um, like Kaggle is a good platform for data sets, but it's not the only source. You can find data sets in other places too. So, It doesn't matter actually. I answered that question. Would you do a data science to camp? No. Uh I mean this one is kind of data scienceish cuz uh if we look at the syllabus, we have uh one, two, three, four, five, six modules. Did I correctly? One, two, three, four, five, six. Yeah, six modules or seven uh that are about data science. I think that's enough. Yeah, I don't see a point in creating another course just for that. So, it will be like the same material. Uh will we will we deploy ML models locally or use remote environment both? Um actually for the course uh for the project of the course you will get extra point if you deploy to the cloud uh but also I know some of you cannot um for\"}\n"
     ]
    }
   ],
   "source": [
    "# fetch docs if needed\n",
    "from elasticsearch import NotFoundError\n",
    "\n",
    "for _id in fused:\n",
    "    try:\n",
    "        src = es_client.get(index=index_name, id=_id)\n",
    "    except NotFoundError:\n",
    "        try:\n",
    "            src = es_client.get(index=VINDEX, id=_id)\n",
    "        except NotFoundError:\n",
    "            src = None\n",
    "    print(_id, (src or {}).get(\"_source\", {}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34924486",
   "metadata": {},
   "source": [
    "# Index & Mapping Cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be41927",
   "metadata": {},
   "source": [
    "## A1) Lexical (BM25) index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "{\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"filter\": {\n",
    "        \"en_stem\": { \"type\": \"stemmer\", \"language\": \"light_english\" }\n",
    "      },\n",
    "      \"analyzer\": {\n",
    "        \"my_english\": {\n",
    "          \"type\": \"custom\",\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\"lowercase\",\"stop\",\"en_stem\"]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"id\":   { \"type\": \"keyword\" },\n",
    "      \"title\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"my_english\",\n",
    "        \"fields\": { \"raw\": { \"type\": \"keyword\", \"ignore_above\": 2048 } }\n",
    "      },\n",
    "      \"body\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"my_english\",\n",
    "        \"fields\": { \"raw\": { \"type\": \"keyword\", \"ignore_above\": 4096 } }\n",
    "      },\n",
    "      \"tags\": { \"type\": \"keyword\" },        # for filters\n",
    "      \"created_at\": { \"type\": \"date\" }      # for ranges/sorts\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25a3a1c",
   "metadata": {},
   "source": [
    "## A2) Vector (k-NN) index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593bfdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "{\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"id\":   { \"type\": \"keyword\" },\n",
    "      \"text\": { \"type\": \"text\" },       # optional if you also want lexical\n",
    "      \"emb\":  {\n",
    "        \"type\": \"dense_vector\",\n",
    "        \"dims\": 384,                    # match your model\n",
    "        \"index\": true,                  # enable ANN\n",
    "        \"similarity\": \"cosine\"          # or \"dot_product\" / \"l2_norm\"\n",
    "      },\n",
    "      \"tags\": { \"type\": \"keyword\" }\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea666f8",
   "metadata": {},
   "source": [
    "## A3) One index for Hybrid (lexical + vector)\n",
    "\n",
    "Goal: keep text + vector side-by-side so you can use single-request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb48d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"my_english\": { \"type\":\"custom\", \"tokenizer\":\"standard\", \"filter\":[\"lowercase\",\"stop\"] }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"id\":   { \"type\": \"keyword\" },\n",
    "      \"text\": { \"type\": \"text\", \"analyzer\":\"my_english\" },\n",
    "      \"emb\":  { \"type\": \"dense_vector\", \"dims\": 384, \"index\": true, \"similarity\": \"cosine\" },\n",
    "      \"tags\": { \"type\": \"keyword\" },\n",
    "      \"created_at\": { \"type\": \"date\" }\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6328cc51",
   "metadata": {},
   "source": [
    "# Query Cheatsheet (Parameters that matter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8dda9",
   "metadata": {},
   "source": [
    "## B1) Lexical (BM25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f796eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic relevance\n",
    "{\n",
    "  \"size\": 10,\n",
    "  \"query\": { \"match\": { \"body\": \"machine learning zoom camp\" } }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering (exact fields don’t affect score)\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": { \"match\": { \"body\": \"registration details\" } },\n",
    "      \"filter\": [\n",
    "        { \"term\": { \"tags\": \"course\" } },\n",
    "        { \"range\": { \"created_at\": { \"gte\": \"2025-01-01\" } } }\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"sort\": [{ \"created_at\": \"desc\" }]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba699b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlighting\n",
    "\"highlight\": { \"fields\": { \"body\": {} } }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83346ff3",
   "metadata": {},
   "source": [
    "## B2) Vector (k-NN)\n",
    "ANN (k-NN) query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104055a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "{\n",
    "  \"knn\": {\n",
    "    \"field\": \"emb\",\n",
    "    \"query_vector\": [/* 384-d numbers */],\n",
    "    \"k\": 10,                 # results to return\n",
    "    \"num_candidates\": 200    # breadth; ↑ for recall (slower)\n",
    "  },\n",
    "  \"_source\": [\"id\",\"text\",\"tags\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f9990",
   "metadata": {},
   "source": [
    "Knobs\n",
    "\n",
    "k: top-K by similarity to return.\n",
    "\n",
    "num_candidates: how many candidates to consider before picking top-k (↑ recall, ↑ latency).\n",
    "\n",
    "similarity: set at mapping (cosine/dot/l2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24893610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector + filter (narrow the candidate pool)\n",
    "{\n",
    "  \"knn\": {\n",
    "    \"field\": \"emb\",\n",
    "    \"query_vector\": [/* ... */],\n",
    "    \"k\": 10,\n",
    "    \"num_candidates\": 300,\n",
    "    \"filter\": { \"term\": { \"tags\": \"course\" } }\n",
    "  }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
