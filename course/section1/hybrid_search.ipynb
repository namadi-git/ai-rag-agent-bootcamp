{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8185e26",
   "metadata": {},
   "source": [
    "## 1) Easiest: LangChain (0.3.x) with EnsembleRetriever (RRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c46f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain langchain-community langchain-openai chromadb rank_bm25\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=\"The Houston Rockets play at Toyota Center.\"),\n",
    "    Document(page_content=\"NBA fantasy values high-usage players.\"),\n",
    "    Document(page_content=\"Chroma is a local vector database.\"),\n",
    "]\n",
    "\n",
    "# BM25 (in-memory)\n",
    "bm25 = BM25Retriever.from_documents(docs)\n",
    "bm25.k = 5\n",
    "\n",
    "# Vector (Chroma)\n",
    "emb = OpenAIEmbeddings()\n",
    "chroma = Chroma.from_documents(docs, embedding=emb)\n",
    "vec = chroma.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Hybrid via Reciprocal Rank Fusion (built-in)\n",
    "hybrid = EnsembleRetriever(retrievers=[bm25, vec], weights=[0.5, 0.5])  # tweak weights\n",
    "\n",
    "# Use like any retriever\n",
    "results = hybrid.get_relevant_documents(\"Where do the Rockets play?\")\n",
    "for d in results:\n",
    "    print(d.page_content, d.metadata if d.metadata else \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56eb6b",
   "metadata": {},
   "source": [
    "Why this is nice: minimal code; EnsembleRetriever uses Reciprocal Rank Fusion (RRF) under the hood (robust, no score normalization needed). You can swap Chroma for FAISS/Pinecone easily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9266698a",
   "metadata": {},
   "source": [
    "## 2) DIY fusion (FAISS + BM25) with RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a82c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence-transformers faiss-cpu rank_bm25\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np, faiss\n",
    "\n",
    "texts = [\n",
    "    \"The Houston Rockets play at Toyota Center.\",\n",
    "    \"NBA fantasy values high-usage players.\",\n",
    "    \"Chroma is a local vector database.\",\n",
    "]\n",
    "\n",
    "# ---- BM25 candidates ----\n",
    "tok = [t.lower().split() for t in texts]\n",
    "bm25 = BM25Okapi(tok)\n",
    "q = \"Where do the Rockets play?\"\n",
    "bm25_scores = bm25.get_scores(q.lower().split())  # length N\n",
    "\n",
    "# ---- Vector candidates ----\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "X = model.encode(texts, normalize_embeddings=True)\n",
    "d = X.shape[1]\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(X)\n",
    "qv = model.encode([q], normalize_embeddings=True)\n",
    "vec_scores, vec_idxs = index.search(qv, k=len(texts))\n",
    "vec_scores = vec_scores[0]  # length N but ordered by vec rank\n",
    "vec_order = vec_idxs[0]     # indices in rank order\n",
    "\n",
    "# ---- RRF fusion ----\n",
    "def rrf(ranks, k=60):\n",
    "    return 1.0 / (k + ranks)  # ranks start at 1\n",
    "\n",
    "# Build rank maps for each method\n",
    "bm25_rank = np.argsort(np.argsort(-bm25_scores)) + 1  # 1..N\n",
    "vec_rank = np.empty_like(bm25_rank)\n",
    "vec_rank[vec_order] = np.arange(1, len(texts)+1)\n",
    "\n",
    "alpha = 0.5  # weight BM25 vs vector\n",
    "fusion = alpha*rrf(bm25_rank) + (1-alpha)*rrf(vec_rank)\n",
    "\n",
    "# Final ranking\n",
    "final_order = np.argsort(-fusion)\n",
    "for i in final_order:\n",
    "    print(f\"{texts[i]} | fused={fusion[i]:.4f} (bm25={bm25_scores[i]:.3f}, vec-rank={vec_rank[i]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee6378",
   "metadata": {},
   "source": [
    "Why RRF? It’s stable across scales (no messy score normalization). Tune alpha if you want to bias toward exact terms (BM25) or semantics (vector)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca0ab6",
   "metadata": {},
   "source": [
    " ## 3) Elasticsearch/OpenSearch (BM25 + kNN) with app-side fusion\n",
    "\n",
    "Elasticsearch/OpenSearch don’t always natively fuse BM25 and kNN into one score. A reliable approach is two queries + fuse in app (again, RRF or normalized sum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59cda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install elasticsearch sentence-transformers\n",
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "index = \"docs\"\n",
    "\n",
    "# 1) BM25 search\n",
    "q = \"Where do the Rockets play?\"\n",
    "bm25_res = es.search(index=index, query={\"match\": {\"text\": q}}, size=50)\n",
    "bm25_hits = bm25_res[\"hits\"][\"hits\"]  # each has _id and _score\n",
    "\n",
    "# 2) kNN search\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "qv = model.encode([q])[0].tolist()\n",
    "knn_res = es.search(index=index, knn={\"field\":\"emb\",\"query_vector\":qv,\"k\":50,\"num_candidates\":200})\n",
    "knn_hits = knn_res[\"hits\"][\"hits\"]\n",
    "\n",
    "# 3) Fuse with RRF\n",
    "def ranks(hits):\n",
    "    # map doc_id -> rank (1..)\n",
    "    return {h[\"_id\"]: r+1 for r, h in enumerate(hits)}\n",
    "\n",
    "r_bm25 = ranks(sorted(bm25_hits, key=lambda h: -h[\"_score\"]))\n",
    "r_knn  = ranks(knn_hits)  # already rank-ordered for kNN\n",
    "\n",
    "def rrf_score(doc_id, k=60):\n",
    "    return (1/(k + r_bm25.get(doc_id, 10**6))) + (1/(k + r_knn.get(doc_id, 10**6)))\n",
    "\n",
    "doc_ids = {h[\"_id\"] for h in bm25_hits} | {h[\"_id\"] for h in knn_hits}\n",
    "fused = sorted(doc_ids, key=lambda d: -rrf_score(d))\n",
    "\n",
    "print(fused[:10])  # top IDs; fetch full docs if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21a59be",
   "metadata": {},
   "source": [
    "Tuning tips (works for all approaches)\n",
    "\n",
    "- k (top-k per channel): start 20–50 each, fuse, then return top 5–10.\n",
    "\n",
    "- RRF k constant: 60 is common; bigger softens rank differences.\n",
    "\n",
    "- Bias toward BM25 (exact names/codes)? increase BM25 weight (e.g., weights=[0.7, 0.3] or higher alpha).\n",
    "\n",
    "- Add a re-ranker: After fusion top-50, run a cross-encoder (e.g., ms-marco-MiniLM-L-6-v2) to pick the final top-k—big precision boost.\n",
    "\n",
    "- Filters: apply metadata/date/type filters before fusion to cut noise.\n",
    "\n",
    "- Chunking: ~200–500 tokens + small overlap tends to help vector recall without diluting meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b7474e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
