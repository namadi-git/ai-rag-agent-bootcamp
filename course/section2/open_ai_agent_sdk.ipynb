{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c223cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from typing import List, Dict, Any, Optional\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafacbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae83cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7236b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load webpage in a simple markdown format\n",
    "\n",
    "import requests\n",
    "\n",
    "def get_page_content(url):\n",
    "    reader_url_prefix = 'https://r.jina.ai/'\n",
    "    request_url = reader_url_prefix + url\n",
    "    response = requests.get(request_url)\n",
    "    return response.content.decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432fefe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Welcome to DataTalks.Club\n",
      "\n",
      "URL Source: https://datatalks.club/\n",
      "\n",
      "Published Time: Thu, 16 Oct 2025 09:40:58 GMT\n",
      "\n",
      "Markdown Content:\n",
      "Welcome to DataTalks.Club\n",
      "\n",
      "===============\n",
      "\n",
      "AI Dev Tools Zoomcamp: Learn AI-powered coding assistants and agents[Register here!](https://airtable.com/appJRFiWKHBgmEt70/shrpw7rk55Ewr1jCG)\n",
      "\n",
      "DataTalks.Club\n",
      "--------------\n",
      "\n",
      "[Articles](https://datatalks.club/articles.html)[Slack](https://datatalks.club/slack.html)[Events](https://datatalks.club/events.html)[Podcast](https://datatalks.club/podcast.html)[Books](https://datatalks.club/books.html)[Courses](https://datatalks.club/blog/guide-to-free-online-courses-at-datatalks-club.html)\n",
      "\n",
      "* * *\n",
      "\n",
      "The place to talk about data\n",
      "============================\n",
      "\n",
      "Global online community of data science professionals, ML engineers, and AI practitioners\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Subscribe to our weekly newsletter and join our Slack.\n",
      "\n",
      " We'll keep you informed about everything happening in the Club.\n",
      "\n",
      "Email \n",
      "\n",
      " Join \n",
      "\n",
      " You'll get an invite within 3 minutes \n",
      "\n",
      "![Image 4: Data science discussions and talks](https://datatalks.club/images/landing/talks.jpg)\n",
      "\n",
      "#### Talk about data, machine\n",
      "\n",
      " learning, and engineering\n",
      "\n",
      "![Image 5: Data science events and courses](https://datatalks.club/images/landing/events.jpg)\n",
      "\n",
      "#### Attend weekly events\n",
      "\n",
      " and learn from free courses\n",
      "\n",
      "![Image 6: Career guidance and mentorship](https://datatalks.club/images/landing/career.jpg)\n",
      "\n",
      "#### Ask career questions and\n",
      "\n",
      " discuss career options\n",
      "\n",
      "* * *\n",
      "\n",
      "#### Upcoming events\n",
      "\n",
      "*   [How to Build and Evaluate AI systems in the Age of LLMs](https://luma.com/w65omumd) on 21 Oct 2025 by [Hugo Bowne-Anderson](https://datatalks.club/people/hugobowneanderson.html)\n",
      "*   [Deep Learning with PyTorch](https://luma.com/vc02zy6a) on 21 Oct 2025 by [Alexey Grigorev](https://datatalks.club/people/alexeygrigorev.html)\n",
      "*   [From Black-Box Systems to Augmented Decision-Making](https://luma.com/gqmsx9zd) on 28 Oct 2025 by [Anusha Akkina](https://datatalks.club/people/anushaakkina.html)\n",
      "*   [Practical guide: Fine-tuning Qwen3 with LoRA](https://luma.com/n41kqkfh) on 30 Oct 2025 by [Ivan Potapov](https://datatalks.club/people/ivanpotapov.html)\n",
      "*   [AI Dev Tools Zoomcamp 2025 Pre-Course Live Q&A](https://luma.com/6p356li5) on 04 Nov 2025 by [Alexey Grigorev](https://datatalks.club/people/alexeygrigorev.html)\n",
      "*   [Reinventing a Career in Tech](https://luma.com/ifmqg2xb) on 17 Nov 2025 by [Xia He-Bleinagel](https://datatalks.club/people/xiahebleinagel.html)\n",
      "*   [AI Dev Tools Zoomcamp 2025 Course Launch](https://luma.com/80ve8r1u) on 18 Nov 2025 by [Alexey Grigorev](https://datatalks.club/people/alexeygrigorev.html)\n",
      "*   [The Future of AI Agents](https://luma.com/0s0dcpdl) on 10 Feb 2026 by [Aditya Gautam](https://datatalks.club/people/adityagautam.html)\n",
      "\n",
      "Check [events](https://datatalks.club/events.html) for all past events. You can also subscribe to [our Google calendar](https://calendar.google.com/calendar/?cid=ZjhxaWRqbnEwamhzY3A4ODA5azFlZ2hzNjBAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ) to get notified about all our events.\n",
      "\n",
      "#### Latest podcast episodes\n",
      "\n",
      "*   [Lessons from Two Decades of AI](https://datatalks.club/podcast/s21e07-lessons-from-two-decades-of-ai.html) with [Micheal Lanham](https://datatalks.club/people/micheallanham.html)\n",
      "*   [From Astronomy to Applied ML](https://datatalks.club/podcast/s21e05-from-astronomy-to-applied-ml.html) with [Daniel Egbo](https://datatalks.club/people/danielegbo.html)\n",
      "*   [From Medicine to Machine Learning: How Public Learning Turned into a Career](https://datatalks.club/podcast/s21e03-from-medicine-to-machine-learning-how-public-learning-turned-into-career.html) with [Pastor Soto](https://datatalks.club/people/pastorsoto.html)\n",
      "*   [Mindful Data Strategy: From Pipelines to Business Impact](https://datatalks.club/podcast/s21e02-mindful-data-strategy-from-pipelines-to-business-impact.html) with [Lior Barak](https://datatalks.club/people/liorbarak.html)\n",
      "*   [From Simulation Algorithms to Production-Grade Data Systems](https://datatalks.club/podcast/s21e01-from-simulation-algorithms-to-production-grade-data-systems.html) with [Orell Garten](https://datatalks.club/people/orellgarten.html)\n",
      "\n",
      "Check the [podcast](https://datatalks.club/podcast.html) page for all past podcast episodes.\n",
      "\n",
      "#### Our Sponsors\n",
      "\n",
      "[![Image 7: dltHub](https://datatalks.club/images/partners/dlthub.png)](https://dlthub.com/)\n",
      "\n",
      "[![Image 8: Astronomer](https://datatalks.club/images/partners/astronomer.png)](https://www.astronomer.io/)\n",
      "\n",
      "[![Image 9: Arize AI](https://datatalks.club/images/partners/arize.png)](https://arize.com/model-monitoring/)\n",
      "\n",
      "#### Book of the week\n",
      "\n",
      "Check the [book of the week](https://datatalks.club/books.html) page for more books!\n",
      "\n",
      "#### Latest articles\n",
      "\n",
      "*   [AI Dev Tools Zoomcamp 2025: Free Course to Master Coding Assistants, Agents, and Automation](https://datatalks.club/blog/ai-dev-tools-zoomcamp-2025-free-course-to-master-coding-assistants-agents-and-automation.html) by [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\n",
      "*   [20+ Best Data Science Slack Communities to Join in 2025](https://datatalks.club/blog/slack-communities.html) by [Alexey Grigorev](https://datatalks.club/people/alexeygrigorev.html), [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\n",
      "*   [A Guide to Free Online Courses at DataTalks.Club](https://datatalks.club/blog/guide-to-free-online-courses-at-datatalks-club.html) by [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\n",
      "*   [Data Engineering Zoomcamp 2026: Free Data Engineering Course and Certification](https://datatalks.club/blog/data-engineering-zoomcamp.html) by [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\n",
      "*   [ML Zoomcamp 2025: Free Machine Learning Engineering Course and Certification](https://datatalks.club/blog/machine-learning-zoomcamp.html) by [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\n",
      "\n",
      "* * *\n",
      "\n",
      " DataTalks.Club. Hosted on [GitHub Pages](https://github.com/DataTalksClub/datatalksclub.github.io). We use cookies.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_page_content('https://datatalks.club'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ded99d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create tool to fetch content of webpage in markdown\n",
    "reader_url_prefix = \"https://r.jina.ai/\"\n",
    "\n",
    "def get_page_content(url: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fetch the Markdown content of a web page using the Jina Reader service.\n",
    "\n",
    "    This function prepends the Jina Reader proxy URL to the provided `url`,\n",
    "    sends a GET request with a timeout, and decodes the response as UTF-8 text.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the page to fetch.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The Markdown-formatted content of the page if the request\n",
    "        succeeds; otherwise, None.\n",
    "\n",
    "    Raises:\n",
    "        None: All network or decoding errors are caught and suppressed.\n",
    "               Logs or error messages could be added as needed.\n",
    "    \"\"\"\n",
    "    reader_url = reader_url_prefix + url\n",
    "\n",
    "    try:\n",
    "        response = requests.get(reader_url, timeout=10)\n",
    "        response.raise_for_status()  # raises for 4xx/5xx HTTP errors\n",
    "        return response.content.decode(\"utf-8\")\n",
    "    except (requests.exceptions.RequestException, UnicodeDecodeError) as e:\n",
    "        # Optional: log or print the error for debugging\n",
    "        print(f\"Error fetching content from {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e55e77",
   "metadata": {},
   "source": [
    "## Configure the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1633f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, function_tool, SQLiteSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8e941ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_instructions = \"\"\"\n",
    "You're a helpful assistant that helps answer user questions.\n",
    "\"\"\"\n",
    "\n",
    "assistant = Agent(\n",
    "    name='assistant', #name of the agent\n",
    "    tools=[function_tool(get_page_content)], # tools available to agent\n",
    "    instructions=assistant_instructions, # agent system instruction\n",
    "    model='gpt-4o-mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b4b089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the agent, we need a Runner:\n",
    "\n",
    "runner_session1= SQLiteSession(\"my_chat_1\", \"../sqlite_db/conv.db\")  # persist history\n",
    "runner = Runner()\n",
    "user_prompt = \"Summarize the content of https://openai.github.io/openai-agents-python/\"\n",
    "result = await runner.run(assistant, input=user_prompt, session= runner_session1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a221a9e",
   "metadata": {},
   "source": [
    "The result contains extensive information about the conversation, including all tool calls and responses.\n",
    "\n",
    "Let's check new_items in results. That's all the communication between OpenAI and us, including all the tool calls. The last item should be the message with the final response:\n",
    "\n",
    "final result is saved in [-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "066535e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The **OpenAI Agents SDK** is a Python library designed to create agentic AI applications effortlessly. It is built on previous experiments and aims for a user-friendly experience using a minimal set of primitives, such as:\n",
      "\n",
      "- **Agents**: LLMs equipped with instructions and tools.\n",
      "- **Handoffs**: Mechanisms for agents to delegate tasks.\n",
      "- **Guardrails**: Features for validating inputs and outputs.\n",
      "- **Sessions**: Management of conversation history automatically across runs.\n",
      "\n",
      "Key features include a built-in agent loop, easy orchestration using Python, and tools for visualizing and debugging workflows. The SDK is installation-friendly with a simple `pip install openai-agents` command and provides tutorials, examples, and extensive documentation. \n",
      "\n",
      "A basic \"Hello World\" example illustrates setting up an agent and running it to generate output, showcasing the SDK's simplicity.\n",
      "\n",
      "For more details, you can explore its [official documentation](https://openai.github.io/openai-agents-python/).\n"
     ]
    }
   ],
   "source": [
    "print(result.new_items[-1].raw_item.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d756671e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The **OpenAI Agents SDK** is a Python library designed to create agentic AI applications effortlessly. It is built on previous experiments and aims for a user-friendly experience using a minimal set of primitives, such as:\n",
      "\n",
      "- **Agents**: LLMs equipped with instructions and tools.\n",
      "- **Handoffs**: Mechanisms for agents to delegate tasks.\n",
      "- **Guardrails**: Features for validating inputs and outputs.\n",
      "- **Sessions**: Management of conversation history automatically across runs.\n",
      "\n",
      "Key features include a built-in agent loop, easy orchestration using Python, and tools for visualizing and debugging workflows. The SDK is installation-friendly with a simple `pip install openai-agents` command and provides tutorials, examples, and extensive documentation. \n",
      "\n",
      "A basic \"Hello World\" example illustrates setting up an agent and running it to generate output, showcasing the SDK's simplicity.\n",
      "\n",
      "For more details, you can explore its [official documentation](https://openai.github.io/openai-agents-python/).\n"
     ]
    }
   ],
   "source": [
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf91b87",
   "metadata": {},
   "source": [
    "## Youtube transcript summary agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5abf8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's how we get a transcript\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "def format_timestamp(seconds: float) -> str:\n",
    "    \"\"\"Convert seconds to H:MM:SS if > 1 hour, else M:SS\"\"\"\n",
    "    total_seconds = int(seconds)\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, secs = divmod(remainder, 60)\n",
    "\n",
    "    if hours > 0:\n",
    "        return f\"{hours}:{minutes:02}:{secs:02}\"\n",
    "    else:\n",
    "        return f\"{minutes}:{secs:02}\"\n",
    "\n",
    "\n",
    "def make_subtitles(transcript) -> str:\n",
    "    lines = []\n",
    "\n",
    "    for entry in transcript:\n",
    "        ts = format_timestamp(entry.start)\n",
    "        text = entry.text.replace('\\n', ' ')\n",
    "        lines.append(ts + ' ' + text)\n",
    "\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "def fetch_transcript_raw(video_id):\n",
    "    ytt_api = YouTubeTranscriptApi()\n",
    "    transcript = ytt_api.fetch(video_id)\n",
    "    return transcript\n",
    "\n",
    "\n",
    "def fetch_transcript_text(video_id):\n",
    "    transcript = fetch_transcript_raw(video_id)\n",
    "    subtitles = make_subtitles(transcript)\n",
    "    return subtitles  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888a787b",
   "metadata": {},
   "source": [
    "We don't want to re-download the transcripts every time. Let's use the /data_cache/youtube_videos/ folder as cache:\n",
    "\n",
    "First check if the folder has the YouTube video\n",
    "\n",
    "If it does, simply return the file content\n",
    "\n",
    "If it doesn't, fetch the transcript and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67bb1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def fetch_transcript_cached(video_id):\n",
    "    cache_dir = Path(\"../data_cache/youtube_videos\")\n",
    "    cache_file = cache_dir / f\"{video_id}.txt\"\n",
    "\n",
    "    if cache_file.exists():\n",
    "        return cache_file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    subtitles = fetch_transcript_text(video_id)\n",
    "    cache_file.write_text(subtitles, encoding=\"utf-8\")\n",
    "\n",
    "    return subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fc8ce2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00 Hey everyone, welcome to our event. This\n",
      "0:02 event is brought to you by data talks\n",
      "0:03 club which is a community of people who\n",
      "0:05 love data. We have weekly events today.\n",
      "0:08 Uh this is one of such events. Um if you\n",
      "0:11 want to find out more about the events\n",
      "0:13 we have, there is a link in the\n",
      "0:14 description. Um so click on that link,\n",
      "0:16 check it out right now. We actually have\n",
      "0:19 quite a few events in our pipeline, but\n",
      "0:21 we need to put them on the website. Uh\n",
      "0:24 but keep a\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "subtitles = fetch_transcript_cached('vK_SxyqIfwk')\n",
    "print(subtitles[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf35e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the fetch youtube transcript tool with docstring\n",
    "def fetch_youtube_transcript(video_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the transcript of a YouTube video and converts it into a subtitle-formatted string.\n",
    "\n",
    "    Args:\n",
    "        video_id (str): The unique YouTube video ID.\n",
    "\n",
    "    Returns:\n",
    "        str: The subtitles generated from the video's transcript.\n",
    "    \"\"\"\n",
    "    return fetch_transcript_cached(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "101d9ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_instructions = \"\"\"\n",
    "You're a helpful assistant that helps answer user questions\n",
    "about YouTube videos\n",
    "\"\"\"\n",
    "\n",
    "tools = [\n",
    "    function_tool(fetch_youtube_transcript)\n",
    "]\n",
    "\n",
    "youtube_assistant = Agent(\n",
    "    name='youtube_assistant',\n",
    "    tools=tools,\n",
    "    instructions=summary_instructions,\n",
    "    model='gpt-4o-mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12eaf1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the agent, we need a Runner:\n",
    "\n",
    "runner_session2= SQLiteSession(\"my_chat_2\", \"../sqlite_db/conv.db\")  # persist history\n",
    "runner = Runner()\n",
    "user_prompt = \"what is this video about https://www.youtube.com/watch?v=nMrGK5QgPVE\"\n",
    "result = await runner.run(assistant, input=user_prompt, session= runner_session1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e28b107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video titled **\"Implement a Search Engine\"** by Alexey Grigorev is a hands-on tutorial focused on building a search engine using text and vector search methods. It covers various aspects, including:\n",
      "\n",
      "1. **Overview of Retrieval-Augmented Generation**: Introduction to the concept and its applications.\n",
      "2. **Creating a Sample Search Engine**: Explanation of an in-memory index and a simple search engine.\n",
      "3. **Setting Up the Environment**: Guidance on installing necessary libraries for development.\n",
      "4. **Implementing Text Search**: Using tools like scikit-learn to facilitate text search.\n",
      "5. **Combining Scores from Queries**: Techniques for weighting different fields in search results.\n",
      "6. **Creating a Text Search Class**: Organizing code for search implementations.\n",
      "7. **Introduction to Vector Search**: Discussing dimensionality reduction and its relevance in search.\n",
      "8. **Using BERT for Embeddings**: Explanation of how transformers are used for embedding text data.\n",
      "\n",
      "The tutorial emphasizes practical implementation and provides resources for further learning.\n"
     ]
    }
   ],
   "source": [
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e8cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09cdf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
