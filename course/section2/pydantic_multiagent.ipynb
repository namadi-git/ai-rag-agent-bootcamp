{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5f5da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26fff67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from minsearch import Index\n",
    "\n",
    "import docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e70567b",
   "metadata": {},
   "source": [
    "## Data load and prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f64967b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348dc0018464416596c325789d815486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "data_folder = Path('../data_cache/youtube_videos/')\n",
    "\n",
    "for f in tqdm(data_folder.glob('*.txt')):\n",
    "    filename = f.name\n",
    "    video_id, _ = filename.split('.')\n",
    "\n",
    "    transcript = f.read_text(encoding='utf-8')\n",
    "\n",
    "    chunks = docs.sliding_window(transcript, size=3000, step=1500)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        chunk['video_id'] = video_id\n",
    "        documents.append(chunk)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b64b1a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x250ceab1d00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = Index(\n",
    "    text_fields=['content'],\n",
    "    keyword_fields=['video_id']\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9e739a",
   "metadata": {},
   "source": [
    "## Search Function Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1afd9bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, TypedDict, Optional\n",
    "\n",
    "class SearchResult(TypedDict):\n",
    "    \"\"\"Represents a single search result entry.\"\"\"\n",
    "    start: int\n",
    "    content: str\n",
    "    video_id: str\n",
    "    _id: int # added\n",
    "\n",
    "class SearchTools:\n",
    "\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "        \n",
    "    def search(self, query: str) -> List[SearchResult]:\n",
    "        \"\"\"\n",
    "        Search the index for documents matching the given query.\n",
    "    \n",
    "        Args:\n",
    "            query (str): The search query string.\n",
    "    \n",
    "        Returns:\n",
    "            List[SearchResult]: A list of search results. Each result dictionary contains:\n",
    "                - start (int): The starting position or offset within the source file.\n",
    "                - content (str): A text excerpt or snippet containing the match.\n",
    "                - video_id (str): Youtube video_id for the snippet.\n",
    "                - _id (int): The unique id for the document\n",
    "        \"\"\"\n",
    "        return self.index.search(\n",
    "            query=query,\n",
    "            num_results=5,\n",
    "            output_ids=True,\n",
    "        )\n",
    "\n",
    "    def get_document_by_id(self, _id: int) -> Optional[SearchResult]:\n",
    "        \"\"\"\n",
    "        Retrieve a document by its unique ID.\n",
    "\n",
    "        Args:\n",
    "            _id (int): The document id.\n",
    "\n",
    "        Returns:\n",
    "            SearchResult: The document corresponding to the given ID or None if it's not in the index.\n",
    "        \"\"\"\n",
    "        if _id < 0 or _id >= len(self.index.docs):\n",
    "            return None\n",
    "\n",
    "        return self.index.docs[_id]\n",
    "\n",
    "tools = SearchTools(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bd6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.messages import FunctionToolCallEvent, FunctionToolResultEvent\n",
    "\n",
    "class NamedCallback:\n",
    "\n",
    "    def __init__(self, agent):\n",
    "        self.agent_name = agent.name\n",
    "\n",
    "    async def print_function_calls(self, ctx, event):\n",
    "        # Detect nested streams\n",
    "        if hasattr(event, \"__aiter__\"):\n",
    "            async for sub in event:\n",
    "                await self.print_function_calls(ctx, sub)\n",
    "            return\n",
    "\n",
    "        if isinstance(event, FunctionToolCallEvent):\n",
    "            print(\"CALL →\", event.part.tool_name, event.part.args_as_dict(), event.tool_call_id)\n",
    "        elif isinstance(event, FunctionToolResultEvent):\n",
    "            print(\"RES  ←\", event.result.tool_name, event.tool_call_id, event.result.content)\n",
    "\n",
    "    async def __call__(self, ctx, event):\n",
    "        return await self.print_function_calls(ctx, event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db05024",
   "metadata": {},
   "source": [
    "## Clarifier Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e518810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e048363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clarifier_instructions = \"\"\"\n",
    "You are the CLARIFIER agent.\n",
    "\n",
    "ROLE\n",
    "Your job is to interpret and refine the user's research request so that it can be passed\n",
    "to the RESEARCH agent for structured exploration.\n",
    "\n",
    "OBJECTIVES\n",
    "1. Understand what the user truly wants to learn or achieve (their intent).\n",
    "2. Identify the core topic and any implicit goals (e.g., learn, compare, evaluate, predict, build).\n",
    "3. Ask the user one targeted clarification question — to confirm scope, focus, or purpose.\n",
    "4. Once the user responds, synthesize a refined version of their request that includes:\n",
    "   - The clarified intent (what the user ultimately wants)\n",
    "   - The initial request (in their own words)\n",
    "   - The refined research focus (a precise version suitable for the RESEARCH agent)\n",
    "   - 3–7 search queries that capture the clarified scope and intent\n",
    "   - A short instruction summary for the RESEARCH agent explaining what to explore\n",
    "\n",
    "DATA SOURCES\n",
    "- You may use your own general knowledge to infer user intent.\n",
    "- You may use the `search()` tool to quickly check ambiguous terms or context.\n",
    "\n",
    "CONSTRAINTS\n",
    "- Ask the user for clarification **once only**.\n",
    "- Do not fabricate information; if uncertain, clarify directly with the user.\n",
    "- The goal is to output a structured handoff ready for the RESEARCH agent's Stage 1 process.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42513c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchInstructions(BaseModel):\n",
    "    \"\"\"\n",
    "    Output of the CLARIFIER agent.\n",
    "    Provides both the user's raw input and the refined, structured guidance\n",
    "    for the RESEARCH agent to begin its first stage.\n",
    "    \"\"\"\n",
    "    initial_request: str = Field(\n",
    "        ...,\n",
    "        description=\"The user's original question or request, captured verbatim.\"\n",
    "    )\n",
    "    refined_request: str = Field(\n",
    "        ...,\n",
    "        description=\"A clarified, rephrased, and contextually grounded version of the initial request.\"\n",
    "    )\n",
    "    user_intent: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"A short summary (1–2 sentences) of what the user truly wants to accomplish \"\n",
    "            \"or learn, inferred from both the initial request and clarification.\"\n",
    "        )\n",
    "    )\n",
    "    queries: List[str] = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"A list of 3–7 specific search queries derived from the refined request, \"\n",
    "            \"covering complementary angles or subtopics the RESEARCH agent should explore.\"\n",
    "        )\n",
    "    )\n",
    "    instructions: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"Concise operational guidance for the RESEARCH agent, explaining how to use \"\n",
    "            \"the queries and what to prioritize during Stage 1 research.\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0177ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clarifier = Agent(\n",
    "    name='clarifier',\n",
    "    instructions=clarifier_instructions,\n",
    "    tools=[tools.search],\n",
    "    model='gpt-4o-mini',\n",
    ")\n",
    "\n",
    "clarifier_callback = NamedCallback(clarifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15584b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how do I get started with data engineering\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "454148b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clarifier_results1 = await clarifier.run(\n",
    "    user_prompt=question,\n",
    "    event_stream_handler=clarifier_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93df9fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To better assist you, could you clarify whether you are looking for information on specific skills and tools within data engineering, a learning pathway or resources, or perhaps insights on how to transition into a data engineering role?\n"
     ]
    }
   ],
   "source": [
    "print(clarifier_results1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2040c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"I want a learning path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1f45264",
   "metadata": {},
   "outputs": [],
   "source": [
    "clarifier_results2 = await clarifier.run(\n",
    "    user_prompt=answer,\n",
    "    message_history=clarifier_results1.new_messages(),\n",
    "    output_type=ResearchInstructions,\n",
    "    event_stream_handler=clarifier_callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a03ef09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_request='how do I get started with data engineering' refined_request='I want a structured learning path to get started with data engineering.' user_intent='To obtain a clear and structured learning path for entering the field of data engineering.' queries=['data engineering learning path for beginners', 'essential skills for data engineers', 'best online courses for data engineering', 'data engineering tools and technologies', 'step-by-step guide to becoming a data engineer', 'data engineering projects for practice'] instructions='Explore various resources and structured learning paths for data engineering, focusing on beginner-friendly courses, essential skills, and practical projects.'\n"
     ]
    }
   ],
   "source": [
    "print(clarifier_results2.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be7d6772",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_task = clarifier_results2.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11ac0ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data engineering learning path for beginners',\n",
       " 'essential skills for data engineers',\n",
       " 'best online courses for data engineering',\n",
       " 'data engineering tools and technologies',\n",
       " 'step-by-step guide to becoming a data engineer',\n",
       " 'data engineering projects for practice']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clarifier_results2.output.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2665057e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explore various resources and structured learning paths for data engineering, focusing on beginner-friendly courses, essential skills, and practical projects.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clarifier_results2.output.instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca32f80",
   "metadata": {},
   "source": [
    "## Researcher Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3111b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_instructions = \"\"\"\n",
    "You are the RESEARCH agent.\n",
    "\n",
    "ROLE\n",
    "You perform structured research on a proprietary podcast/video database for a specific stage\n",
    "of exploration (Stage 1, 2, or 3).\n",
    "\n",
    "DATA SOURCE\n",
    "- You may ONLY use the `search()` function\n",
    "- Every reference must cite a real snippet with a valid `youtube_id`, `timestamp` and `_id`.\n",
    "- Do not invent data, names, or timestamps.\n",
    "\n",
    "INTENT HANDLING\n",
    "- Before searching, infer the underlying intent behind the user's request.\n",
    "  Examples:\n",
    "    - “getting into ML” → learning pathways, beginner resources, first projects\n",
    "    - “AI safety concerns” → risks, ethical challenges, mitigation strategies\n",
    "    - “startup funding trends” → investment patterns, valuations, stages\n",
    "- Generate searches that reflect this **intent**, not just literal words.\n",
    "\n",
    "STAGES\n",
    "\n",
    "Stage 1 — Initial Search\n",
    "- Use the user’s question or clarified keywords from context.\n",
    "- Identify 3–5 primary keywords, run one or more searches.\n",
    "- Summarize the main findings, highlighting initial insights and directions.\n",
    "\n",
    "Stage 2 — Expansion\n",
    "- Build upon Stage 1 outputs (from context).\n",
    "- Generate 5–7 related or complementary queries.\n",
    "- Summarize recurring ideas and patterns across new results.\n",
    "\n",
    "Stage 3 — Deep Dive\n",
    "- Build upon Stage 1 and Stage 2.\n",
    "- Generate 5–7 deeper or contrasting queries.\n",
    "- Explore nuances, counterpoints, or mechanisms.\n",
    "- Provide a more analytical synthesis.\n",
    "\n",
    "CONSTRAINTS\n",
    "- Use context from previous stages to guide deeper exploration.\n",
    "- You must perform the necessary amount of queries for each stage:\n",
    "    - 3-5 for stage 1\n",
    "    - 5-7 for stage 2\n",
    "    - 5-7 for stage 3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edb4c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reference(BaseModel):\n",
    "    \"\"\"\n",
    "    A single, verifiable citation to a transcript snippet or video segment.\n",
    "    Must correspond to a real snippet returned by the `search()` tool.\n",
    "    \"\"\"\n",
    "    document_id: int = Field(..., description=\"Internal ID of the transcript snippet.\")\n",
    "    quote: str = Field(..., description=\"Exact snippet that supports the keyword or insight.\")\n",
    "    timestamp: str = Field(..., description=\"Timestamp in the source video where the quote occurs, 'mm:ss' or 'h:mm:ss'\")\n",
    "    relevance_to_keyword: str = Field(..., description=\"Explanation of *how* this quote supports or illustrates the specific keyword or concept being explored.\")\n",
    "    relevance_to_user_intent:  str = Field(..., description=\"Explanation of *how* this quote help the user with their intent.\")\n",
    "\n",
    "class ResearchKeyword(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a keyword explicitly searched during this research stage.\n",
    "    Each keyword must match an actual query used in the search tool calls.\n",
    "    \"\"\"\n",
    "    keyword: str = Field(..., description=\"The exact keyword or phrase used in the search() tool call.\")\n",
    "    relevant_references: List[Reference] = Field(\n",
    "        ..., \n",
    "        description=\"List of transcript snippets directly relevant to this keyword. Each must include a 'relevance_to_keyword' explanation.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class VerifiableInsight(BaseModel):\n",
    "    \"\"\"\n",
    "    A synthesized insight that can be traced back to specific evidence.\n",
    "    Each insight must be supported by at least one real reference.\n",
    "    \"\"\"\n",
    "    insight: str = Field(..., description=\"An insight derived from the research, phrased in an evidence-based, verifiable way.\")\n",
    "    references: List[Reference] = Field(..., description=\"Citations that directly support this insight. Must contain valid timestamps and IDs.\")\n",
    "\n",
    "\n",
    "class ResearchStageReport(BaseModel):\n",
    "    \"\"\"\n",
    "    Structured output for each research stage (1–3).\n",
    "    Ensures traceability between searches, keywords, and findings.\n",
    "    \"\"\"\n",
    "    stage: int = Field(..., description=\"The research stage number (1 = Initial Search, 2 = Expansion, 3 = Deep Dive).\")\n",
    "    explored_keywords: List[ResearchKeyword] = Field(\n",
    "        ..., \n",
    "        description=\"List of the *exact* keywords used in this stage's search() calls, along with references showing their relevance.\"\n",
    "    )\n",
    "    verifiable_insights: List[VerifiableInsight] = Field(\n",
    "        ..., \n",
    "        description=\"List of data-backed insights derived from the references gathered at this stage.\"\n",
    "    )\n",
    "    stage_summary: str = Field(..., description=\"Analytical summary of what was learned at this stage, connecting evidence to emerging themes.\")\n",
    "    recommended_next_steps: str = Field(..., description=\"Guidance for what to do in the next stage — e.g., new angles, counterpoints, or subtopics.\")\n",
    "    recommended_next_keywords: List[str] = Field(\n",
    "        ..., \n",
    "        description=\"Suggested next queries based on gaps or promising directions discovered in this stage.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf3199c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher = Agent(\n",
    "    name='researcher',\n",
    "    instructions=researcher_instructions,\n",
    "    tools=[tools.search],\n",
    "    model='gpt-4o-mini',\n",
    "    output_type=ResearchStageReport\n",
    ")\n",
    "\n",
    "researcher_callback = NamedCallback(researcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "414906c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = 1\n",
    "stage_instructions = research_task.model_dump_json()\n",
    "previous_stages_json = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2983abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def do_research(\n",
    "    stage: int,\n",
    "    stage_instructions: str,\n",
    "    previous_stages: List[ResearchStageReport]\n",
    ") -> ResearchStageReport:\n",
    "    previous_stages_json = '\\n'.join([r.model_dump_json() for r in previous_stages])\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "    Current stage: {stage}\n",
    "\n",
    "    Stage instrustructions:\n",
    "    {stage_instructions}\n",
    "\n",
    "    Previous stages:\n",
    "    {previous_stages_json}\n",
    "    \"\"\"\n",
    "\n",
    "    callback = NamedCallback(researcher)\n",
    "\n",
    "    results = await researcher.run(\n",
    "        user_prompt=user_prompt,\n",
    "        event_stream_handler=callback,\n",
    "    )\n",
    "\n",
    "    return results.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f775af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALL → search {'query': 'data engineering learning path for beginners'} call_PzX6FWvolNVEHc7ZrC5v7H0j\n",
      "CALL → search {'query': 'essential skills for data engineers'} call_UfQjXQTMEFUGkY5hNrCtnsI3\n",
      "CALL → search {'query': 'best online courses for data engineering'} call_JLqVF7rIrXgzmSNbuHnL9Xr4\n",
      "CALL → search {'query': 'data engineering tools and technologies'} call_xvI8X4YbzzcxxgexB68km1iD\n",
      "CALL → search {'query': 'step-by-step guide to becoming a data engineer'} call_4e5AisxqtTlyluXPNH2arcT9\n",
      "RES  ← search call_UfQjXQTMEFUGkY5hNrCtnsI3 [{'start': 9000, 'content': \"a engineers like uh buy\\n9:28 the book and the way it's supposed to be\\n9:30 a difference in terms of um how you\\n9:32 process the data like big data\\n9:34 engineering requires a bit different\\n9:36 tools like heavy load\\n9:37 optimizations data engineering small\\n9:40 like\\n9:40 software engineering on the back end but\\n9:43 in reality i would say that\\n9:44 a lot of companies name big data\\n9:46 engineers as data engineers and it's\\n9:48 like constantly a bit confusing\\n9:50 because of that so many just drop the\\n9:53 big part and just\\n9:55 go with data engineer and is there any\\n9:58 difference in\\n9:59 tools uh because for example you you say\\n10:02 you mentioned spark impala\\n10:05 things like this and what i see\\n10:09 in data engineers\\n10:12 maybe is a bit different like most of\\n10:14 them use spark as well but i see\\n10:17 more cloud-based things like i don't\\n10:20 know\\n10:21 streams lambda functions and things like\\n10:24 this or it's just\\n10:25 it depends on the company and there's no\\n10:27 really big difference\\n10:29 i would say it depends on the company\\n10:30 because some companies choose multiple\\n10:32 cloud sources\\n10:33 some companies build custom solutions\\n10:35 and because of that\\n10:37 data engineers might be more on the side\\n10:39 of for example parsing data\\n10:40 which is considered to be like more\\n10:42 background thing or\\n10:44 writing written from the database while\\n10:46 more big data scene is working with\\n10:48 uh so-called big data specific data\\n10:51 formats\\n10:51 like uh avro rk and protobuf\\n10:55 probably like backgrounds and js usually\\n10:58 work with json\\n10:59 or maybe a little bit the safe space\\n11:02 okay so at the end usually there is no\\n11:04 much difference\\n11:05 yeah okay and so what kind of i think we\\n11:09 talked about\\n11:10 about tools so we talked about uh\\n11:13 spark cloud\\n11:16 and you mentioned scala as well i think\\n11:18 python is quite popular\\n11:20 yeah what kind of skills if we not if\\n11:23 we're not talking about specific tools\\n11:24 but more skills\\n11:26 or more fundamental skills what kind of\\n11:28 skills they need\\n11:30 to be able to do their job i would say\\n11:33 the most important one is coding skills\\n11:35 um\\n11:36 it's often that senior level engineers\\n11:39 get into big data engineering which is\\n11:40 quite logical because\\n11:42 they already have some experience on the\\n11:44 backend side and then\\n11:45 they learn big data stack and just\\n11:48 understand already how it works behind\\n11:50 the scenes\\n11:51 so definitely a great level of coding\\n11:54 skills\\n11:55 another one is working these databases\\n11:58 like writing queries being able to\\n12:00 optimize them\\n12:00 usually it's a sql databases sometimes\\n12:03 no sql\\n12:04 so kind of being able to switch from one\\n12:07 to another because\\n12:08 in my experience when you join different\\n12:10 companies sometimes you have\\n12:12 totally different stack or even\\n12:13 different projects and you just have to\\n12:15 switch real quick\\n12:17 so those are those would be the m\", 'video_id': 'yg3d1lFd7Uo', '_id': 7527}, {'start': 42000, 'content': \"1:07 for their jobs i think they can\\n41:11 just do the monitoring in terms of\\n41:14 whether the model returns the results\\n41:17 and whether it's expected results\\n41:20 i would say that another part of monitor\\n41:22 in terms of resources\\n41:23 and something like that would be more on\\n41:25 data engineers or machine learning\\n41:26 engineers\\n41:28 at least it's the way it works in in\\n41:30 another team where data scientists are\\n41:32 in my company\\n41:34 do you think tools you would use are\\n41:37 the same the dating data scientists\\n41:39 would use some data engineers or they're\\n41:41 different like tools for monitoring\\n41:43 quality\\n41:45 and i think that it could be the same\\n41:47 like for example\\n41:48 some alerts or metrics gathering\\n41:51 or something either visual like\\n41:54 dashboards with their phone or other\\n41:56 tools or tableau\\n41:58 so i think it's quite universal in this\\n42:00 case\\n42:02 okay thank you here we have an\\n42:04 interesting question uh\\n42:06 so as you said the data scientists\\n42:07 depend on data engineer\\n42:09 engineers so let's say data engineers\\n42:11 data scientist needs\\n42:13 a new field they would open agility\\n42:15 ticket for\\n42:16 data engineers to add this\\n42:19 is there anything on which for which\\n42:21 data engineers\\n42:23 depend on data scientists and i think it\\n42:26 depends on the workflow\\n42:28 for example if we would get the results\\n42:30 of the models\\n42:31 in some way we would definitely depend\\n42:33 on data scientists\\n42:35 like for example right now we depend on\\n42:37 either the source of data\\n42:39 which is a third party client or the\\n42:42 database where another\\n42:44 team pushes the data so we kind of\\n42:46 already depend on another team\\n42:48 but on the data scientist side yeah\\n42:50 definitely if you would uh\\n42:52 get the data from them for example the\\n42:54 case that we described with\\n42:55 recommendations if you would want to\\n42:58 build some reports on that and before\\n43:00 that we need to do some transformations\\n43:02 for\\n43:02 other people for example analysts and\\n43:04 therefore it could depend on the results\\n43:06 of the model\\n43:08 but i guess like more\\n43:11 what more happens more often is data\\n43:13 scientists depend on data engineers\\n43:15 because\\n43:16 to train a model you need to have some\\n43:18 data and if you don't have data\\n43:20 engineers you don't have data or\\n43:21 data scientists have to somehow get this\\n43:24 data and because of this dependency on\\n43:27 data\\n43:28 it happens more often that data data\\n43:31 scientists depends on data changes\\n43:33 yeah exactly\\n43:37 so we have a question about data\\n43:39 documentation how do you\\n43:41 maintain data documentation do you think\\n43:43 it's important\\n43:44 to to have it and what would be your\\n43:46 recommendation there\\n43:49 i would say it's just in general\\n43:50 important to have it but a lot of people\\n43:52 don't like to create\\n43:54 the communication therefore it's not the\\n43:56 case for many companies where i noticed\\n43:59 that esp\", 'video_id': 'yg3d1lFd7Uo', '_id': 7549}, {'start': 13500, 'content': \"3:44 lot of\\n13:45 people a lot of companies just switch to\\n13:47 something else\\n13:48 instead of that because it's easier to\\n13:50 maintain some cloud services for example\\n13:54 yeah and so we talked about big data\\n13:57 engineers\\n13:58 so they take care of data preparation so\\n14:01 there is some data generated by the\\n14:03 users of our product\\n14:04 so data engineers big data engineers\\n14:07 take care of\\n14:08 processing this data and making it\\n14:11 possible for analysts and other people\\n14:13 to\\n14:14 run their queries what do data\\n14:16 scientists do\\n14:18 usually yeah the main part would be\\n14:21 actually building machine learning\\n14:23 models but it's only one part of the\\n14:25 machine learning model cycle how it's\\n14:27 called because they do need to clean the\\n14:29 data\\n14:30 prepare it to build features create the\\n14:33 models\\n14:34 deploy them sometimes sometimes it's in\\n14:36 their role sometimes in someone else's\\n14:38 but still they need to understand very\\n14:40 well how it's supposed to be deployed\\n14:42 so they would be able to evaluate it\\n14:44 further and\\n14:45 it's called the cycle because it can get\\n14:47 repeated again if we need to\\n14:49 fix some features some two hyper\\n14:52 parameters\\n14:53 or just in general go to another\\n14:55 solution because this one\\n14:57 is not really good for our needs\\n15:01 so clean the data is something that data\\n15:04 scientists do\\n15:05 so you cannot expect data engineers to\\n15:07 clean data for data scientists right\\n15:09 i would say it's a bit controversial\\n15:11 because sometimes\\n15:12 data engineers do that sometimes data\\n15:15 scientists need to still have this\\n15:17 pre-processing stuff depends on the\\n15:18 company as well\\n15:19 or just the way the pipeline is built\\n15:23 and they just attend both do just\\n15:26 different uh different kind of cleaning\\n15:29 right\\n15:30 yeah okay and so in terms of\\n15:36 responsibilities i think i have an\\n15:38 understanding\\n15:39 in terms of tools i think data\\n15:41 scientists use quite a different set of\\n15:43 tools right\\n15:44 from big data engineers yeah sometimes\\n15:47 they\\n15:47 can coincide in spark because now spark\\n15:50 is getting more and more popular for\\n15:52 machine learning as well\\n15:53 and the python is also heavily used by\\n15:56 some big data engineers so\\n15:57 they can kind of coincide here but yeah\\n16:00 mostly\\n16:01 machine learning engineers or data\\n16:02 scientists would use some\\n16:04 multiple specific libraries for a\\n16:07 specific model case\\n16:08 whether it's recommendation system deep\\n16:10 learning or computer vision\\n16:12 and they may not get involved that much\\n16:14 with infrastructure for example\\n16:16 and yeah databases would be practically\\n16:19 the same\\n16:19 especially if eight engineers just lose\\n16:22 the data there and\\n16:23 data scientists just read it from there\\n16:26 and in terms of the programming language\\n16:28 um like\\n16:30 you use scala do your\\n16:33 do data scientists we work with they\\n16:35 also use color or the\", 'video_id': 'yg3d1lFd7Uo', '_id': 7530}, {'start': 7500, 'content': \"ibraries for the\\n7:52 part of\\n7:53 data parts in like play in scala\\n7:57 or libraries for tests which are also\\n7:59 scholar libraries like scala tests\\n8:02 and all of that i remember you have a\\n8:05 talk\\n8:05 about um uh what is it uh i think\\n8:09 this has a funny name about alice\\n8:12 discovering kubernetes\\n8:14 what's the name of this talk i think\\n8:17 i have like a series of those probably\\n8:19 it was the first one when\\n8:21 alice learns the difference between\\n8:23 functional programming and\\n8:25 kubernetes i'm doing that how did you\\n8:27 come up with this idea by alice\\n8:31 i don't know it's hard for me to say\\n8:32 it's kind of a cumulative experience\\n8:35 because\\n8:35 i before i started to speak at\\n8:37 conferences i visited like tons\\n8:40 of local and european conferences and\\n8:43 i noticed that it's much more\\n8:44 interesting to kind of get invested into\\n8:47 the story aside from the technical side\\n8:50 and that's how i tried this idea with\\n8:52 the first talk\\n8:53 and only after some time i decided that\\n8:55 probably i need to build more of those\\n8:57 and then it kind of sparked the\\n8:58 popularity because people enjoyed a lot\\n9:00 the story side as well\\n9:03 it became like a brand uh like this kind\\n9:06 of okay\\n9:10 um so i'm sometimes\\n9:13 a bit confused so we have data engineers\\n9:15 we have big data engineers\\n9:17 is there any difference between these\\n9:19 two like or\\n9:20 they're mostly synonyms of big data\\n9:22 engineers and usual engineers\\n9:24 i mean usual data engineers like uh buy\\n9:28 the book and the way it's supposed to be\\n9:30 a difference in terms of um how you\\n9:32 process the data like big data\\n9:34 engineering requires a bit different\\n9:36 tools like heavy load\\n9:37 optimizations data engineering small\\n9:40 like\\n9:40 software engineering on the back end but\\n9:43 in reality i would say that\\n9:44 a lot of companies name big data\\n9:46 engineers as data engineers and it's\\n9:48 like constantly a bit confusing\\n9:50 because of that so many just drop the\\n9:53 big part and just\\n9:55 go with data engineer and is there any\\n9:58 difference in\\n9:59 tools uh because for example you you say\\n10:02 you mentioned spark impala\\n10:05 things like this and what i see\\n10:09 in data engineers\\n10:12 maybe is a bit different like most of\\n10:14 them use spark as well but i see\\n10:17 more cloud-based things like i don't\\n10:20 know\\n10:21 streams lambda functions and things like\\n10:24 this or it's just\\n10:25 it depends on the company and there's no\\n10:27 really big difference\\n10:29 i would say it depends on the company\\n10:30 because some companies choose multiple\\n10:32 cloud sources\\n10:33 some companies build custom solutions\\n10:35 and because of that\\n10:37 data engineers might be more on the side\\n10:39 of for example parsing data\\n10:40 which is considered to be like more\\n10:42 background thing or\\n10:44 writing written from the database while\\n10:46 more big data scene is working with\\n10:48 uh so-called big data specific data\\n10:51 formats\\n10:51 like \", 'video_id': 'yg3d1lFd7Uo', '_id': 7526}, {'start': 42000, 'content': \":23 yeah sharing\\n37:24 it mainly just boiled down to sharing my\\n37:27 thoughts and asking when to ask for help\\n37:28 asking when to offer help and all these\\n37:31 kind of small things that i wasn't used\\n37:33 to working mostly by myself before\\n37:36 so really how to work very closely with\\n37:39 people on a day to day level\\n37:40 keeping them in the loop\\n37:43 knowing when to figure out when i need\\n37:44 to get myself into the loop and all\\n37:46 these kind of questions\\n37:49 so you would say that that engineering\\n37:50 is more\\n37:51 of a team sport than data science\\n37:53 exactly exactly and engineering in\\n37:55 general i guess right because usually\\n37:57 you have a lot more engineers than data\\n37:59 scientists\\n38:00 so maybe for a team you\\n38:03 maybe you have one data scientist and\\n38:04 then a bunch of back-end engineers right\\n38:07 exactly exactly and you use it yeah and\\n38:10 you usually have\\n38:12 also more data engineers than data\\n38:13 scientists and so there's a whole\\n38:16 different approach to working together\\n38:19 in your experience\\n38:21 do data engineers usually work like in\\n38:24 one team so maybe there is one platform\\n38:26 or data engineering team or they\\n38:29 are spread across different teams\\n38:32 i've seen both i prefer the model where\\n38:34 they're not where there's not a data\\n38:36 engineering platform team i think unless\\n38:38 you have a really large company where\\n38:40 you where you really need a data\\n38:41 platform infrastructure and you need\\n38:43 people dedicated to that i think in in\\n38:45 the smaller companies i've usually\\n38:46 worked with i\\n38:48 i think it works better if the data\\n38:49 engineers are embedded with the other\\n38:51 either with the other data faults or\\n38:52 also is part of the date of a wider\\n38:55 platform team\\n38:56 but for what i've usually worked with is\\n38:58 just kind of embedded into the more\\n39:00 general data teams\\n39:02 that are consisting of analysts and data\\n39:04 engineers and data scientists and maybe\\n39:07 ml engineers and all sorts of data\\n39:09 specialists\\n39:11 and in this setup you usually see more\\n39:14 engineers than data scientists right\\n39:16 more than just yes usually but\\n39:20 there can also be a lot of\\n39:21 a lot of analysts for example that it's\\n39:23 common that's common to see so it\\n39:26 depends on the setup\\n39:29 okay now there is a question\\n39:31 so do you know if there is a name for\\n39:33 the role for people who are both data\\n39:36 engineers and data scientists\\n39:39 is such a thing does such a thing exist\\n39:42 at all\\n39:43 um\\n39:44 [Music]\\n39:46 i have not encountered it as such but i\\n39:48 think the closest i've seen is really\\n39:50 analytics engineer this this particular\\n39:53 and it\\n39:54 again it depends on what you consider\\n39:56 data scientists being a data engineer\\n39:58 because the overlap might be all sorts\\n39:59 of things it could also be\\n40:01 it could if it goes to the end it could\\n40:04 also be an mlops engineer for example\\n40:06 that could also be an\", 'video_id': '3TTu-hYzxeg', '_id': 643}]\n",
      "RES  ← search call_4e5AisxqtTlyluXPNH2arcT9 [{'start': 16500, 'content': \" and then we can easily access this data\\n17:29 so when we make sure that all the data\\n17:31 we need is there\\n17:33 we go to the next step which is data\\n17:35 preparation step\\n17:36 and this is the step where we prepare\\n17:39 the data so usually the data engineer\\n17:43 works on making sure the data is there\\n17:45 so\\n17:47 they can work with the moderation team\\n17:49 to\\n17:50 to move the data from the moderation\\n17:53 team to our team\\n17:54 uh to access it uh so it involves\\n17:56 setting up data pipelines and\\n17:58 doing things like that and\\n18:02 yeah when we're just starting with the\\n18:03 project it uh often makes sense to\\n18:06 iterate to move fast to iterate quickly\\n18:09 um so maybe\\n18:10 the version of the pipeline that we have\\n18:12 that the data engineer develops doesn't\\n18:14 need to be\\n18:16 great it doesn't need to be perfect so\\n18:19 as long as we\\n18:21 can have a way of getting data from the\\n18:23 other team and use it for solving our\\n18:25 problems\\n18:25 it's good the goal at this stage is to\\n18:28 have the data we need\\n18:30 for a model easily accessible\\n18:34 ideally in a single table so we have all\\n18:37 the features that we need\\n18:39 we have one column with target so in our\\n18:42 case\\n18:42 the features are title description and\\n18:44 the target is the correct category\\n18:47 and we have if we have that then we go\\n18:49 to the modeling step\\n18:50 in the next step and this is actually\\n18:52 the step when we\\n18:54 train a model so\\n18:57 as i said ideally the data is prepared\\n18:59 in such a way that we\\n19:00 do a simple select from our database and\\n19:03 we have the data that we can simply put\\n19:05 to our model\\n19:06 and do model.fit or maybe do a bit of\\n19:09 extra pre-processing\\n19:11 um let's say in case if we have text\\n19:14 then what we can do is we can\\n19:17 do things like count actorizer or tf idf\\n19:20 victorizer\\n19:21 basically we need to do something with\\n19:23 text in order to be\\n19:25 able to use uh these things in a model\\n19:29 this step we need to define some model\\n19:31 evaluation metric\\n19:32 so this is typically something like\\n19:34 accuracy or precision or recall or f1 or\\n19:37 auc like usual performance evaluation\\n19:41 metric that we use for training a model\\n19:44 for regulating models so these are not\\n19:46 business metrics this is something we\\n19:48 use internally as data scientists\\n19:52 and often at this step it makes sense to\\n19:54 come to first come up with a simple\\n19:56 baseline\\n19:57 uh even with before training the model\\n20:00 so it can be simply coming up with rules\\n20:04 saying that if iphone is in the title\\n20:06 then the category is mobile phones\\n20:09 and having a bunch of rules like that\\n20:11 maybe this is already good enough for\\n20:13 the different situation\\n20:15 oh and then we can see okay\\n20:19 what is the accuracy of this baseline um\\n20:22 if the accuracy is really bad and maybe\\n20:24 we need to invest a bit of time in\\n20:25 training\\n20:27 a slightly more complex model or maybe\\n20:30 it's \", 'video_id': 'SesVTDklFYQ', '_id': 5871}, {'start': 4500, 'content': \"y it was created by ibm\\n5:31 in 90s and back then data science was\\n5:34 called data mining\\n5:36 things were different back then but\\n5:37 surprisingly um\\n5:40 the the framework they developed still\\n5:42 applies to data science projects today\\n5:44 with some corrections but the general\\n5:48 process\\n5:49 is still about it today and\\n5:53 a process in crisp dm consists of six\\n5:56 steps\\n5:57 six steps the first step is business\\n6:00 understanding\\n6:01 so we want to understand the the\\n6:04 business problem we want to set\\n6:05 objective\\n6:06 we want to uh really make sure that\\n6:09 the problem we're solving is worth\\n6:11 solving once we have that we go to the\\n6:14 next step which is data understanding\\n6:16 and in at this step we analyze the data\\n6:20 that is available\\n6:21 and we decide if the data is good enough\\n6:23 or not and if we need to get some\\n6:26 new data then we have a data preparation\\n6:28 step\\n6:29 so once we analyze the data we uh found\\n6:32 out if uh\\n6:34 all the data we need is there we need to\\n6:37 transform this data in a way that it can\\n6:39 be used for a machine learning model\\n6:42 now once we have that once the data is\\n6:44 transformed and\\n6:45 it's in a way that is usable for a model\\n6:49 we go to the next step which is modeling\\n6:52 and this is actually training the model\\n6:54 taking\\n6:55 our favorite libraries like scikit-learn\\n6:57 or whatever\\n6:58 and actually training in the model once\\n7:00 we train the model we want to evaluate\\n7:02 it\\n7:03 so we want to look at the results check\\n7:05 it and see\\n7:06 if the model performs according to our\\n7:08 expectations according to what we\\n7:11 defined as an objective at the first\\n7:13 business understanding step\\n7:15 and finally we have a step of deployment\\n7:17 so if our model meets the expectations\\n7:19 we roll out the solution to all the\\n7:21 users\\n7:24 we'll now take a closer look at all the\\n7:27 steps\\n7:28 and see what exactly happens at each of\\n7:30 this tab\\n7:31 and to illustrate it better we'll again\\n7:34 use\\n7:35 the same example we used previously on\\n7:36 our previous conversation\\n7:39 and that was an example of classifying\\n7:42 the category of listing so imagine that\\n7:45 we have an online classified website\\n7:47 where people come to sell things they\\n7:50 don't need and where people\\n7:52 come to buy things they need so\\n7:55 the website like craigslist\\n7:59 ebay or linux avito there are many\\n8:02 different websites like that\\n8:04 and imagine you have you have an iphone\\n8:06 and you want to sell this iphone\\n8:08 so what you do is you go to this website\\n8:10 you create a listing\\n8:12 and people who are interested in this\\n8:14 iphone contact you\\n8:15 and eventually buy buy this iphone\\n8:19 so what we want to do is we want to help\\n8:21 these sellers create listings faster\\n8:24 so for that we want to develop a model\\n8:26 that uh\\n8:27 classifies a list link automatically\\n8:29 suggests a\\n8:30 right category so when you create an\\n8:32 iphone it says okay this\\n8:34 should belong to the m\", 'video_id': 'SesVTDklFYQ', '_id': 5863}, {'start': 15000, 'content': \"ry\\n15:54 or they say okay it doesn't belong to\\n15:56 the to do the correct category\\n15:57 the correct category for iphone is\\n16:00 mobile phones\\n16:02 so we take a look at the data and we\\n16:05 find out that we have information about\\n16:07 the listing so we have a title the\\n16:09 description\\n16:10 but access to images is difficult and\\n16:13 now we need to decide okay\\n16:14 do we really want to now invest time\\n16:17 into\\n16:18 figuring out how to access images or\\n16:21 this information is enough\\n16:23 and then we can say okay like title and\\n16:25 description is enough we can also talk\\n16:27 to the data scientist to see\\n16:29 if it's actually possible to um\\n16:33 to use this information to solve the\\n16:35 problem or we need something extra\\n16:37 um and yeah since images maybe are not\\n16:41 crucial\\n16:41 uh a crucial part here maybe it's\\n16:44 actually a good idea to go without\\n16:45 images\\n16:47 and just use title for solving this\\n16:49 problem\\n16:51 and if we have all the data\\n16:54 in\\n16:57 our data lake then data engineers don't\\n16:59 need to do anything else\\n17:01 but let's say if some of the data is not\\n17:03 accessible\\n17:05 it needs for example let's say if we\\n17:07 want to get\\n17:08 decisions from moderators but this data\\n17:11 is not easily accessible then data\\n17:12 engineers\\n17:14 will need to work with other team with\\n17:16 the moderation team to actually make\\n17:17 sure that\\n17:18 the data can be used for our models so\\n17:21 the data is there in our data lake\\n17:23 and then we can easily access this data\\n17:29 so when we make sure that all the data\\n17:31 we need is there\\n17:33 we go to the next step which is data\\n17:35 preparation step\\n17:36 and this is the step where we prepare\\n17:39 the data so usually the data engineer\\n17:43 works on making sure the data is there\\n17:45 so\\n17:47 they can work with the moderation team\\n17:49 to\\n17:50 to move the data from the moderation\\n17:53 team to our team\\n17:54 uh to access it uh so it involves\\n17:56 setting up data pipelines and\\n17:58 doing things like that and\\n18:02 yeah when we're just starting with the\\n18:03 project it uh often makes sense to\\n18:06 iterate to move fast to iterate quickly\\n18:09 um so maybe\\n18:10 the version of the pipeline that we have\\n18:12 that the data engineer develops doesn't\\n18:14 need to be\\n18:16 great it doesn't need to be perfect so\\n18:19 as long as we\\n18:21 can have a way of getting data from the\\n18:23 other team and use it for solving our\\n18:25 problems\\n18:25 it's good the goal at this stage is to\\n18:28 have the data we need\\n18:30 for a model easily accessible\\n18:34 ideally in a single table so we have all\\n18:37 the features that we need\\n18:39 we have one column with target so in our\\n18:42 case\\n18:42 the features are title description and\\n18:44 the target is the correct category\\n18:47 and we have if we have that then we go\\n18:49 to the modeling step\\n18:50 in the next step and this is actually\\n18:52 the step when we\\n18:54 train a model so\\n18:57 as i said ideally the da\", 'video_id': 'SesVTDklFYQ', '_id': 5870}, {'start': 18000, 'content': \"ta is prepared\\n18:59 in such a way that we\\n19:00 do a simple select from our database and\\n19:03 we have the data that we can simply put\\n19:05 to our model\\n19:06 and do model.fit or maybe do a bit of\\n19:09 extra pre-processing\\n19:11 um let's say in case if we have text\\n19:14 then what we can do is we can\\n19:17 do things like count actorizer or tf idf\\n19:20 victorizer\\n19:21 basically we need to do something with\\n19:23 text in order to be\\n19:25 able to use uh these things in a model\\n19:29 this step we need to define some model\\n19:31 evaluation metric\\n19:32 so this is typically something like\\n19:34 accuracy or precision or recall or f1 or\\n19:37 auc like usual performance evaluation\\n19:41 metric that we use for training a model\\n19:44 for regulating models so these are not\\n19:46 business metrics this is something we\\n19:48 use internally as data scientists\\n19:52 and often at this step it makes sense to\\n19:54 come to first come up with a simple\\n19:56 baseline\\n19:57 uh even with before training the model\\n20:00 so it can be simply coming up with rules\\n20:04 saying that if iphone is in the title\\n20:06 then the category is mobile phones\\n20:09 and having a bunch of rules like that\\n20:11 maybe this is already good enough for\\n20:13 the different situation\\n20:15 oh and then we can see okay\\n20:19 what is the accuracy of this baseline um\\n20:22 if the accuracy is really bad and maybe\\n20:24 we need to invest a bit of time in\\n20:25 training\\n20:27 a slightly more complex model or maybe\\n20:30 it's just like\\n20:31 having a bunch of simple rules uh east\\n20:34 enough at this step\\n20:36 but the important thing here is we have\\n20:38 some sort of way of measuring\\n20:40 it so let's say we have accuracy and we\\n20:43 see that this baseline\\n20:44 is accurate enough to actually go to the\\n20:47 next step\\n20:48 and the next step is evaluation step\\n20:51 this is when we want to see if the model\\n20:54 we developed previously on the previous\\n20:56 step\\n20:57 actually meets the objective asset and\\n21:00 in our example the objective was to\\n21:01 reduce the time moderators spent\\n21:03 on manually adjusting the category\\n21:07 by 50 so what we want to see now is if\\n21:10 the heuristic or a model we trained\\n21:11 previously\\n21:12 actually moves us closer to to this\\n21:15 objective\\n21:16 or actually it can\\n21:19 we can meet this this objective\\n21:22 so what we do is we integrate the\\n21:24 solution we developed on the previous\\n21:26 step\\n21:28 and then evaluate it against a small\\n21:30 traffic a small part of traffic so let's\\n21:32 say\\n21:32 we have all the new listings that are\\n21:35 coming to us\\n21:36 we can take five percent of all this\\n21:38 traffic of all the listings\\n21:40 and apply the model to them uh and see\\n21:44 how users react and actually take a\\n21:48 couple of moderators\\n21:49 and uh put them on just working with\\n21:52 this traffic\\n21:53 while the this the rest of the team\\n21:55 works with the\\n21:57 remaining 90 of the traffic and then we\\n22:00 can\\n22:00 run it for a week or two\", 'video_id': 'SesVTDklFYQ', '_id': 5872}, {'start': 13500, 'content': \"se you rely on very specific\\n14:51 handcrafted uh heuristic of how to\\n14:54 create the dictionary and what to do to\\n14:56 those queries to kind of match the two s\\n14:59 together um and by the way this is still\\n15:02 in the realm of the underlying kind of\\n15:05 retrieval step right so we should\\n15:07 probably also mention that there are\\n15:09 kind of usually two distinct steps in\\n15:11 each of these search systems so you have\\n15:14 this um initial retrieval step you can\\n15:17 call it candidate generation where you\\n15:19 want to like quickly figure out okay\\n15:21 here are the uh potential good results\\n15:25 um so we are narrowing the whole htech\\n15:27 to some tiny fraction of it um and then\\n15:32 you have the second step of ranking\\n15:33 right people consider these problems\\n15:35 very differently uh and the ranking step\\n15:38 um in its final most sophisticated form\\n15:42 you can think about it as a machine\\n15:43 learning problem that's usually framed\\n15:46 as okay for this query and this\\n15:49 potential candidate result um what is\\n15:52 the probability that they actually uh\\n15:55 match right uh so it could be what is\\n15:58 the probability that the user that's\\n16:00 doing the search actually clicks on on\\n16:02 this particular result right there are\\n16:04 different ways to frame the problem but\\n16:07 this this part sounds more like machine\\n16:09 learning and the first part sounds more\\n16:11 like engineering right so we had kind of\\n16:15 in a way stupid uh retrieval and smart\\n16:19 uh\\n16:20 ranking um and then in the dranking step\\n16:23 is usually where those models get\\n16:25 complicated you have all the mlops\\n16:27 issues uh that's where you bring all\\n16:30 that context into the picture right and\\n16:32 you try to run that model on all the\\n16:34 candidates and reorder them and serve\\n16:36 that to the user or to the system that's\\n16:39 doing the searching so so that's the\\n16:42 anatomy you have those two parts usually\\n16:44 um so I have this book those who watch\\n16:47 this in Rec listen to this in recording\\n16:49 don't see this is a German grammatic\\n16:52 grammar\\n16:53 book and yeah so like there's a lot of\\n16:57 information\\n16:59 and let's say I want to find something\\n17:00 in it right so how would we build a\\n17:04 search system for that so we need two\\n17:06 steps right you mentioned like this\\n17:08 candidate generation and binary\\n17:09 classification but also we even before\\n17:11 that we need\\n17:12 to index the entire book right build\\n17:15 index so how would we go about that step\\n17:19 by\\n17:20 step yeah I mean uh you basically\\n17:23 actually at the end of that book there\\n17:24 is most likely uh such uh lookup t\\n17:29 right uh maybe called the reference or\\n17:32 maybe this one doesn't have it but it\\n17:34 doesn't have it only has table of\\n17:36 contents but some PE some books do yeah\\n17:39 yeah some some books do so I mean the\\n17:43 the\\n17:44 Practical uh use Lucin right or one you\\n17:48 know there are uh big open source\\n17:50 projects out there tha\", 'video_id': 'gEmSrknGKDE', '_id': 2579}]\n",
      "RES  ← search call_PzX6FWvolNVEHc7ZrC5v7H0j [{'start': 21000, 'content': \"re\\n19:31 right and then um then also\\n19:34 learn a bit of machine learning right um\\n19:37 is how\\n19:38 this is this how the learning path uh\\n19:40 like let's say we have a typical\\n19:43 data analyst who knows how to write sql\\n19:46 queries who knows how to create\\n19:47 dashboards\\n19:48 who knows how to do\\n19:52 nice data visualization and they want to\\n19:54 become this type a\\n19:56 data scientist how the learning path for\\n19:58 them will look like\\n20:00 so i can talk about this quite well\\n20:03 because that was exactly my path\\n20:05 i when i started my journey into data\\n20:08 science i could\\n20:10 build like do the sequel very badly did\\n20:13 the\\n20:13 do the excel do the dashboarding\\n20:16 do a little bit of r but i had no idea\\n20:19 what the other skills were\\n20:21 so a lot of my journey was essentially\\n20:23 just trying to figure out what i should\\n20:25 learn\\n20:26 once i had that direction when i started\\n20:30 working with people who were in a data\\n20:31 science role\\n20:32 who had data science experiments or\\n20:34 experience\\n20:36 and they could guide me on what i should\\n20:38 be learning that was when i saw my own\\n20:40 growth\\n20:40 and development really like just pick up\\n20:42 like a hockey stick\\n20:43 so um definitely i felt that\\n20:47 before i had that sort of guidance i was\\n20:49 just kind of fumbling around in the dark\\n20:51 reading a lot of different articles and\\n20:53 kind of being stretched everywhere\\n20:55 so you hear like oh you need to\\n20:57 understand all the theory before you\\n20:58 even start doing any programming and\\n21:00 then someone else would say\\n21:01 no you just go implement the machine\\n21:02 learning things and then you pick up the\\n21:04 theory\\n21:04 so i feel like yeah that's what i would\\n21:08 say is all just\\n21:08 go and try a few things and when you\\n21:11 need to learn the theory you'll know\\n21:12 when you need to learn the theory\\n21:13 because you have no idea what's going on\\n21:14 so\\n21:16 i think that was that was the same\\n21:17 advice given to me also\\n21:19 so um but yeah i would say for anyone\\n21:22 who's currently\\n21:23 in a data analyst role or doing\\n21:26 work which is not even in analytics but\\n21:28 you're managing databases or\\n21:30 you're um i wouldn't say software\\n21:33 developer that comes into the\\n21:34 the other into the type b but for anyone\\n21:37 who's working with data\\n21:38 and they're doing things and visualizing\\n21:40 and whatever\\n21:42 there's definitely a path into data\\n21:43 science you just have to be curious and\\n21:45 keep working on it\\n21:46 and work with good strong mentors who\\n21:49 can give you\\n21:50 that level of guidance to push you in\\n21:51 the right direction\\n21:54 yeah so that's uh so i'm just\\n21:57 trying to like how can we formalize this\\n21:59 being curious right\\n22:00 so you can just uh like let's say you\\n22:03 you are trying to put a learning plan\\n22:05 and then you put\\n22:06 python there you put machine learning\\n22:07 theory there you put uh\\n22:09 some other things and then th\", 'video_id': 'HVQ0DZOQcts', '_id': 2965}, {'start': 4500, 'content': \"alized\\n4:14 i didn't really enjoy data science as\\n4:16 much because it was very black box it\\n4:18 fell to me because i never was felt like\\n4:20 i was feeding some model but i didn't\\n4:22 really understand what's going on which\\n4:23 is partially due to the fact that my\\n4:24 mathematics background isn't that strong\\n4:27 so i didn't never really got the theory\\n4:29 behind it\\n4:30 but also i realized i kind of miss more\\n4:32 the engineering parts of it and\\n4:34 that was also the time when data\\n4:36 engineering became more of a thing\\n4:37 because companies realized that they\\n4:38 need not just data scientists but also\\n4:40 people that actually before come before\\n4:42 them and\\n4:43 make data available for data science\\n4:45 because that's at the time was a common\\n4:47 frustration for data scientists to not\\n4:48 have data\\n4:51 great ambitions but no data\\n4:54 and then i went\\n4:56 got an offer at native instruments to be\\n4:58 one of their first data engineers\\n5:01 i did that for a while um i still had\\n5:04 the ambition back then to transition\\n5:05 back into data science but i left native\\n5:07 instruments for unrelated reasons before\\n5:10 that happened\\n5:12 then i got another job at another\\n5:13 company as a bi developer\\n5:18 my title was data scientists but really\\n5:19 what i did was\\n5:21 develop custom\\n5:23 with data visualizations\\n5:26 and i realized eventually that this was\\n5:28 kind of a dead end for me\\n5:30 and so i\\n5:32 i remembered my software engineering\\n5:34 background which i actually enjoyed\\n5:36 except it was a repetitive and then\\n5:38 at the time i was speaking to somebody\\n5:40 at thoughtworks she was the first data\\n5:42 scientist at the thoughtworks in germany\\n5:44 at the time and she told me that\\n5:46 thoughtworks was planning to expand its\\n5:48 data engineering offering and what i'd\\n5:49 be interested in\\n5:52 in becoming the solidworks germany's\\n5:54 first data engineer and help her expand\\n5:56 that offering and i thought it was\\n5:58 really exciting and\\n5:59 especially since southwark is a great\\n6:01 place for really learning good software\\n6:03 engineering practices which as a data\\n6:05 engineer is always frustrated as a data\\n6:07 scientist that always frustrated me that\\n6:09 the quality of the code and the\\n6:11 collaboration wasn't as good as i was i\\n6:13 remembered it from my back in\\n6:14 engineering days\\n6:16 and so i jumped on that and that's when\\n6:17 i finally decided to stay in data\\n6:19 engineering which i had done on and off\\n6:21 before\\n6:23 and then then yeah after that was i went\\n6:26 to where i'm now it was my transfers and\\n6:28 built up data engineering there which\\n6:29 way i'm now heading a team\\n6:32 that's quite a story and thanks for\\n6:33 sharing so uh what i also wanted to ask\\n6:36 you the next question i prepared is that\\n6:38 you were a data scientist and then you\\n6:40 switched to data engineering and i\\n6:41 wanted to ask why i think you partly\\n6:43 answered that so you said that\\n6:47 data science was a bit too black boxy\", 'video_id': '3TTu-hYzxeg', '_id': 618}, {'start': 1500, 'content': \"during the interview and that's\\n1:33 all i have\\n1:37 for the introduction are you ready to\\n1:38 start yeah\\n1:40 okay so let me just\\n1:47 pull my notes\\n1:52 okay we have um today we will talk about\\n1:55 uh the difference between uh\\n1:57 big data engineers and data scientists\\n2:00 and we have special guests today\\n2:02 rexella ruxlana works as a big data\\n2:04 engineer\\n2:05 in uh captify right yeah and\\n2:09 uh yeah so today she will talk about\\n2:13 the role of a data engineer and data\\n2:14 scientist welcome\\n2:17 thank you before we go before we start\\n2:20 with our\\n2:21 main topic let's talk a bit about your\\n2:24 background\\n2:25 can you tell us a bit about your career\\n2:26 journey so far\\n2:28 yeah sure so i have a software\\n2:31 engineering degree\\n2:32 in one of the key universities it's both\\n2:35 bachelor and\\n2:36 master's degree and after that i was\\n2:38 working some time as\\n2:40 a background engineer in java mostly and\\n2:43 just at some point i\\n2:44 learned about data science big data\\n2:46 engineering and\\n2:48 i had some time to make a decision what\\n2:50 exactly i would want to do\\n2:52 and kind of back-end engineering at some\\n2:54 point just got a bit boring for me so\\n2:56 i switched into big data engineering\\n2:59 learned the\\n2:59 scala programming language and that's my\\n3:02 main programming language\\n3:04 now and um for a few years i worked at\\n3:07 a company called sql it's quite famous\\n3:10 in ukraine because it's\\n3:11 quite big company one of the top five\\n3:13 and\\n3:14 it's an outsourcing company which works\\n3:16 with clients and\\n3:18 as well as has some research so i was\\n3:21 working at the\\n3:22 r d department we had some internal\\n3:24 research stuff and\\n3:26 also i worked for some client projects\\n3:28 and\\n3:29 only two years ago i joined captify\\n3:32 which is\\n3:33 a product company they are building a\\n3:35 product in the sphere of\\n3:37 advertising and actually a company is\\n3:40 british it's based in uk\\n3:41 but it has a part of the engineering\\n3:44 team in cave\\n3:44 where i'm based and mostly working on\\n3:48 the product part specifically\\n3:50 in the big data engineering team\\n3:53 yeah i've heard that in advertising\\n3:55 there are there is so much data\\n3:57 that this data engineering big data\\n4:00 engineering becomes really important\\n4:01 because\\n4:02 these companies every day gets get\\n4:04 terabytes of data and they need to\\n4:06 effectively\\n4:07 uh process this data right yeah\\n4:10 and also what kind of makes uh the\\n4:12 solution of creptify unique\\n4:14 is data insights which are obviously\\n4:17 delivered to the help of\\n4:19 big data engineering team by having\\n4:21 different\\n4:22 sources of data and ways to transform\\n4:24 this data and deliver it to the clients\\n4:27 so what do you do at work uh what do you\\n4:29 usually do\\n4:30 as a big data engineer so my main\\n4:33 responsibility is building data\\n4:35 pipelines uh usually it's etl format\\n4:37 extract transform load so kind of\\n4:39 reading the data from some source\\n4:42 building transformations s\", 'video_id': 'yg3d1lFd7Uo', '_id': 7522}, {'start': 49500, 'content': \"you in\\n48:35 browser\\n48:36 and then in this browser you get a\\n48:38 terminal like a linux\\n48:39 terminal and then you can do you have a\\n48:43 cubectl there with these kubernetes\\n48:45 and then you can do and they basically\\n48:49 tell you\\n48:49 uh what you should do like execute this\\n48:52 comment execute that command\\n48:53 and then you get this feeling\\n48:56 also google cloud has sometimes some\\n48:59 called labs\\n49:00 they have this in documentation for\\n49:02 example of q flow where you can\\n49:04 try out on each step and some of them\\n49:07 are free so\\n49:08 it's possible to use them data breaks\\n49:09 has this kind of trainings as well but\\n49:12 they are usually paid sometimes they\\n49:14 allow to use some of them for free\\n49:16 either for\\n49:17 some conferences attend this like lately\\n49:20 sparks on it is free and\\n49:22 people could send the summit can use\\n49:24 these trainings for free some of them\\n49:27 [Music]\\n49:28 thanks um so there is a question that\\n49:31 they wanted to ask\\n49:32 and they just uh just remembered it\\n49:35 so let's say i am graduating from a\\n49:37 university\\n49:39 so it was let's say i was studying\\n49:42 um i'm studying um\\n49:45 you know computer science so i'm\\n49:46 graduating from university i study\\n49:48 computer science\\n49:49 and now i need to make a choice um\\n49:53 what kind of position i want to work um\\n49:57 do i want to do data science or i want\\n49:59 to do\\n50:00 data engineering so which one uh which\\n50:03 path would you recommend\\n50:04 and why and maybe uh you can also think\\n50:07 how would you\\n50:09 suggest people to find out what they are\\n50:11 more interested in\\n50:13 yeah and exactly i would suggest to like\\n50:15 find out what's more interesting\\n50:17 um why i chose big data engineering is\\n50:19 for me uh\\n50:20 data science was a bit not that\\n50:23 determined\\n50:24 i think that software engineers would\\n50:25 understand me because\\n50:27 it's hard sometimes to explain why\\n50:29 machine learning model does what she\\n50:31 does and why\\n50:32 these results are this way and uh big\\n50:36 data engineering is more like software\\n50:37 engineering that it's more determined\\n50:39 so for me i was just in general\\n50:41 interested in software engineering and i\\n50:43 wanted to work with some different tools\\n50:44 and different\\n50:45 uh tasks therefore big data engineering\\n50:48 is\\n50:48 a great way for people who are getting\\n50:51 bored in backhand engineering or they\\n50:53 already just go right from the\\n50:55 university and learn more of big data\\n50:57 tech\\n50:57 and go into the great engineering if the\\n51:01 person would be more interested\\n51:02 in building algorithms like mathematics\\n51:05 machine learning just feeling kind of\\n51:07 fashionable things\\n51:09 like computer revision or deep learning\\n51:11 then it's a good case to start with data\\n51:14 science\\n51:15 is there any project you would recommend\\n51:18 people to try\\n51:20 to understand if they like data\\n51:22 engineering or not\\n51:24 like i mean it sounds cool right uh\", 'video_id': 'yg3d1lFd7Uo', '_id': 7554}, {'start': 52500, 'content': \"0 yeah definitely but for software\\n55:33 Engineers I would recommend them the\\n55:34 same team up with data scientists they\\n55:36 definitely need some perspective from\\n55:38 software Engineers how to write better\\n55:40 code and there are some nice courses I\\n55:43 used to do a lot of you Destiny degrees\\n55:45 before\\n55:47 um I also used to be a mentor there in\\n55:49 university at some point of time and\\n55:52 they have some machine learning\\n55:54 engineering courses maybe it's\\n55:57 interesting to check that out and there\\n55:59 are of course a lot of data scientists\\n56:01 courses in in general\\n56:04 um so it's always good to check those\\n56:06 out\\n56:07 in your opinion how much\\n56:10 uh\\n56:12 machine learning should machine learning\\n56:14 Engineers know\\n56:17 yeah so I think there is a Google paper\\n56:19 I believe that says only five percent of\\n56:22 the whole ml system is machine learning\\n56:25 it's actually this famous figure right\\n56:28 this famous diagram\\n56:31 very fine and like very tiny part\\n56:33 exactly I think it's about right so I\\n56:37 think machine learning Engineers\\n56:38 definitely need to know something about\\n56:40 machine learning so\\n56:43 I would suggest to do data science\\n56:45 course and understand with what tools\\n56:48 data scientists work\\n56:50 and how what type of things they produce\\n56:53 and how do they think about that so I\\n56:55 think it's very important because it\\n56:57 really influences the deployment\\n57:00 um but because they're coming from\\n57:03 software engineering background they\\n57:04 probably know a lot about the rest of 95\\n57:07 so I'm guessing the advantage\\n57:11 mm-hmm\\n57:12 okay\\n57:14 um do you think ml Engineers need to\\n57:16 know some data engineering\\n57:19 yeah actually I I also now interested in\\n57:22 dating engineering there is a course\\n57:24 from Zach Wilson he created a boot camp\\n57:28 from data engineering that's actually a\\n57:29 very nice one I'm following it at the\\n57:31 moment I'm a bit slower than others I\\n57:34 guess\\n57:35 um but I I am following it it's really\\n57:38 nice\\n57:39 because a large part of the machine\\n57:42 learning pipelines actually related to\\n57:43 engineering because it's always the\\n57:46 first step and the most challenging one\\n57:49 quite often yeah if you don't have data\\n57:52 like you just have science right yeah\\n57:54 yeah definitely but also you need to\\n57:58 construct your data engineering data\\n58:00 engineering pipelines which are part of\\n58:02 your machine learning platforms or in a\\n58:04 smart way because often those pipelines\\n58:07 tend to run for a long time\\n58:10 um so you really need to spend time on\\n58:12 optimizing those\\n58:14 mm-hmm\\n58:16 okay and actually the question I was\\n58:18 going to ask at the end is any resource\\n58:21 recommendation but I think we covered\\n58:22 that and I look at the time and I think\\n58:25 we should be wrapping up so I want to\\n58:27 thank you Maria for joining us today uh\\n58:31 it was very nice talking to you so maybe\\n58:33 we should repeat th\", 'video_id': 'q3DTR3Od1MA', '_id': 4887}]\n",
      "RES  ← search call_xvI8X4YbzzcxxgexB68km1iD [{'start': 1500, 'content': \"during the interview and that's\\n1:33 all i have\\n1:37 for the introduction are you ready to\\n1:38 start yeah\\n1:40 okay so let me just\\n1:47 pull my notes\\n1:52 okay we have um today we will talk about\\n1:55 uh the difference between uh\\n1:57 big data engineers and data scientists\\n2:00 and we have special guests today\\n2:02 rexella ruxlana works as a big data\\n2:04 engineer\\n2:05 in uh captify right yeah and\\n2:09 uh yeah so today she will talk about\\n2:13 the role of a data engineer and data\\n2:14 scientist welcome\\n2:17 thank you before we go before we start\\n2:20 with our\\n2:21 main topic let's talk a bit about your\\n2:24 background\\n2:25 can you tell us a bit about your career\\n2:26 journey so far\\n2:28 yeah sure so i have a software\\n2:31 engineering degree\\n2:32 in one of the key universities it's both\\n2:35 bachelor and\\n2:36 master's degree and after that i was\\n2:38 working some time as\\n2:40 a background engineer in java mostly and\\n2:43 just at some point i\\n2:44 learned about data science big data\\n2:46 engineering and\\n2:48 i had some time to make a decision what\\n2:50 exactly i would want to do\\n2:52 and kind of back-end engineering at some\\n2:54 point just got a bit boring for me so\\n2:56 i switched into big data engineering\\n2:59 learned the\\n2:59 scala programming language and that's my\\n3:02 main programming language\\n3:04 now and um for a few years i worked at\\n3:07 a company called sql it's quite famous\\n3:10 in ukraine because it's\\n3:11 quite big company one of the top five\\n3:13 and\\n3:14 it's an outsourcing company which works\\n3:16 with clients and\\n3:18 as well as has some research so i was\\n3:21 working at the\\n3:22 r d department we had some internal\\n3:24 research stuff and\\n3:26 also i worked for some client projects\\n3:28 and\\n3:29 only two years ago i joined captify\\n3:32 which is\\n3:33 a product company they are building a\\n3:35 product in the sphere of\\n3:37 advertising and actually a company is\\n3:40 british it's based in uk\\n3:41 but it has a part of the engineering\\n3:44 team in cave\\n3:44 where i'm based and mostly working on\\n3:48 the product part specifically\\n3:50 in the big data engineering team\\n3:53 yeah i've heard that in advertising\\n3:55 there are there is so much data\\n3:57 that this data engineering big data\\n4:00 engineering becomes really important\\n4:01 because\\n4:02 these companies every day gets get\\n4:04 terabytes of data and they need to\\n4:06 effectively\\n4:07 uh process this data right yeah\\n4:10 and also what kind of makes uh the\\n4:12 solution of creptify unique\\n4:14 is data insights which are obviously\\n4:17 delivered to the help of\\n4:19 big data engineering team by having\\n4:21 different\\n4:22 sources of data and ways to transform\\n4:24 this data and deliver it to the clients\\n4:27 so what do you do at work uh what do you\\n4:29 usually do\\n4:30 as a big data engineer so my main\\n4:33 responsibility is building data\\n4:35 pipelines uh usually it's etl format\\n4:37 extract transform load so kind of\\n4:39 reading the data from some source\\n4:42 building transformations s\", 'video_id': 'yg3d1lFd7Uo', '_id': 7522}, {'start': 43500, 'content': \" that\\n38:06 you have the data in the warehouse and\\n38:08 you want to basically send data\\n38:10 to a lot of different tools your sales\\n38:12 marketing\\n38:13 advertising support tools or whatever\\n38:15 product analytics tools you can do that\\n38:17 um\\n38:18 using this this third party too so yeah\\n38:21 a lot of different tools solving\\n38:23 different\\n38:24 pieces of the puzzle uh of course like\\n38:26 to implement all of these different\\n38:27 tools you'd\\n38:28 uh need like a lot of resources you'd\\n38:30 need a data team\\n38:32 um at least a couple of or maybe at\\n38:34 least one dedicated data engineer\\n38:36 so it's not possible for early stage\\n38:38 startups to do everything\\n38:40 um and that's where it's also worth\\n38:43 mentioning\\n38:44 cdp's customer data platforms which are\\n38:47 sort of they're like an all-in-one\\n38:49 bundled solution\\n38:50 where you can track data and then you\\n38:52 can send data to different tools\\n38:54 um so you can like you can create\\n38:56 audiences and create your\\n38:57 models and segments inside a cdp of\\n39:00 course\\n39:01 it has limited capabilities you can't\\n39:03 exactly do everything you can do in a\\n39:04 warehouse\\n39:05 but it still gives a lot of flexibility\\n39:07 to marketers and growth\\n39:09 professionals to to you know work with\\n39:11 data without relying on\\n39:13 on data teams so yeah\\n39:16 i was trying to take a note of all the\\n39:20 tools you mentioned but there are simply\\n39:21 so many\\n39:23 and i'm wondering so let's say i just\\n39:25 started the startup\\n39:27 i and my co-founder so i haven't started\\n39:30 the startup i'm just like a hypothetical\\n39:31 hypothetical yeah\\n39:32 yes so i have a co-founder so there are\\n39:35 two of us we just started the startup\\n39:37 and to understand that data is important\\n39:40 we want to collect and we look at all\\n39:42 these tools and\\n39:43 there are just too many like how do we\\n39:45 make a decision which tool to choose\\n39:47 like\\n39:48 uh i think it's not about are they\\n39:51 different\\n39:51 similar yeah how to choose yeah i think\\n39:54 i think it's first important to define\\n39:56 what your\\n39:56 goals are uh and a good way to think\\n39:59 about this is to like just\\n40:00 list down uh you know 10 questions that\\n40:02 you want to answer with data\\n40:04 and then work backwards and and figure\\n40:06 out the tools uh\\n40:08 of course there are ready-made tools but\\n40:09 a lot of companies end up\\n40:11 uh you know fixing these problems or\\n40:14 implementing these solutions without uh\\n40:16 buying ready-made tools by building in\\n40:18 our schools so\\n40:19 it depends uh you know what your\\n40:20 resources are because\\n40:22 these tools can also get expensive but\\n40:24 uh at the very least you need\\n40:26 you need to start collecting data so you\\n40:29 need uh tool\\n40:30 like a cdi to like segment connections\\n40:32 broader stack\\n40:33 uh meta router uh i'll share this whole\\n40:36 list\\n40:37 which actually written a lot about this\\n40:38 stuff so shares list\\n40:40 um and once you have the \", 'video_id': '8v5KpHWgyYw', '_id': 1049}, {'start': 4500, 'content': \" i know kafka\\n4:39 spark and things like this right\\n4:41 yeah yeah it's more uh custom solutions\\n4:44 these days right which fits our needs\\n4:46 and moving towards more open source\\n4:50 frameworks right\\n4:52 okay yeah thanks\\n4:54 so let's talk about data engineering\\n4:56 managers so what do they do and why do\\n4:59 we need them\\n5:01 yeah so um\\n5:04 actually the core uh still remains same\\n5:07 as a people manager right so we have to\\n5:09 take care of your team you know you have\\n5:10 to\\n5:11 you know keep looking at you know how\\n5:13 your team is moving your deliverables\\n5:15 etc\\n5:16 but uh another thing which you know adds\\n5:18 up to this role is stakeholder\\n5:20 management right when you're working\\n5:22 with as an individual contributor you're\\n5:24 just\\n5:25 caring about your piece of work here you\\n5:28 have to talk to various stakeholders who\\n5:30 are sponsoring this data platform as\\n5:32 well as\\n5:33 who are consumers right these days the\\n5:36 the number of and variety of consumers\\n5:38 are also growing\\n5:39 they are the stakeholders for us right\\n5:41 so as a data engineering manager you\\n5:43 have to take care of them\\n5:44 their needs right\\n5:46 and uh again uh from the team\\n5:49 your team is also your stakeholder right\\n5:50 so you have to make sure you know their\\n5:53 skill set are getting upgraded\\n5:55 along with the\\n5:57 new tools and technologies coming into\\n5:59 play right\\n6:00 and then\\n6:01 coaching them just deciding their career\\n6:03 path right\\n6:05 and sometimes you know other things like\\n6:08 within a team deciding for some approach\\n6:11 or sometimes conflict resolutions right\\n6:14 and one of the most important tasks for\\n6:16 data hinging manager or any engineering\\n6:18 manager should be prioritizing the task\\n6:21 right you have lot of things coming on\\n6:23 your way right from various stakeholders\\n6:26 so how you\\n6:27 prioritize that that's one of the key\\n6:30 responsibilities as well\\n6:32 so you work on a data platform some\\n6:35 internal data platform right and you\\n6:37 manage the engineers right\\n6:40 and because the the setup we have to\\n6:43 elix is we have engineering managers\\n6:47 and\\n6:48 people who report to the engineering\\n6:50 managers are back-end engineers\\n6:52 front-end engineers and data engineers\\n6:55 right so\\n6:57 we don't have a role that is called data\\n6:58 engineering manager and usually there is\\n7:01 just an engineering manager who manages\\n7:03 the engineers\\n7:05 and i'm wondering why do we have this um\\n7:08 maybe because we work in so-called\\n7:11 feature teams like a team that works on\\n7:13 a specific\\n7:15 part of a product and everyone works on\\n7:17 the same thing while in your case your\\n7:19 team takes care of the other platform so\\n7:21 everyone on your team is a data engineer\\n7:23 right\\n7:24 absolutely yeah\\n7:26 correct yeah\\n7:28 and i guess it's helpful for data\\n7:30 engineers to have a manager who is also\\n7:32 a data engineer or at least who can\\n7:34 relate to the problems they have because\\n7:36 this is how the\", 'video_id': 'FljnbUQ796w', '_id': 2283}, {'start': 4500, 'content': \"alized\\n4:14 i didn't really enjoy data science as\\n4:16 much because it was very black box it\\n4:18 fell to me because i never was felt like\\n4:20 i was feeding some model but i didn't\\n4:22 really understand what's going on which\\n4:23 is partially due to the fact that my\\n4:24 mathematics background isn't that strong\\n4:27 so i didn't never really got the theory\\n4:29 behind it\\n4:30 but also i realized i kind of miss more\\n4:32 the engineering parts of it and\\n4:34 that was also the time when data\\n4:36 engineering became more of a thing\\n4:37 because companies realized that they\\n4:38 need not just data scientists but also\\n4:40 people that actually before come before\\n4:42 them and\\n4:43 make data available for data science\\n4:45 because that's at the time was a common\\n4:47 frustration for data scientists to not\\n4:48 have data\\n4:51 great ambitions but no data\\n4:54 and then i went\\n4:56 got an offer at native instruments to be\\n4:58 one of their first data engineers\\n5:01 i did that for a while um i still had\\n5:04 the ambition back then to transition\\n5:05 back into data science but i left native\\n5:07 instruments for unrelated reasons before\\n5:10 that happened\\n5:12 then i got another job at another\\n5:13 company as a bi developer\\n5:18 my title was data scientists but really\\n5:19 what i did was\\n5:21 develop custom\\n5:23 with data visualizations\\n5:26 and i realized eventually that this was\\n5:28 kind of a dead end for me\\n5:30 and so i\\n5:32 i remembered my software engineering\\n5:34 background which i actually enjoyed\\n5:36 except it was a repetitive and then\\n5:38 at the time i was speaking to somebody\\n5:40 at thoughtworks she was the first data\\n5:42 scientist at the thoughtworks in germany\\n5:44 at the time and she told me that\\n5:46 thoughtworks was planning to expand its\\n5:48 data engineering offering and what i'd\\n5:49 be interested in\\n5:52 in becoming the solidworks germany's\\n5:54 first data engineer and help her expand\\n5:56 that offering and i thought it was\\n5:58 really exciting and\\n5:59 especially since southwark is a great\\n6:01 place for really learning good software\\n6:03 engineering practices which as a data\\n6:05 engineer is always frustrated as a data\\n6:07 scientist that always frustrated me that\\n6:09 the quality of the code and the\\n6:11 collaboration wasn't as good as i was i\\n6:13 remembered it from my back in\\n6:14 engineering days\\n6:16 and so i jumped on that and that's when\\n6:17 i finally decided to stay in data\\n6:19 engineering which i had done on and off\\n6:21 before\\n6:23 and then then yeah after that was i went\\n6:26 to where i'm now it was my transfers and\\n6:28 built up data engineering there which\\n6:29 way i'm now heading a team\\n6:32 that's quite a story and thanks for\\n6:33 sharing so uh what i also wanted to ask\\n6:36 you the next question i prepared is that\\n6:38 you were a data scientist and then you\\n6:40 switched to data engineering and i\\n6:41 wanted to ask why i think you partly\\n6:43 answered that so you said that\\n6:47 data science was a bit too black boxy\", 'video_id': '3TTu-hYzxeg', '_id': 618}, {'start': 1500, 'content': \"xperience in data and\\n1:29 engineering he has been a manager for\\n1:32 the last two almost three years and now\\n1:34 he works as a data engineer manager at\\n1:36 siemens welcome rahul\\n1:39 thanks alexey\\n1:41 pleasure to be here\\n1:42 yeah thanks for for coming for joining\\n1:44 us so before we go into our main topic\\n1:46 of behind and engineering and data\\n1:49 engineering manager let's start with\\n1:51 your background can you tell us about\\n1:53 your career journey so far\\n1:56 yeah uh so first of all uh thanks\\n1:58 everyone for joining and thanks alexi\\n2:00 for inviting\\n2:02 uh yeah i started uh my career in\\n2:05 somewhere in 2010\\n2:07 like 12 years back and started as a\\n2:10 traditional etl developer and working\\n2:12 with the databases\\n2:14 and relational databases like sql server\\n2:17 oracle etl tools like ssis sssrs like\\n2:21 microstick\\n2:22 and then slowly moved into uh more of a\\n2:25 master data management kind of stuff for\\n2:27 enterprise\\n2:28 right and then somewhere in 2015 uh\\n2:32 started getting into cloud\\n2:34 and you know the volume of data was\\n2:36 increasing so\\n2:38 got some skill set dealing with uh big\\n2:40 data\\n2:41 right and\\n2:44 that got me into more of a data\\n2:45 engineering role\\n2:47 so transition from traditional uh etl\\n2:50 developer or bi developer you can call\\n2:52 it to more of a data engineering role\\n2:54 and nowadays dealing with\\n2:56 a lot of batch data and you know real\\n2:58 time streaming data building pipelines\\n3:01 exposing data to consumers like\\n3:04 to downstream systems\\n3:06 so yeah that's it's been a very\\n3:09 interesting journey in last 12 years and\\n3:11 currently in\\n3:13 since last two and a half to three years\\n3:15 took up uh this data engineering manager\\n3:18 role where i am managing a team of\\n3:20 enthusiast data engineers here in india\\n3:23 and\\n3:24 yeah building iot data platform for\\n3:28 one of the siemens businesses\\n3:32 that's that's pretty cool a pretty cool\\n3:34 journey so your journey into what we\\n3:37 call today data engineering started with\\n3:39 cloud adoption right so you saw that\\n3:41 many companies started to use cloud and\\n3:43 this is so when you turned\\n3:45 your transition from etl developer to a\\n3:48 data engineer right\\n3:50 do you think it's different or just the\\n3:52 same thing but under a different name\\n3:55 no it's absolutely same\\n3:58 i mean\\n3:59 basics remain same but right but you\\n4:02 have to acquire a new skill set but when\\n4:04 this data paradigm is shifting right\\n4:06 so a lot of things changes when the\\n4:08 volume and variety of data grows right\\n4:11 so in traditional ways days we were\\n4:13 dealing more likely with the structured\\n4:15 data which is more in relation in nature\\n4:18 but these days with evolution of uh you\\n4:20 know machines and sensors right social\\n4:23 media a lot of unstructured and\\n4:25 semi-structured data use case we are\\n4:27 dealing with\\n4:29 so before you probably use tools like\\n4:31 informatica talent\\n4:34 microsoft integration service right and\\n4:36 now it's uh\", 'video_id': 'FljnbUQ796w', '_id': 2281}]\n",
      "RES  ← search call_JLqVF7rIrXgzmSNbuHnL9Xr4 [{'start': 15000, 'content': \"have not me personally but\\n17:58 like the problem\\n18:00 that let me take a step back so in our\\n18:03 community we have courses right so right\\n18:05 now we have three courses free different\\n18:06 courses so ml engineering course data\\n18:09 engineering course and mops course while\\n18:11 the first and the last one are kind of\\n18:13 similar the data engineering course is\\n18:16 quite different so it's a different kind\\n18:17 of job right so then people take all\\n18:20 these courses so they take the\\n18:21 engineering the data engineering course\\n18:23 the ml engineering course and they say\\n18:25 okay I like all the courses M all of\\n18:29 them right what's the third so ml\\n18:31 engineering data engineering and the\\n18:33 third mops mops okay okay so and then\\n18:37 the students come and say like we took\\n18:39 the courses and we like all of them and\\n18:42 I want to do all of this stuff right and\\n18:44 this is a lot right so you cannot be you\\n18:46 cannot like you can but like it's\\n18:48 difficult to be a jack of all trades\\n18:50 right especially if you're only starting\\n18:51 your career and you you need to figure\\n18:53 out what exactly from these\\n18:57 directions where exactly do I want to go\\n19:00 and what sometimes happens\\n19:03 is the students just apply to everything\\n19:06 right so they apply to data engineering\\n19:07 position mlops position ml engineering\\n19:10 positions like all of them right yeah\\n19:14 like I am not sure if it's a good thing\\n19:17 or a bad thing maybe you can tell us but\\n19:20 I think one of the consequences of that\\n19:22 that you kind of lose focus right yeah\\n19:25 exactly so how in this situation when\\n19:28 there are so many options and because um\\n19:31 like if I try to focus then it means\\n19:34 that I\\n19:36 am kind of how to say losing\\n19:40 opportunities like I have this fear of\\n19:42 missing out that if I don't apply to\\n19:44 data engineering positions then like\\n19:46 there's a very big chunk of potential\\n19:49 jobs that I will not get because I don't\\n19:52 apply to them right so if I only apply\\n19:54 to ml engineering positions so how in\\n19:57 this case can I actually understand\\n19:59 which one is better and what is better\\n20:01 for me okay yeah the first thing so\\n20:07 taking the courses all the courses to\\n20:09 explore is good because one doesn't have\\n20:12 experience in the field so exploring\\n20:15 different um uh\\n20:18 specializations is uh a good way to\\n20:21 start but what I would suggest to do\\n20:25 before before starting to do courses\\n20:27 okay now we are we I will talk about\\n20:30 those who already do the course but\\n20:32 before doing the courses and start doing\\n20:35 like applying for jobs take some times\\n20:38 and reflect on your profile what do you\\n20:42 have as uh as skills what do you have as\\n20:47 strengths and what do you have as uh\\n20:50 qualifications of course qualifications\\n20:53 strengths skills and then what do you\\n20:55 have as experience so taking into\\n20:59 consideration all of these in addition\\n21:01 to\", 'video_id': 'PchwbIs0tOg', '_id': 4616}, {'start': 16500, 'content': \" towards data\\n17:21 science career\\n17:22 and in universities there were a lot of\\n17:25 freedom to choose\\n17:26 and i have chosen the most\\n17:29 the hardest courses i would say because\\n17:33 yeah i was really interested in it i\\n17:34 choose two machine learning classes\\n17:36 uh like supervised and unsupervised\\n17:40 then two artificial intelligence classes\\n17:42 they are quite different but they speak\\n17:44 about the same\\n17:45 problems but from different angles then\\n17:48 multivariate analysis\\n17:49 statistics time series analysis graph\\n17:52 theory\\n17:53 networks analysis and all this\\n17:55 mathematical stuff\\n17:58 i felt that i i knew mars\\n18:01 and probably i can tackle those courses\\n18:04 and\\n18:04 yeah so it was quite uh\\n18:09 focused on data science right so because\\n18:11 you could select the courses you wanted\\n18:14 so you you knew what you wanted to study\\n18:16 and you\\n18:17 picked up courses that you thought that\\n18:20 will be super useful for your career\\n18:22 like machine learning artificial\\n18:23 intelligence statistics and\\n18:26 yeah because in my from my previous\\n18:28 experience as a project manager i absorb\\n18:30 the problems\\n18:30 i i i know what business needs or at\\n18:33 least have an impression that they know\\n18:34 it\\n18:35 and i try to base my choice of courses\\n18:37 based on\\n18:38 what i observed in the business so it's\\n18:40 it's also another benefit\\n18:42 to go to mass program after having some\\n18:44 experience\\n18:45 because you kind of understand what you\\n18:48 will be\\n18:49 resolving uh later on in the work and\\n18:51 why you have to choose\\n18:53 this or that yeah so i can already see\\n18:56 how your\\n18:57 uh background as project manager was\\n18:59 useful\\n19:00 yeah it feels like it was very carefully\\n19:03 planned\\n19:03 uh like the the way you approached your\\n19:06 studies uh\\n19:07 uh like you you knew what you wanted to\\n19:10 to do and\\n19:11 you just went for this so that's uh\\n19:13 that's uh that's really cool\\n19:15 um and um yeah i i know we already\\n19:18 talked about\\n19:19 uh online courses um and you perhaps had\\n19:22 the chance to compare these online\\n19:24 courses and\\n19:26 [Music]\\n19:27 the courses you took at university what\\n19:29 is your opinion like how they are\\n19:32 different and what worked better for you\\n19:36 yeah probably here i can even give\\n19:38 advices to people\\n19:39 who are interested and probably choose\\n19:42 between\\n19:42 having none a degree online and going to\\n19:46 university\\n19:47 um i have some experience in it uh\\n19:50 basically\\n19:50 useful courses uh it's um\\n19:54 uh it depends on your purpose here uh\\n19:57 always\\n19:58 and if you want to pick up some\\n20:00 knowledge about some specific\\n20:02 uh package to analyze or visualize data\\n20:05 it's enough to just go to code academy\\n20:08 and just speak the first\\n20:10 course that explains you this semantic\\n20:12 and\\n20:13 to to give some example and you just\\n20:15 learn it immediately for one or two\\n20:17 evenings\\n20:18 it's another story but if\", 'video_id': 'rBKezdb9jEc', '_id': 5108}, {'start': 18000, 'content': \" you\\n18:48 will be\\n18:49 resolving uh later on in the work and\\n18:51 why you have to choose\\n18:53 this or that yeah so i can already see\\n18:56 how your\\n18:57 uh background as project manager was\\n18:59 useful\\n19:00 yeah it feels like it was very carefully\\n19:03 planned\\n19:03 uh like the the way you approached your\\n19:06 studies uh\\n19:07 uh like you you knew what you wanted to\\n19:10 to do and\\n19:11 you just went for this so that's uh\\n19:13 that's uh that's really cool\\n19:15 um and um yeah i i know we already\\n19:18 talked about\\n19:19 uh online courses um and you perhaps had\\n19:22 the chance to compare these online\\n19:24 courses and\\n19:26 [Music]\\n19:27 the courses you took at university what\\n19:29 is your opinion like how they are\\n19:32 different and what worked better for you\\n19:36 yeah probably here i can even give\\n19:38 advices to people\\n19:39 who are interested and probably choose\\n19:42 between\\n19:42 having none a degree online and going to\\n19:46 university\\n19:47 um i have some experience in it uh\\n19:50 basically\\n19:50 useful courses uh it's um\\n19:54 uh it depends on your purpose here uh\\n19:57 always\\n19:58 and if you want to pick up some\\n20:00 knowledge about some specific\\n20:02 uh package to analyze or visualize data\\n20:05 it's enough to just go to code academy\\n20:08 and just speak the first\\n20:10 course that explains you this semantic\\n20:12 and\\n20:13 to to give some example and you just\\n20:15 learn it immediately for one or two\\n20:17 evenings\\n20:18 it's another story but if you really\\n20:20 want to understand the deep\\n20:21 um nature of of data science concept and\\n20:25 so on\\n20:26 um i would i can recommend you some nice\\n20:29 uh courses online courses that help me i\\n20:32 didn't do it during my university\\n20:34 because uh during the study i took a lot\\n20:37 of classes and also i\\n20:38 i worked as a researcher and i had an\\n20:41 enough practice\\n20:42 and knowledge and knowledge to consume\\n20:45 and people to ask\\n20:46 it was a full learning process but after\\n20:50 and when i graduated i realized that\\n20:52 okay sometimes\\n20:53 when you do some one thing you might\\n20:56 forget\\n20:57 something else and you have to refresh\\n20:59 your knowledge and what i prefer\\n21:01 i am doing some classes on machine\\n21:02 learning every year\\n21:04 uh just to refresh knowledge about\\n21:06 everything\\n21:07 and because usually at work you don't\\n21:09 use everything that you learned\\n21:11 but it's still important to have in mind\\n21:13 and\\n21:14 i personally find this fundamental\\n21:17 online class\\n21:18 what i could recommend there is a open\\n21:20 data science community\\n21:22 and they provide i know definitely once\\n21:25 per year\\n21:28 this online course and designed by\\n21:31 yuri kashnicki a super\\n21:34 well structured course which get your\\n21:37 deep understanding of the algorithm and\\n21:39 also provide a lot of practice\\n21:41 and you can communicate with\\n21:44 tutors and also get feedbacks and\\n21:47 you also communicate with peers and\\n21:50 learn from them i per\", 'video_id': 'rBKezdb9jEc', '_id': 5109}, {'start': 13500, 'content': \"at you enjoy\\n16:14 you you are interested in doing so you\\n16:16 start to collect okay these tasks I like\\n16:18 to do these now this technology I'm\\n16:21 interested to to learn about it this\\n16:24 technology not so this is part of\\n16:27 research and uh the job description but\\n16:31 not only that the other thing is doing\\n16:34 connecting with people who are doing the\\n16:36 job so let's say I found I found um\\n16:41 that's last time I found a Flink so\\n16:44 that's by example like playing that have\\n16:46 uh uh job advertisement for data\\n16:50 scientist then I see is there\\n16:52 any uh people that I can connect with\\n16:56 who work it at the company or are\\n16:59 currently working at fling so that I can\\n17:02 uh ask them about how is it to work\\n17:05 there what do you do on your on a daily\\n17:07 day-to-day\\n17:09 basis and this uh helps to discover the\\n17:13 alignment exactly by going through the\\n17:16 process of researching talking to doing\\n17:18 informational interviews which is a\\n17:20 strategy that I really like because it\\n17:23 gives you another perspective I used it\\n17:26 myself when I was doing my care career\\n17:28 transition and even as I look at how I\\n17:31 want to grow further in my position I I\\n17:34 do informational interviews with\\n17:36 different people so that I figure out\\n17:39 what would be the thing that is right\\n17:42 for\\n17:46 me yeah and I'm a bit sidet tracking Sid\\n17:49 tracking again so yes it's fine I hope\\n17:52 it's fine so the problem that I\\n17:56 personally have not me personally but\\n17:58 like the problem\\n18:00 that let me take a step back so in our\\n18:03 community we have courses right so right\\n18:05 now we have three courses free different\\n18:06 courses so ml engineering course data\\n18:09 engineering course and mops course while\\n18:11 the first and the last one are kind of\\n18:13 similar the data engineering course is\\n18:16 quite different so it's a different kind\\n18:17 of job right so then people take all\\n18:20 these courses so they take the\\n18:21 engineering the data engineering course\\n18:23 the ml engineering course and they say\\n18:25 okay I like all the courses M all of\\n18:29 them right what's the third so ml\\n18:31 engineering data engineering and the\\n18:33 third mops mops okay okay so and then\\n18:37 the students come and say like we took\\n18:39 the courses and we like all of them and\\n18:42 I want to do all of this stuff right and\\n18:44 this is a lot right so you cannot be you\\n18:46 cannot like you can but like it's\\n18:48 difficult to be a jack of all trades\\n18:50 right especially if you're only starting\\n18:51 your career and you you need to figure\\n18:53 out what exactly from these\\n18:57 directions where exactly do I want to go\\n19:00 and what sometimes happens\\n19:03 is the students just apply to everything\\n19:06 right so they apply to data engineering\\n19:07 position mlops position ml engineering\\n19:10 positions like all of them right yeah\\n19:14 like I am not sure if it's a good thing\\n19:17 or a bad thing maybe you can tell \", 'video_id': 'PchwbIs0tOg', '_id': 4615}, {'start': 27000, 'content': \"be they have a phd in physics\\n23:56 or\\n23:57 you know what i'm talking about like\\n23:58 they are maybe coming from academia and\\n24:00 then there is another oh\\n24:03 another kind of way\\n24:05 is people who are software engineers and\\n24:07 they get into data science\\n24:09 and i guess if well there is also a\\n24:12 third way now people who graduate from\\n24:14 universities and become data scientists\\n24:17 immediately right yeah i think this is\\n24:19 also a thing right now so many people\\n24:21 for them data science is the first job i\\n24:24 guess for\\n24:25 for those who are software engineers and\\n24:27 they become became data scientists it's\\n24:30 not\\n24:30 that difficult to then transition to\\n24:32 data engineering because they already\\n24:34 have all the skills they know how to use\\n24:36 um\\n24:37 terminal properly they know barcelona\\n24:39 linux and icd all these things that i\\n24:42 needed for\\n24:44 data engineer right but what about\\n24:47 this who are coming from academia or\\n24:49 this who for who\\n24:51 data science is their first job like how\\n24:54 can they actually level up their\\n24:55 software engineering skills do you know\\n24:59 if there is a good course about that\\n25:01 somewhere\\n25:04 yeah\\n25:05 there are good courses about this\\n25:09 i\\n25:10 i mean data camp is not really\\n25:12 recommended anymore for for various\\n25:14 reasons but that used to be my go-to\\n25:16 place to because they had a really good\\n25:17 um engineering track\\n25:19 um\\n25:21 but there are other place there are\\n25:23 online courses that focus and i would\\n25:25 always recommend for data scientists who\\n25:27 want to live up on on\\n25:29 programming skills to take one of those\\n25:31 intro to software engineering courses\\n25:32 and even if it's web development or\\n25:34 something totally unrelated that they're\\n25:35 not really that interested in but\\n25:38 something that's not ideal that data\\n25:40 scientists because that in the\\n25:41 programming for data scientist courses\\n25:43 they usually don't learn the software\\n25:44 engineering fundamentals but\\n25:46 something that's more of a track to\\n25:48 become a web developer or an android\\n25:50 developer even or something like that\\n25:52 they usually teach you the software\\n25:54 engineering fundamentals in those\\n25:55 courses so i would recommend to try that\\n25:57 and it's always useful if you can build\\n25:59 a small web app or you can build a small\\n26:01 android app it's not a wasted skill\\n26:04 and and that's maybe a better way to\\n26:06 find out if you're interested in these\\n26:07 kind of things than to figure out than\\n26:09 to\\n26:11 purely focus on the on your python\\n26:13 skills and\\n26:15 learning yet another\\n26:17 deep learning library\\n26:20 yeah so what do you think a good\\n26:22 course should contain what kind of\\n26:24 things so i guess uh build tools right\\n26:27 like how exactly you build your\\n26:29 uh\\n26:30 your software right and testing ci cd\\n26:34 command line basics like how do you\\n26:37 navigate\\n26:39 i don't know linux how do y\", 'video_id': '3TTu-hYzxeg', '_id': 633}]\n"
     ]
    }
   ],
   "source": [
    "stage1 = await do_research(\n",
    "    stage=1,\n",
    "    stage_instructions=research_task.model_dump_json(),\n",
    "    previous_stages=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5aa790ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResearchStageReport(stage=1, explored_keywords=[ResearchKeyword(keyword='data engineering learning path for beginners', relevant_references=[Reference(document_id=2965, quote='so definitely i felt that before I had that sort of guidance I was just kind of fumbling around in the dark reading a lot of different articles...', timestamp='19:40', relevance_to_keyword='This quote highlights that having guidance is critical for following an effective learning path in data engineering, especially for beginners.', relevance_to_user_intent='It illustrates the importance of finding clear directions for learning data engineering.')]), ResearchKeyword(keyword='essential skills for data engineers', relevant_references=[Reference(document_id=7527, quote='I would say the most important one is coding skills...', timestamp='11:33', relevance_to_keyword='This snippet points out that coding skills are fundamental for data engineers, emphasizing the skills necessary for the role.', relevance_to_user_intent='It provides insights into the skills required for those starting in data engineering.')]), ResearchKeyword(keyword='best online courses for data engineering', relevant_references=[Reference(document_id=643, quote='There are good courses about this...', timestamp='25:04', relevance_to_keyword='This segment highlights available courses that focus on data engineering skills crucial for beginners.', relevance_to_user_intent='It suggests resources for structured learning in data engineering.')]), ResearchKeyword(keyword='data engineering tools and technologies', relevant_references=[Reference(document_id=2283, quote='...you can see them as tools solving different pieces of the puzzle.', timestamp='38:24', relevance_to_keyword='This snippet provides insight into the various tools available for data engineering and how they can be utilized.', relevance_to_user_intent='It informs the user about tools that are important for practical application in data engineering.')]), ResearchKeyword(keyword='step-by-step guide to becoming a data engineer', relevant_references=[Reference(document_id=618, quote='...you have to acquire a new skill set but when this data paradigm is shifting right...', timestamp='4:02', relevance_to_keyword='This quote implies that to transition into data engineering, one must adapt to new methodologies and skills.', relevance_to_user_intent='It suggests a trajectory for skill acquisition necessary for becoming a data engineer.')])], verifiable_insights=[VerifiableInsight(insight='Guidance is essential for beginners in data engineering to avoid confusion and streamline their learning path.', references=[Reference(document_id=2965, quote='so definitely i felt that before I had that sort of guidance I was just kind of fumbling around in the dark...', timestamp='19:40', relevance_to_keyword='This quote highlights the difficulty beginners face without clear guidance.', relevance_to_user_intent='It underscores the need for a structured learning approach.')]), VerifiableInsight(insight='Coding skills are deemed the most important for success in data engineering roles, according to experts in the field.', references=[Reference(document_id=7527, quote='...most important one is coding skills...', timestamp='11:33', relevance_to_keyword='This statement emphasizes the priority of coding abilities for data engineers.', relevance_to_user_intent='It identifies key skills necessary for users to develop.')]), VerifiableInsight(insight='There are numerous online courses available that focus on essential skills and practices in data engineering.', references=[Reference(document_id=643, quote='There are good courses about this...', timestamp='25:04', relevance_to_keyword='This indicates a variety of educational resources accessible to newcomers.', relevance_to_user_intent='It points readers toward structured learning options.')]), VerifiableInsight(insight='Understanding various tools and technologies used in data engineering is crucial for practical application in the field.', references=[Reference(document_id=2283, quote='...tools solving different pieces of the puzzle.', timestamp='38:24', relevance_to_keyword='This highlights the diversity of tools and their purposes in data engineering.', relevance_to_user_intent='It emphasizes the need to be familiar with various technologies.')]), VerifiableInsight(insight='Becoming a data engineer involves acquiring a new skill set and adapting to evolving data paradigms.', references=[Reference(document_id=618, quote='...you have to acquire a new skill set but when this data paradigm is shifting...', timestamp='4:02', relevance_to_keyword='This segment suggests a path forward for skill development.', relevance_to_user_intent='It indicates the dynamic nature of the data engineering field.')])], stage_summary='In this initial research stage, we identified key resources and insights for beginners aiming to start a career in data engineering. Primary themes emerged around the necessity of guidance and the importance of acquiring coding skills, alongside recommendations for online courses and tools essential for practical application in the field. A clear learning path was recognized as critical to navigate the complexities of entering this profession.', recommended_next_steps='For the next stage, it would be beneficial to explore the specific learning pathways that practitioners recommend and delve deeper into the practical applications and projects that can reinforce these skills.', recommended_next_keywords=['data engineering projects for beginners', 'advanced data engineering skills', 'career transitions to data engineering', 'mentorship in data engineering', 'data engineering certifications', 'real-world data engineering examples', 'data engineering interview preparation'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc19727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"stage\": 1,\n",
      "  \"explored_keywords\": [\n",
      "    {\n",
      "      \"keyword\": \"data engineering learning path for beginners\",\n",
      "      \"relevant_references\": [\n",
      "        {\n",
      "          \"document_id\": 2965,\n",
      "          \"quote\": \"so definitely i felt that before I had that sort of guidance I was just kind of fumbling around in the dark reading a lot of different articles...\",\n",
      "          \"timestamp\": \"19:40\",\n",
      "          \"relevance_to_keyword\": \"This quote highlights that having guidance is critical for following an effective learning path in data engineering, especially for beginners.\",\n",
      "          \"relevance_to_user_intent\": \"It illustrates the importance of finding clear directions for learning data engineering.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"essential skills for data engineers\",\n",
      "      \"relevant_references\": [\n",
      "        {\n",
      "          \"document_id\": 7527,\n",
      "          \"quote\": \"I would say the most important one is coding skills...\",\n",
      "          \"timestamp\": \"11:33\",\n",
      "          \"relevance_to_keyword\": \"This snippet points out that coding skills are fundamental for data engineers, emphasizing the skills necessary for the role.\",\n",
      "          \"relevance_to_user_intent\": \"It provides insights into the skills required for those starting in data engineering.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"best online courses for data engineering\",\n",
      "      \"relevant_references\": [\n",
      "        {\n",
      "          \"document_id\": 643,\n",
      "          \"quote\": \"There are good courses about this...\",\n",
      "          \"timestamp\": \"25:04\",\n",
      "          \"relevance_to_keyword\": \"This segment highlights available courses that focus on data engineering skills crucial for beginners.\",\n",
      "          \"relevance_to_user_intent\": \"It suggests resources for structured learning in data engineering.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"data engineering tools and technologies\",\n",
      "      \"relevant_references\": [\n",
      "        {\n",
      "          \"document_id\": 2283,\n",
      "          \"quote\": \"...you can see them as tools solving different pieces of the puzzle.\",\n",
      "          \"timestamp\": \"38:24\",\n",
      "          \"relevance_to_keyword\": \"This snippet provides insight into the various tools available for data engineering and how they can be utilized.\",\n",
      "          \"relevance_to_user_intent\": \"It informs the user about tools that are important for practical application in data engineering.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"step-by-step guide to becoming a data engineer\",\n",
      "      \"relevant_references\": [\n",
      "        {\n",
      "          \"document_id\": 618,\n",
      "          \"quote\": \"...you have to acquire a new skill set but when this data paradigm is shifting right...\",\n",
      "          \"timestamp\": \"4:02\",\n",
      "          \"relevance_to_keyword\": \"This quote implies that to transition into data engineering, one must adapt to new methodologies and skills.\",\n",
      "          \"relevance_to_user_intent\": \"It suggests a trajectory for skill acquisition necessary for becoming a data engineer.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"verifiable_insights\": [\n",
      "    {\n",
      "      \"insight\": \"Guidance is essential for beginners in data engineering to avoid confusion and streamline their learning path.\",\n",
      "      \"references\": [\n",
      "        {\n",
      "          \"document_id\": 2965,\n",
      "          \"quote\": \"so definitely i felt that before I had that sort of guidance I was just kind of fumbling around in the dark...\",\n",
      "          \"timestamp\": \"19:40\",\n",
      "          \"relevance_to_keyword\": \"This quote highlights the difficulty beginners face without clear guidance.\",\n",
      "          \"relevance_to_user_intent\": \"It underscores the need for a structured learning approach.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"insight\": \"Coding skills are deemed the most important for success in data engineering roles, according to experts in the field.\",\n",
      "      \"references\": [\n",
      "        {\n",
      "          \"document_id\": 7527,\n",
      "          \"quote\": \"...most important one is coding skills...\",\n",
      "          \"timestamp\": \"11:33\",\n",
      "          \"relevance_to_keyword\": \"This statement emphasizes the priority of coding abilities for data engineers.\",\n",
      "          \"relevance_to_user_intent\": \"It identifies key skills necessary for users to develop.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"insight\": \"There are numerous online courses available that focus on essential skills and practices in data engineering.\",\n",
      "      \"references\": [\n",
      "        {\n",
      "          \"document_id\": 643,\n",
      "          \"quote\": \"There are good courses about this...\",\n",
      "          \"timestamp\": \"25:04\",\n",
      "          \"relevance_to_keyword\": \"This indicates a variety of educational resources accessible to newcomers.\",\n",
      "          \"relevance_to_user_intent\": \"It points readers toward structured learning options.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"insight\": \"Understanding various tools and technologies used in data engineering is crucial for practical application in the field.\",\n",
      "      \"references\": [\n",
      "        {\n",
      "          \"document_id\": 2283,\n",
      "          \"quote\": \"...tools solving different pieces of the puzzle.\",\n",
      "          \"timestamp\": \"38:24\",\n",
      "          \"relevance_to_keyword\": \"This highlights the diversity of tools and their purposes in data engineering.\",\n",
      "          \"relevance_to_user_intent\": \"It emphasizes the need to be familiar with various technologies.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"insight\": \"Becoming a data engineer involves acquiring a new skill set and adapting to evolving data paradigms.\",\n",
      "      \"references\": [\n",
      "        {\n",
      "          \"document_id\": 618,\n",
      "          \"quote\": \"...you have to acquire a new skill set but when this data paradigm is shifting...\",\n",
      "          \"timestamp\": \"4:02\",\n",
      "          \"relevance_to_keyword\": \"This segment suggests a path forward for skill development.\",\n",
      "          \"relevance_to_user_intent\": \"It indicates the dynamic nature of the data engineering field.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"stage_summary\": \"In this initial research stage, we identified key resources and insights for beginners aiming to start a career in data engineering. Primary themes emerged around the necessity of guidance and the importance of acquiring coding skills, alongside recommendations for online courses and tools essential for practical application in the field. A clear learning path was recognized as critical to navigate the complexities of entering this profession.\",\n",
      "  \"recommended_next_steps\": \"For the next stage, it would be beneficial to explore the specific learning pathways that practitioners recommend and delve deeper into the practical applications and projects that can reinforce these skills.\",\n",
      "  \"recommended_next_keywords\": [\n",
      "    \"data engineering projects for beginners\",\n",
      "    \"advanced data engineering skills\",\n",
      "    \"career transitions to data engineering\",\n",
      "    \"mentorship in data engineering\",\n",
      "    \"data engineering certifications\",\n",
      "    \"real-world data engineering examples\",\n",
      "    \"data engineering interview preparation\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(stage1.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df08627e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALL → search {'query': 'data engineering projects for beginners'} call_U3tErpkDZvjWV6rtiO3RFtho\n",
      "CALL → search {'query': 'advanced data engineering skills'} call_jK1GMwxZ1fz9z3GfI0AbOnC2\n",
      "CALL → search {'query': 'career transitions to data engineering'} call_KPyHfQs0oO7Bv344WhMJzqqb\n",
      "CALL → search {'query': 'mentorship in data engineering'} call_44iCrRmO8DY3AuQoVMWECe5K\n",
      "CALL → search {'query': 'data engineering certifications'} call_iAH9afrQLxz8BQPDMTl4YjTf\n",
      "CALL → search {'query': 'real-world data engineering examples'} call_5B1uTYNGHzMUPwLZQdn6H9fO\n",
      "CALL → search {'query': 'data engineering interview preparation'} call_I1zHYs2jFV46b525GqTYZBYw\n",
      "RES  ← search call_U3tErpkDZvjWV6rtiO3RFtho [{'start': 1500, 'content': \"during the interview and that's\\n1:33 all i have\\n1:37 for the introduction are you ready to\\n1:38 start yeah\\n1:40 okay so let me just\\n1:47 pull my notes\\n1:52 okay we have um today we will talk about\\n1:55 uh the difference between uh\\n1:57 big data engineers and data scientists\\n2:00 and we have special guests today\\n2:02 rexella ruxlana works as a big data\\n2:04 engineer\\n2:05 in uh captify right yeah and\\n2:09 uh yeah so today she will talk about\\n2:13 the role of a data engineer and data\\n2:14 scientist welcome\\n2:17 thank you before we go before we start\\n2:20 with our\\n2:21 main topic let's talk a bit about your\\n2:24 background\\n2:25 can you tell us a bit about your career\\n2:26 journey so far\\n2:28 yeah sure so i have a software\\n2:31 engineering degree\\n2:32 in one of the key universities it's both\\n2:35 bachelor and\\n2:36 master's degree and after that i was\\n2:38 working some time as\\n2:40 a background engineer in java mostly and\\n2:43 just at some point i\\n2:44 learned about data science big data\\n2:46 engineering and\\n2:48 i had some time to make a decision what\\n2:50 exactly i would want to do\\n2:52 and kind of back-end engineering at some\\n2:54 point just got a bit boring for me so\\n2:56 i switched into big data engineering\\n2:59 learned the\\n2:59 scala programming language and that's my\\n3:02 main programming language\\n3:04 now and um for a few years i worked at\\n3:07 a company called sql it's quite famous\\n3:10 in ukraine because it's\\n3:11 quite big company one of the top five\\n3:13 and\\n3:14 it's an outsourcing company which works\\n3:16 with clients and\\n3:18 as well as has some research so i was\\n3:21 working at the\\n3:22 r d department we had some internal\\n3:24 research stuff and\\n3:26 also i worked for some client projects\\n3:28 and\\n3:29 only two years ago i joined captify\\n3:32 which is\\n3:33 a product company they are building a\\n3:35 product in the sphere of\\n3:37 advertising and actually a company is\\n3:40 british it's based in uk\\n3:41 but it has a part of the engineering\\n3:44 team in cave\\n3:44 where i'm based and mostly working on\\n3:48 the product part specifically\\n3:50 in the big data engineering team\\n3:53 yeah i've heard that in advertising\\n3:55 there are there is so much data\\n3:57 that this data engineering big data\\n4:00 engineering becomes really important\\n4:01 because\\n4:02 these companies every day gets get\\n4:04 terabytes of data and they need to\\n4:06 effectively\\n4:07 uh process this data right yeah\\n4:10 and also what kind of makes uh the\\n4:12 solution of creptify unique\\n4:14 is data insights which are obviously\\n4:17 delivered to the help of\\n4:19 big data engineering team by having\\n4:21 different\\n4:22 sources of data and ways to transform\\n4:24 this data and deliver it to the clients\\n4:27 so what do you do at work uh what do you\\n4:29 usually do\\n4:30 as a big data engineer so my main\\n4:33 responsibility is building data\\n4:35 pipelines uh usually it's etl format\\n4:37 extract transform load so kind of\\n4:39 reading the data from some source\\n4:42 building transformations s\", 'video_id': 'yg3d1lFd7Uo', '_id': 7522}, {'start': 4500, 'content': \"alized\\n4:14 i didn't really enjoy data science as\\n4:16 much because it was very black box it\\n4:18 fell to me because i never was felt like\\n4:20 i was feeding some model but i didn't\\n4:22 really understand what's going on which\\n4:23 is partially due to the fact that my\\n4:24 mathematics background isn't that strong\\n4:27 so i didn't never really got the theory\\n4:29 behind it\\n4:30 but also i realized i kind of miss more\\n4:32 the engineering parts of it and\\n4:34 that was also the time when data\\n4:36 engineering became more of a thing\\n4:37 because companies realized that they\\n4:38 need not just data scientists but also\\n4:40 people that actually before come before\\n4:42 them and\\n4:43 make data available for data science\\n4:45 because that's at the time was a common\\n4:47 frustration for data scientists to not\\n4:48 have data\\n4:51 great ambitions but no data\\n4:54 and then i went\\n4:56 got an offer at native instruments to be\\n4:58 one of their first data engineers\\n5:01 i did that for a while um i still had\\n5:04 the ambition back then to transition\\n5:05 back into data science but i left native\\n5:07 instruments for unrelated reasons before\\n5:10 that happened\\n5:12 then i got another job at another\\n5:13 company as a bi developer\\n5:18 my title was data scientists but really\\n5:19 what i did was\\n5:21 develop custom\\n5:23 with data visualizations\\n5:26 and i realized eventually that this was\\n5:28 kind of a dead end for me\\n5:30 and so i\\n5:32 i remembered my software engineering\\n5:34 background which i actually enjoyed\\n5:36 except it was a repetitive and then\\n5:38 at the time i was speaking to somebody\\n5:40 at thoughtworks she was the first data\\n5:42 scientist at the thoughtworks in germany\\n5:44 at the time and she told me that\\n5:46 thoughtworks was planning to expand its\\n5:48 data engineering offering and what i'd\\n5:49 be interested in\\n5:52 in becoming the solidworks germany's\\n5:54 first data engineer and help her expand\\n5:56 that offering and i thought it was\\n5:58 really exciting and\\n5:59 especially since southwark is a great\\n6:01 place for really learning good software\\n6:03 engineering practices which as a data\\n6:05 engineer is always frustrated as a data\\n6:07 scientist that always frustrated me that\\n6:09 the quality of the code and the\\n6:11 collaboration wasn't as good as i was i\\n6:13 remembered it from my back in\\n6:14 engineering days\\n6:16 and so i jumped on that and that's when\\n6:17 i finally decided to stay in data\\n6:19 engineering which i had done on and off\\n6:21 before\\n6:23 and then then yeah after that was i went\\n6:26 to where i'm now it was my transfers and\\n6:28 built up data engineering there which\\n6:29 way i'm now heading a team\\n6:32 that's quite a story and thanks for\\n6:33 sharing so uh what i also wanted to ask\\n6:36 you the next question i prepared is that\\n6:38 you were a data scientist and then you\\n6:40 switched to data engineering and i\\n6:41 wanted to ask why i think you partly\\n6:43 answered that so you said that\\n6:47 data science was a bit too black boxy\", 'video_id': '3TTu-hYzxeg', '_id': 618}, {'start': 10500, 'content': \" i've\\n9:37 experienced it in quite a few places\\n9:41 and uh but as a data engineer i guess as\\n9:44 a data scientist you already needed to\\n9:46 do some things that data engineers would\\n9:48 do right so you mentioned that at\\n9:50 soundcloud so you not only did modeling\\n9:54 but also everything that it was before\\n9:55 modeling like building data pipelines\\n9:58 and after modeling i guess deploying the\\n10:00 model so how does it overlap with what\\n10:04 data engineers usually do what you did\\n10:05 as a data scientist yes there's a lot of\\n10:07 overlap and\\n10:09 so there as the data scientists usually\\n10:12 are often you you don't work with\\n10:14 perfectly clean and perfectly delivered\\n10:16 data you will still build up your own\\n10:18 pipelines to make the data accessible\\n10:20 and especially if you move into more\\n10:23 production level\\n10:25 and\\n10:26 i mean the\\n10:27 data size is a very loose title and what\\n10:29 you do under this role can be very\\n10:30 different but there's often a lot of\\n10:33 pipelining work that you do on yourself\\n10:35 and i think\\n10:36 it's a good thing that data scientists\\n10:38 do that and don't just rely on data\\n10:40 engineers to kind of do handhold them\\n10:42 through these steps\\n10:45 and so there's a lot of transferable\\n10:46 skills it also depends great and also\\n10:48 data engineering is a very broad topic\\n10:51 and i never did the more kafka real-time\\n10:53 data engineering kind of stuff i've\\n10:54 carefully navigated myself around that\\n10:57 i've always done more what is now\\n10:58 considered analytics engineering maybe\\n11:01 which is more like the preparing data\\n11:03 for vi and data warehouses and\\n11:06 scheduling batch processing and all\\n11:08 these kind of things\\n11:10 so that was more my realm of data\\n11:12 engineering\\n11:13 and there's there's a this whole other\\n11:15 universe of data engineering that i've\\n11:16 never really touched and that i don't\\n11:18 feel i think where you need a better\\n11:20 understanding of distributed system and\\n11:21 things like that which i don't have\\n11:23 and so that is that's often more the\\n11:25 playground for people with a really\\n11:27 strong distributed computer science\\n11:29 background\\n11:31 and that isn't just not my round but in\\n11:33 for another for anything that's more in\\n11:35 the world of what is now analytics\\n11:36 engineering that kind of branch of data\\n11:38 engineering i think data scientists are\\n11:40 very well prepared there's obviously\\n11:42 things we need to learn but it there's a\\n11:44 lot\\n11:45 i've seen of i've often found that\\n11:47 people that come from peers of\\n11:49 engineering don't have a feeling for\\n11:50 data that they struggle more to move\\n11:52 into that space than people that come\\n11:54 that have a data science background and\\n11:56 just need to level up on\\n11:58 software engineering and collaboration\\n12:00 skills\\n12:01 what is this feeling of data in your\\n12:04 opinion what is that\\n12:06 yeah that that means understanding\\n12:08 it's a lot of things about\", 'video_id': '3TTu-hYzxeg', '_id': 622}, {'start': 12000, 'content': \"ways done more what is now\\n10:58 considered analytics engineering maybe\\n11:01 which is more like the preparing data\\n11:03 for vi and data warehouses and\\n11:06 scheduling batch processing and all\\n11:08 these kind of things\\n11:10 so that was more my realm of data\\n11:12 engineering\\n11:13 and there's there's a this whole other\\n11:15 universe of data engineering that i've\\n11:16 never really touched and that i don't\\n11:18 feel i think where you need a better\\n11:20 understanding of distributed system and\\n11:21 things like that which i don't have\\n11:23 and so that is that's often more the\\n11:25 playground for people with a really\\n11:27 strong distributed computer science\\n11:29 background\\n11:31 and that isn't just not my round but in\\n11:33 for another for anything that's more in\\n11:35 the world of what is now analytics\\n11:36 engineering that kind of branch of data\\n11:38 engineering i think data scientists are\\n11:40 very well prepared there's obviously\\n11:42 things we need to learn but it there's a\\n11:44 lot\\n11:45 i've seen of i've often found that\\n11:47 people that come from peers of\\n11:49 engineering don't have a feeling for\\n11:50 data that they struggle more to move\\n11:52 into that space than people that come\\n11:54 that have a data science background and\\n11:56 just need to level up on\\n11:58 software engineering and collaboration\\n12:00 skills\\n12:01 what is this feeling of data in your\\n12:04 opinion what is that\\n12:06 yeah that that means understanding\\n12:08 it's a lot of things about data so data\\n12:10 as you know i don't have to tell you is\\n12:12 very complex so it has all these how\\n12:14 it's produced all the quality the\\n12:16 statistical aspects of it understanding\\n12:18 what the data actually means how it's\\n12:20 structured how it how it evolves\\n12:23 and for a software engineer and i\\n12:25 remember that from my software\\n12:26 engineering latest often just something\\n12:27 that we don't really worry about just\\n12:29 something we type in and out but we\\n12:30 don't really worry what it is\\n12:32 some json right so some json or xml file\\n12:36 you just get it\\n12:37 you do something with this and then you\\n12:39 spit it out and then something happens\\n12:41 after that right\\n12:42 but the big part of data engineering is\\n12:44 really worrying about the quality of\\n12:45 your data that's probably the biggest\\n12:47 challenge for that data data science\\n12:49 that's something that data scientists\\n12:50 are very familiar with data quality\\n12:52 issues and how to deal with them and\\n12:55 what to do about them and\\n12:57 having these conversations around with\\n12:59 the people that collect the data produce\\n13:00 the data and all these kind of things\\n13:03 [Music]\\n13:04 but he also mentioned that you were\\n13:06 doing more work of what is called today\\n13:08 analytics engineer\\n13:10 rather than\\n13:11 uh you know kafka distributed system\\n13:14 kind of data engineer so do you think\\n13:16 this uh worrying about data quality\\n13:18 applies to all data engineers regardless\\n13:20 \", 'video_id': '3TTu-hYzxeg', '_id': 623}, {'start': 6000, 'content': \"u know other things like\\n6:08 within a team deciding for some approach\\n6:11 or sometimes conflict resolutions right\\n6:14 and one of the most important tasks for\\n6:16 data hinging manager or any engineering\\n6:18 manager should be prioritizing the task\\n6:21 right you have lot of things coming on\\n6:23 your way right from various stakeholders\\n6:26 so how you\\n6:27 prioritize that that's one of the key\\n6:30 responsibilities as well\\n6:32 so you work on a data platform some\\n6:35 internal data platform right and you\\n6:37 manage the engineers right\\n6:40 and because the the setup we have to\\n6:43 elix is we have engineering managers\\n6:47 and\\n6:48 people who report to the engineering\\n6:50 managers are back-end engineers\\n6:52 front-end engineers and data engineers\\n6:55 right so\\n6:57 we don't have a role that is called data\\n6:58 engineering manager and usually there is\\n7:01 just an engineering manager who manages\\n7:03 the engineers\\n7:05 and i'm wondering why do we have this um\\n7:08 maybe because we work in so-called\\n7:11 feature teams like a team that works on\\n7:13 a specific\\n7:15 part of a product and everyone works on\\n7:17 the same thing while in your case your\\n7:19 team takes care of the other platform so\\n7:21 everyone on your team is a data engineer\\n7:23 right\\n7:24 absolutely yeah\\n7:26 correct yeah\\n7:28 and i guess it's helpful for data\\n7:30 engineers to have a manager who is also\\n7:32 a data engineer or at least who can\\n7:34 relate to the problems they have because\\n7:36 this is how they can\\n7:38 think what is the best way for the\\n7:41 development for coaching right and if we\\n7:44 have just a usual\\n7:46 engineering manager they might not\\n7:48 know in a lot of details about you know\\n7:51 new data tools and so on right that's\\n7:53 where you come into play into picture\\n7:56 and then this is you if you give\\n7:58 suggestions to people you tell them what\\n8:00 is good to learn right\\n8:02 yeah i think you mentioned very valid\\n8:04 point right um this role when i talk to\\n8:07 other engineering managers i realized\\n8:08 that as a data engineering manager you\\n8:11 have to\\n8:12 be in line with some hands-on activities\\n8:15 as well so you should know what your\\n8:16 team is working upon at the code level\\n8:18 sometimes right\\n8:20 so that's that's how i spend my time\\n8:22 like i wear two heads here so 50 of the\\n8:25 time i am working as an individual\\n8:26 contributor as a data engineer in my\\n8:28 team and remaining fifty percent i am uh\\n8:31 managing the team right\\n8:33 so\\n8:33 as you mentioned it uh correctly because\\n8:35 uh sometimes when you when you have\\n8:38 technical brainstorming you know or\\n8:40 maybe defining road maps then your\\n8:42 technical skill sets really comes into\\n8:44 play\\n8:45 so a data engineering manager should\\n8:48 should definitely you know have some\\n8:50 hands on not only just managing people\\n8:54 how do you find time to actually do this\\n8:56 like how large is your team how many\\n8:58 people do you make so currently uh\\n9:00 in i manage eight people s\", 'video_id': 'FljnbUQ796w', '_id': 2284}]\n",
      "RES  ← search call_44iCrRmO8DY3AuQoVMWECe5K [{'start': 34500, 'content': \"58 for it i would recommend to do\\n33:00 long-term mentorship because\\n33:03 it's difficult to understand the entire\\n33:06 context\\n33:07 and background in one conversation\\n33:10 it's always useful to you know um get to\\n33:14 know\\n33:14 each other a little bit more over time\\n33:16 and then you you\\n33:18 really get more productive with the\\n33:20 mental\\n33:21 mentoring process i guess\\n33:24 it makes more sense to find somebody in\\n33:27 your company\\n33:28 in your work workplace for this kind of\\n33:31 relationships right for a long term\\n33:33 mentorship relationship right not\\n33:36 necessarily if your\\n33:38 organization has either a formal program\\n33:41 or informally you know somebody you can\\n33:42 reach out to\\n33:43 i think that works out wonders so yeah\\n33:48 mariam is asking um how do you set\\n33:50 boundaries for long-term\\n33:52 mentorship relationships like uh of\\n33:54 course\\n33:55 uh like you as a mentor you also\\n33:58 you have other things right you cannot\\n34:00 uh spend all your time\\n34:02 helping your mentees and there are\\n34:04 perhaps other things so how do you set\\n34:06 up how do you set these boundaries\\n34:09 yeah and that's really good as i said\\n34:11 earlier right so um\\n34:12 and sometimes it's more meaningful\\n34:15 to have a paid relationship in those\\n34:18 aspects because you know\\n34:20 then both parties are more committed to\\n34:22 it and and it's easier to create those\\n34:24 boundaries and expectations\\n34:26 versus uh just a regular long-term\\n34:28 mentorship because then you don't know\\n34:30 what to expect from each other\\n34:32 um if if that was the question around\\n34:34 boundaries if i understood that question\\n34:36 correctly\\n34:36 yeah i think this is how i understood as\\n34:38 well um\\n34:40 yeah thank you and sometimes you know\\n34:42 it's also about like i have\\n34:43 i have a couple of people i mentor long\\n34:45 term and it's it's it's also about\\n34:49 telling them look it it's not meaningful\\n34:52 to have\\n34:53 a next conversation unless there is a\\n34:55 change in a situation you know\\n34:57 and and it's not just about meeting\\n34:59 every week and talking about things if\\n35:01 it's not if\\n35:02 you want to point it it starts showing\\n35:03 diminishing returns\\n35:05 so just setting those expectations also\\n35:07 clearly often helps in one question\\n35:09 like as a mentor sometimes if someone\\n35:11 reaches out for for regular mentorship i\\n35:13 say do you really want to talk to me\\n35:14 because\\n35:15 is there anything different that we\\n35:17 would talk about versus what we spoke\\n35:19 about\\n35:19 a month ago and if the answer is no then\\n35:21 maybe\\n35:22 there is a there's no point in the\\n35:24 discussion\\n35:25 it's so basically\\n35:29 being mindful uh like from both sides\\n35:32 and\\n35:32 asking hey do you really think we should\\n35:34 have this would be beneficial for\\n35:36 for you to have this uh extra session\\n35:41 okay um yeah so\\n35:45 ruslan is asking what do you think about\\n35:46 paid mentoring i think you\\n35:48 already covered that y\", 'video_id': 'LQvwTNQbPg4', '_id': 4037}, {'start': 48000, 'content': \"rappo with these people these\\n48:42 are huge communities then it becomes a\\n48:44 word of mouth so if you have done like\\n48:47 good networking putter good um good name\\n48:50 to your work um then it becomes a word\\n48:54 of mouth and that's how you kind of\\n48:56 excel in these community-driven uh\\n48:58 programs um because cold emailing or\\n49:01 these stuff can get you into it but like\\n49:04 to build you know a good uh trustworthy\\n49:07 uh relationships or networking as we\\n49:09 call it it's mainly through Word of\\n49:11 Mouth in my opinion yeah actually so now\\n49:16 again speaking of the our conversation\\n49:19 the earlier conversation um so I\\n49:22 scrolled up and saw that we talked about\\n49:24 mentorship and the reason I asked you\\n49:26 about that is because I was doing some\\n49:28 mentorship myself back then so I was\\n49:29 interested in your perspective on these\\n49:33 things and\\n49:35 um for me what was helpful is\\n49:40 uh maybe just structuring my knowledge\\n49:43 around things so people come to you with\\n49:45 requests and then you try to help and\\n49:48 then this way when you speak when you\\n49:50 say things out loud it helps to\\n49:53 structure these things in your head and\\n49:54 then it becomes easier to use this\\n49:57 information like in other settings that\\n49:59 was the main kind of highlight for me\\n50:01 and then like when\\n50:03 people one year after that right hey\\n50:06 like thanks because of the interview\\n50:09 because of the session we did together\\n50:11 like now I work at this company so\\n50:13 thanks a lot you changed my life and\\n50:16 like that's so cool yeah I think uh that\\n50:19 kind of exposure I only got with my U\\n50:22 open-ended mentorship experiences uh\\n50:25 since you work independently you had a\\n50:26 lot of this but I was tied to like more\\n50:29 uh formal organized structures with\\n50:31 these different that I was working with\\n50:33 so there were set expectations and goals\\n50:36 you know less open-ended stuff but there\\n50:39 is more fun in the open-ended stuff\\n50:41 because as you say like once you it's\\n50:43 just a normal conversation it's not like\\n50:45 oh I'm going to you know give out to you\\n50:47 some magic tricks that is going to\\n50:50 change your life but uh when you hear\\n50:52 back from people some years down the\\n50:54 line that it helped uh that's a really\\n50:57 nice feeling that mentorship uh rewards\\n50:59 you\\n51:00 with yeah thank you so um another\\n51:04 question in in relations to Alex's\\n51:07 question on successful data sets I\\n51:08 wanted to ask Lavania Lavania what she\\n51:12 considers to be the other important\\n51:13 element of a portfolio for data science\\n51:15 so basically the question is okay data\\n51:18 set is one option but what else or what\\n51:22 instead of a data set we can include in\\n51:24 our portfolio oh yes um I think the data\\n51:28 set itself I don't think it's even\\n51:30 mentioned on my resume because once you\\n51:33 go out for these roles uh these are like\\n51:35 your pet projects it's nice to show your\\n51:3\", 'video_id': 'ekG5zJioyFs', '_id': 2237}, {'start': 46500, 'content': \"n quickly check like tabue\\n47:00 or um basic SQL stuff and then just get\\n47:04 going on learning on your own self-\\n47:06 learning is crucial but it I feel those\\n47:10 roles still require some effort because\\n47:11 you do need to spend sometime hardcore\\n47:14 learning those Technologies but product\\n47:17 manager I think it's easier to get\\n47:20 through MH yeah and um yeah so we talked\\n47:25 about Eugene and Eugene also lives in\\n47:27 Seattle\\n47:29 yes I didn't realize that you from the\\n47:32 same city and uh yeah but it's a big\\n47:35 city right it's not like you can\\n47:36 randomly St like running to people on\\n47:38 the street yeah I mean uh I'm very close\\n47:42 to the area where all these Amazon\\n47:43 offices are so yeah every day I do look\\n47:48 some I do come across someone familiar\\n47:51 either from my undergrad Masters or just\\n47:53 from LinkedIn yeah very very active\\n47:56 people yeah\\n47:58 so another question can you please\\n48:00 highlight me mentorship networking\\n48:01 opportunities which were\\n48:04 helpful um so is this about um getting\\n48:07 those opportunities for to be a\\n48:10 mentor so I the way I interpret\\n48:13 interpret this question is you had some\\n48:16 mentorship opportunities but then some\\n48:18 of them ended being helpful for you in\\n48:23 some way oh I see uh yeah I think so\\n48:28 getting those Mentor roles is uh\\n48:31 typically just through reach outs um\\n48:34 cold emailing LinkedIn messages um stuff\\n48:38 like that uh and once you build like\\n48:40 certain rappo with these people these\\n48:42 are huge communities then it becomes a\\n48:44 word of mouth so if you have done like\\n48:47 good networking putter good um good name\\n48:50 to your work um then it becomes a word\\n48:54 of mouth and that's how you kind of\\n48:56 excel in these community-driven uh\\n48:58 programs um because cold emailing or\\n49:01 these stuff can get you into it but like\\n49:04 to build you know a good uh trustworthy\\n49:07 uh relationships or networking as we\\n49:09 call it it's mainly through Word of\\n49:11 Mouth in my opinion yeah actually so now\\n49:16 again speaking of the our conversation\\n49:19 the earlier conversation um so I\\n49:22 scrolled up and saw that we talked about\\n49:24 mentorship and the reason I asked you\\n49:26 about that is because I was doing some\\n49:28 mentorship myself back then so I was\\n49:29 interested in your perspective on these\\n49:33 things and\\n49:35 um for me what was helpful is\\n49:40 uh maybe just structuring my knowledge\\n49:43 around things so people come to you with\\n49:45 requests and then you try to help and\\n49:48 then this way when you speak when you\\n49:50 say things out loud it helps to\\n49:53 structure these things in your head and\\n49:54 then it becomes easier to use this\\n49:57 information like in other settings that\\n49:59 was the main kind of highlight for me\\n50:01 and then like when\\n50:03 people one year after that right hey\\n50:06 like thanks because of the interview\\n50:09 because of the session we did together\\n50:11 like now I work at\", 'video_id': 'ekG5zJioyFs', '_id': 2236}, {'start': 33000, 'content': \"31:35 through this mentoring club\\n31:37 some people just want to have like a\\n31:39 one-time\\n31:40 conversation but maybe sometimes\\n31:43 i'm not sure if i got it right but\\n31:46 sometimes people need something more\\n31:47 long-term right um how often like what's\\n31:51 the like how often do you have somebody\\n31:54 who wants to have\\n31:55 something more long-term long-term is a\\n31:58 little\\n31:58 tricky honestly because um first of all\\n32:02 so i have a few people who i'm mentoring\\n32:04 long term some of these are\\n32:06 people i was mentoring at thoughtworks\\n32:08 when i was working there and also\\n32:10 through the mentoring club\\n32:11 i think one thing that you have to keep\\n32:12 in mind is that long term is\\n32:14 um so you need to\\n32:18 to also be mindful of the time\\n32:19 investment that the mentor is putting\\n32:21 into this right\\n32:22 and sometimes these relationships could\\n32:25 also\\n32:27 mean uh some kind of a monetary aspect\\n32:30 to it so there are mentors who do it\\n32:32 more professionally\\n32:33 um so one time mentoring is fine but if\\n32:36 you're trying to\\n32:37 to to build a more long-term\\n32:38 relationship then maybe there's like um\\n32:41 you know a fee that you need to pay to\\n32:42 them or something like that\\n32:44 um but yeah but other than that it's\\n32:47 just about\\n32:48 um you know establishing that that kind\\n32:50 of a contract\\n32:52 between you and the mentor and if they\\n32:54 are interested and willing to\\n32:56 provide that to you then then surely go\\n32:58 for it i would recommend to do\\n33:00 long-term mentorship because\\n33:03 it's difficult to understand the entire\\n33:06 context\\n33:07 and background in one conversation\\n33:10 it's always useful to you know um get to\\n33:14 know\\n33:14 each other a little bit more over time\\n33:16 and then you you\\n33:18 really get more productive with the\\n33:20 mental\\n33:21 mentoring process i guess\\n33:24 it makes more sense to find somebody in\\n33:27 your company\\n33:28 in your work workplace for this kind of\\n33:31 relationships right for a long term\\n33:33 mentorship relationship right not\\n33:36 necessarily if your\\n33:38 organization has either a formal program\\n33:41 or informally you know somebody you can\\n33:42 reach out to\\n33:43 i think that works out wonders so yeah\\n33:48 mariam is asking um how do you set\\n33:50 boundaries for long-term\\n33:52 mentorship relationships like uh of\\n33:54 course\\n33:55 uh like you as a mentor you also\\n33:58 you have other things right you cannot\\n34:00 uh spend all your time\\n34:02 helping your mentees and there are\\n34:04 perhaps other things so how do you set\\n34:06 up how do you set these boundaries\\n34:09 yeah and that's really good as i said\\n34:11 earlier right so um\\n34:12 and sometimes it's more meaningful\\n34:15 to have a paid relationship in those\\n34:18 aspects because you know\\n34:20 then both parties are more committed to\\n34:22 it and and it's easier to create those\\n34:24 boundaries and expectations\\n34:26 versus uh just a regular long-term\\n34:28 mentorship becaus\", 'video_id': 'LQvwTNQbPg4', '_id': 4036}, {'start': 60000, 'content': \"ding your network\\n56:42 right so because you usually work with\\n56:44 people who maybe not some someone\\n56:47 directly from your team um and also\\n56:50 maybe with someone who might move to\\n56:52 some other department sometime if you're\\n56:54 working in the big company so it's a\\n56:55 nice way to establish relationship and I\\n56:58 think this is how in initially the\\n57:00 mentorship appeared right so it was more\\n57:02 like people within one company or trying\\n57:04 to find like uh people who can guide\\n57:08 them right and I belief is still worth\\n57:10 it even if you're not paid by your\\n57:12 company for this but if you look for\\n57:14 someone outside you need to understand\\n57:17 and I would definitely ask why we why\\n57:21 they decided to become a mentor right so\\n57:23 because if you don't understand their\\n57:25 motivation um it might be not clear for\\n57:27 you how far they can help you yeah right\\n57:31 and I remember I did use actually like\\n57:33 this my my mentorship experience uh\\n57:36 mentoring experience uh or my uh\\n57:40 promotion case saying hey like people\\n57:44 yeah I\\n57:46 did I was actually I did not do this spe\\n57:49 when but um at some point and we didn't\\n57:52 have time to talk about this but um I\\n57:54 realized that um like in blue yander I\\n57:57 will not have let's say as I I can't go\\n58:00 as far as I wanted or as quick as I\\n58:02 wanted to go very far I mean and like\\n58:04 mve to the official leadership positions\\n58:07 um and I was trying to explore the kind\\n58:09 of the world outside and this is why I\\n58:12 actually left blue yand eventually to\\n58:14 explore with leadership um um positions\\n58:18 and I think like having this Mentor uh\\n58:22 experience helped me a lot because\\n58:23 otherwise I mean I had was informal\\n58:26 um kind of experience right so I was\\n58:28 leading the team I was kind of leading\\n58:30 the project and so on but I never had\\n58:32 like official title like a manager or\\n58:34 something right so I was an individual\\n58:36 contributor and um talking about this\\n58:40 mentorship experience actually helped me\\n58:42 back when because it's part I mean it's\\n58:45 not like 100% of what you do as the\\n58:48 manager of a team but some things are\\n58:50 very relevant right so when people want\\n58:52 to develop and I think in in data\\n58:54 science and machine learning many people\\n58:56 people want to develop themselves so if\\n58:57 you come with this yeah I know how to\\n58:59 develop people I know how to talk with\\n59:01 them about this this is a big plus um\\n59:04 for many companies who will consider to\\n59:06 hire you without a formal leadership\\n59:09 experience so last question and then we\\n59:12 call it today so which communities would\\n59:14 you recommend uh where people can find\\n59:18 uh like un paid mentors or\\n59:21 Volunteers in the data science this is a\\n59:25 good um\\n59:26 to be honest right now since I'm not\\n59:28 like part of this community or not\\n59:30 active member I don't remember the names\\n59:32 but I guess in Germany right\", 'video_id': 'kV0ZDy2UtJA', '_id': 3895}]\n",
      "RES  ← search call_5B1uTYNGHzMUPwLZQdn6H9fO [{'start': 10500, 'content': \" i've\\n9:37 experienced it in quite a few places\\n9:41 and uh but as a data engineer i guess as\\n9:44 a data scientist you already needed to\\n9:46 do some things that data engineers would\\n9:48 do right so you mentioned that at\\n9:50 soundcloud so you not only did modeling\\n9:54 but also everything that it was before\\n9:55 modeling like building data pipelines\\n9:58 and after modeling i guess deploying the\\n10:00 model so how does it overlap with what\\n10:04 data engineers usually do what you did\\n10:05 as a data scientist yes there's a lot of\\n10:07 overlap and\\n10:09 so there as the data scientists usually\\n10:12 are often you you don't work with\\n10:14 perfectly clean and perfectly delivered\\n10:16 data you will still build up your own\\n10:18 pipelines to make the data accessible\\n10:20 and especially if you move into more\\n10:23 production level\\n10:25 and\\n10:26 i mean the\\n10:27 data size is a very loose title and what\\n10:29 you do under this role can be very\\n10:30 different but there's often a lot of\\n10:33 pipelining work that you do on yourself\\n10:35 and i think\\n10:36 it's a good thing that data scientists\\n10:38 do that and don't just rely on data\\n10:40 engineers to kind of do handhold them\\n10:42 through these steps\\n10:45 and so there's a lot of transferable\\n10:46 skills it also depends great and also\\n10:48 data engineering is a very broad topic\\n10:51 and i never did the more kafka real-time\\n10:53 data engineering kind of stuff i've\\n10:54 carefully navigated myself around that\\n10:57 i've always done more what is now\\n10:58 considered analytics engineering maybe\\n11:01 which is more like the preparing data\\n11:03 for vi and data warehouses and\\n11:06 scheduling batch processing and all\\n11:08 these kind of things\\n11:10 so that was more my realm of data\\n11:12 engineering\\n11:13 and there's there's a this whole other\\n11:15 universe of data engineering that i've\\n11:16 never really touched and that i don't\\n11:18 feel i think where you need a better\\n11:20 understanding of distributed system and\\n11:21 things like that which i don't have\\n11:23 and so that is that's often more the\\n11:25 playground for people with a really\\n11:27 strong distributed computer science\\n11:29 background\\n11:31 and that isn't just not my round but in\\n11:33 for another for anything that's more in\\n11:35 the world of what is now analytics\\n11:36 engineering that kind of branch of data\\n11:38 engineering i think data scientists are\\n11:40 very well prepared there's obviously\\n11:42 things we need to learn but it there's a\\n11:44 lot\\n11:45 i've seen of i've often found that\\n11:47 people that come from peers of\\n11:49 engineering don't have a feeling for\\n11:50 data that they struggle more to move\\n11:52 into that space than people that come\\n11:54 that have a data science background and\\n11:56 just need to level up on\\n11:58 software engineering and collaboration\\n12:00 skills\\n12:01 what is this feeling of data in your\\n12:04 opinion what is that\\n12:06 yeah that that means understanding\\n12:08 it's a lot of things about\", 'video_id': '3TTu-hYzxeg', '_id': 622}, {'start': 42000, 'content': \"of Singapore releases a\\n45:30 lot of public data to like this open\\n45:33 data platforms right and sometimes you\\n45:36 need to edit this data before\\n45:40 publishing um the current data that we\\n45:43 share are data that is collected from\\n45:46 systems of course we Mass things like\\n45:50 um U cut numbers\\n45:55 MH what they actually share like and how\\n45:58 to to find this\\n45:59 information um there are two key\\n46:01 platforms one is data.gov Dog the other\\n46:05 one is called Data Mo so data.gov\\n46:08 Aggregates um information across\\n46:11 different government bodies in Singapore\\n46:13 and it ranges from things like rainfall\\n46:16 to air pollution\\n46:20 figures so there are categories like art\\n46:22 and culture education economy\\n46:24 environment geospatial housing Health\\n46:26 social trans\\n46:27 real time API so I guess I need to go to\\n46:30 transport to see your data sets right\\n46:34 yeah okay so I go to\\n46:37 transport and there is quite a lot of\\n46:40 things yes\\n46:42 like air travel geospatial data of like\\n46:47 Puffs\\n46:49 Network and um let's say somebody also\\n46:54 in January will start the next of data\\n46:57 engineering what kind of projects would\\n46:59 you recommend for them to try using\\n47:02 these data\\n47:04 sets I think one useful data set could\\n47:07 be car parking data because we collect\\n47:11 um car parking figures in I think I\\n47:14 think if I'm not wrong it's real time so\\n47:16 you get Gentry um transactions so I\\n47:20 think transaction data is quite a useful\\n47:22 and large data set for data engineering\\n47:25 projects whereby you can inest the data\\n47:27 in real time store it store it in a data\\n47:30 warehouse data Lake and then process it\\n47:32 later on for\\n47:35 analysis car\\n47:40 parking how do I find it so I just uh\\n47:44 look for car parking I don't think I can\\n47:46 find anything I think car parking is a\\n47:49 dynamic data\\n47:51 set H there there's a real time apis\\n47:55 maybe this is what I yes I'm interested\\n47:57 in okay\\n48:00 yeah and I guess I would be interested\\n48:03 in uh I cannot find maybe you can send\\n48:06 it later this is not something I can\\n48:07 just find right now yeah I can send to\\n48:09 you later another one would be real time\\n48:12 taxi data also another Dynamic data set\\n48:15 because I think the last data\\n48:16 engineering Zoom cam we were using the\\n48:19 the New York Taxi data set keep using it\\n48:22 it is an aggregated data set but I think\\n48:26 would be useful to also look at real\\n48:29 time data set and like go through the\\n48:30 process on on how to to store this\\n48:34 information so I put taxi there in the\\n48:37 search bar and then I see public\\n48:40 transport capacity monthly taxi\\n48:42 population and there's data from January\\n48:45 2005 to December uh this is not uh super\\n48:49 up to date but like it's up to December\\n48:51 2017 so there is quite a lot of data but\\n48:56 I see like there are many data sets with\\n48:59 that are constantly updated right ah you\\n49:02 sent me something yeah I just sent it\", 'video_id': 'VXQIGHUWeL0', '_id': 6845}, {'start': 58500, 'content': \"rn a\\n57:26 new tool\\n57:27 yeah\\n57:28 yeah there is one question uh probably\\n57:31 last one because i see we should be\\n57:32 wrapping up\\n57:33 but this question has seven upwards so i\\n57:35 think i have to ask it so question from\\n57:38 akshay is i want to know real world\\n57:40 end-to-end process of how a data\\n57:42 engineering team design build deploy and\\n57:44 monitor with structured\\n57:47 data in both real and batch i think this\\n57:49 is too much for one minute that we have\\n57:51 left\\n57:52 maybe you can give us okay an overview\\n57:56 i think i think we should have another\\n57:57 session you know dedicated to this piece\\n57:59 right\\n58:00 which which can you know last couple of\\n58:02 hours right\\n58:04 but anyways you know just to summarize\\n58:06 this you know in in the matter of time\\n58:08 is um\\n58:09 so there are different pieces of data\\n58:12 engineering right end to end so\\n58:13 first\\n58:14 if you start with the source systems\\n58:16 where data exists right it could be\\n58:18 relational database flat files cloud s3\\n58:20 all these things and you build one data\\n58:22 pipeline to pull data from source\\n58:24 systems and load into your data\\n58:26 warehouse or data lake that is your\\n58:28 centralized data hub and then you build\\n58:30 one process to expose this data because\\n58:33 this is one first part of it you have\\n58:34 all the retain data warehouse\\n58:36 but how a consumer who is interested in\\n58:38 your data will consume it so there could\\n58:40 be various methods of con consuming the\\n58:43 data in terms of you have let's say\\n58:45 reporting tool or visualization tool\\n58:48 and you have certain apis built on on\\n58:50 top of your data warehouse platforms\\n58:52 which can serve any applications in real\\n58:54 time\\n58:55 you can have some another etl layer for\\n58:58 you know um some other consumers who are\\n59:00 interested in your data so\\n59:02 this this whole end-to-end system can be\\n59:05 in batch mode also which runs daily or\\n59:07 weekly load and second thing is it can\\n59:09 be event based also so the moment data\\n59:12 arrive in your source system you can\\n59:14 have certain events listening to that\\n59:16 source system for example let's say s3\\n59:18 bucket right your file length on s3\\n59:19 bucket\\n59:20 your lambda function get triggered i am\\n59:22 talking in terms of aws terminologies\\n59:25 and that puts your reads data from s3\\n59:27 buckets and load into your data\\n59:29 warehouse so that is more real time\\n59:31 or if you talk about streaming then you\\n59:33 have kafka or any message brokers which\\n59:36 you know can connect to real-time data\\n59:38 with your warehouse right so i would say\\n59:41 just to summarize this focus not only\\n59:44 just bringing data into data warehouse\\n59:45 but a second part which is how you\\n59:48 expose that data if nobody is able to\\n59:51 consumer data consume your data then\\n59:53 your data warehouse is not uh worthy or\\n59:55 useful at all right\\n59:58 yeah thanks a lot um\\n1:00:01 what's the best way to find you if\\n1:00:03 so\", 'video_id': 'FljnbUQ796w', '_id': 2319}, {'start': 1500, 'content': \"during the interview and that's\\n1:33 all i have\\n1:37 for the introduction are you ready to\\n1:38 start yeah\\n1:40 okay so let me just\\n1:47 pull my notes\\n1:52 okay we have um today we will talk about\\n1:55 uh the difference between uh\\n1:57 big data engineers and data scientists\\n2:00 and we have special guests today\\n2:02 rexella ruxlana works as a big data\\n2:04 engineer\\n2:05 in uh captify right yeah and\\n2:09 uh yeah so today she will talk about\\n2:13 the role of a data engineer and data\\n2:14 scientist welcome\\n2:17 thank you before we go before we start\\n2:20 with our\\n2:21 main topic let's talk a bit about your\\n2:24 background\\n2:25 can you tell us a bit about your career\\n2:26 journey so far\\n2:28 yeah sure so i have a software\\n2:31 engineering degree\\n2:32 in one of the key universities it's both\\n2:35 bachelor and\\n2:36 master's degree and after that i was\\n2:38 working some time as\\n2:40 a background engineer in java mostly and\\n2:43 just at some point i\\n2:44 learned about data science big data\\n2:46 engineering and\\n2:48 i had some time to make a decision what\\n2:50 exactly i would want to do\\n2:52 and kind of back-end engineering at some\\n2:54 point just got a bit boring for me so\\n2:56 i switched into big data engineering\\n2:59 learned the\\n2:59 scala programming language and that's my\\n3:02 main programming language\\n3:04 now and um for a few years i worked at\\n3:07 a company called sql it's quite famous\\n3:10 in ukraine because it's\\n3:11 quite big company one of the top five\\n3:13 and\\n3:14 it's an outsourcing company which works\\n3:16 with clients and\\n3:18 as well as has some research so i was\\n3:21 working at the\\n3:22 r d department we had some internal\\n3:24 research stuff and\\n3:26 also i worked for some client projects\\n3:28 and\\n3:29 only two years ago i joined captify\\n3:32 which is\\n3:33 a product company they are building a\\n3:35 product in the sphere of\\n3:37 advertising and actually a company is\\n3:40 british it's based in uk\\n3:41 but it has a part of the engineering\\n3:44 team in cave\\n3:44 where i'm based and mostly working on\\n3:48 the product part specifically\\n3:50 in the big data engineering team\\n3:53 yeah i've heard that in advertising\\n3:55 there are there is so much data\\n3:57 that this data engineering big data\\n4:00 engineering becomes really important\\n4:01 because\\n4:02 these companies every day gets get\\n4:04 terabytes of data and they need to\\n4:06 effectively\\n4:07 uh process this data right yeah\\n4:10 and also what kind of makes uh the\\n4:12 solution of creptify unique\\n4:14 is data insights which are obviously\\n4:17 delivered to the help of\\n4:19 big data engineering team by having\\n4:21 different\\n4:22 sources of data and ways to transform\\n4:24 this data and deliver it to the clients\\n4:27 so what do you do at work uh what do you\\n4:29 usually do\\n4:30 as a big data engineer so my main\\n4:33 responsibility is building data\\n4:35 pipelines uh usually it's etl format\\n4:37 extract transform load so kind of\\n4:39 reading the data from some source\\n4:42 building transformations s\", 'video_id': 'yg3d1lFd7Uo', '_id': 7522}, {'start': 4500, 'content': \"alized\\n4:14 i didn't really enjoy data science as\\n4:16 much because it was very black box it\\n4:18 fell to me because i never was felt like\\n4:20 i was feeding some model but i didn't\\n4:22 really understand what's going on which\\n4:23 is partially due to the fact that my\\n4:24 mathematics background isn't that strong\\n4:27 so i didn't never really got the theory\\n4:29 behind it\\n4:30 but also i realized i kind of miss more\\n4:32 the engineering parts of it and\\n4:34 that was also the time when data\\n4:36 engineering became more of a thing\\n4:37 because companies realized that they\\n4:38 need not just data scientists but also\\n4:40 people that actually before come before\\n4:42 them and\\n4:43 make data available for data science\\n4:45 because that's at the time was a common\\n4:47 frustration for data scientists to not\\n4:48 have data\\n4:51 great ambitions but no data\\n4:54 and then i went\\n4:56 got an offer at native instruments to be\\n4:58 one of their first data engineers\\n5:01 i did that for a while um i still had\\n5:04 the ambition back then to transition\\n5:05 back into data science but i left native\\n5:07 instruments for unrelated reasons before\\n5:10 that happened\\n5:12 then i got another job at another\\n5:13 company as a bi developer\\n5:18 my title was data scientists but really\\n5:19 what i did was\\n5:21 develop custom\\n5:23 with data visualizations\\n5:26 and i realized eventually that this was\\n5:28 kind of a dead end for me\\n5:30 and so i\\n5:32 i remembered my software engineering\\n5:34 background which i actually enjoyed\\n5:36 except it was a repetitive and then\\n5:38 at the time i was speaking to somebody\\n5:40 at thoughtworks she was the first data\\n5:42 scientist at the thoughtworks in germany\\n5:44 at the time and she told me that\\n5:46 thoughtworks was planning to expand its\\n5:48 data engineering offering and what i'd\\n5:49 be interested in\\n5:52 in becoming the solidworks germany's\\n5:54 first data engineer and help her expand\\n5:56 that offering and i thought it was\\n5:58 really exciting and\\n5:59 especially since southwark is a great\\n6:01 place for really learning good software\\n6:03 engineering practices which as a data\\n6:05 engineer is always frustrated as a data\\n6:07 scientist that always frustrated me that\\n6:09 the quality of the code and the\\n6:11 collaboration wasn't as good as i was i\\n6:13 remembered it from my back in\\n6:14 engineering days\\n6:16 and so i jumped on that and that's when\\n6:17 i finally decided to stay in data\\n6:19 engineering which i had done on and off\\n6:21 before\\n6:23 and then then yeah after that was i went\\n6:26 to where i'm now it was my transfers and\\n6:28 built up data engineering there which\\n6:29 way i'm now heading a team\\n6:32 that's quite a story and thanks for\\n6:33 sharing so uh what i also wanted to ask\\n6:36 you the next question i prepared is that\\n6:38 you were a data scientist and then you\\n6:40 switched to data engineering and i\\n6:41 wanted to ask why i think you partly\\n6:43 answered that so you said that\\n6:47 data science was a bit too black boxy\", 'video_id': '3TTu-hYzxeg', '_id': 618}]\n",
      "RES  ← search call_jK1GMwxZ1fz9z3GfI0AbOnC2 [{'start': 10500, 'content': \" i've\\n9:37 experienced it in quite a few places\\n9:41 and uh but as a data engineer i guess as\\n9:44 a data scientist you already needed to\\n9:46 do some things that data engineers would\\n9:48 do right so you mentioned that at\\n9:50 soundcloud so you not only did modeling\\n9:54 but also everything that it was before\\n9:55 modeling like building data pipelines\\n9:58 and after modeling i guess deploying the\\n10:00 model so how does it overlap with what\\n10:04 data engineers usually do what you did\\n10:05 as a data scientist yes there's a lot of\\n10:07 overlap and\\n10:09 so there as the data scientists usually\\n10:12 are often you you don't work with\\n10:14 perfectly clean and perfectly delivered\\n10:16 data you will still build up your own\\n10:18 pipelines to make the data accessible\\n10:20 and especially if you move into more\\n10:23 production level\\n10:25 and\\n10:26 i mean the\\n10:27 data size is a very loose title and what\\n10:29 you do under this role can be very\\n10:30 different but there's often a lot of\\n10:33 pipelining work that you do on yourself\\n10:35 and i think\\n10:36 it's a good thing that data scientists\\n10:38 do that and don't just rely on data\\n10:40 engineers to kind of do handhold them\\n10:42 through these steps\\n10:45 and so there's a lot of transferable\\n10:46 skills it also depends great and also\\n10:48 data engineering is a very broad topic\\n10:51 and i never did the more kafka real-time\\n10:53 data engineering kind of stuff i've\\n10:54 carefully navigated myself around that\\n10:57 i've always done more what is now\\n10:58 considered analytics engineering maybe\\n11:01 which is more like the preparing data\\n11:03 for vi and data warehouses and\\n11:06 scheduling batch processing and all\\n11:08 these kind of things\\n11:10 so that was more my realm of data\\n11:12 engineering\\n11:13 and there's there's a this whole other\\n11:15 universe of data engineering that i've\\n11:16 never really touched and that i don't\\n11:18 feel i think where you need a better\\n11:20 understanding of distributed system and\\n11:21 things like that which i don't have\\n11:23 and so that is that's often more the\\n11:25 playground for people with a really\\n11:27 strong distributed computer science\\n11:29 background\\n11:31 and that isn't just not my round but in\\n11:33 for another for anything that's more in\\n11:35 the world of what is now analytics\\n11:36 engineering that kind of branch of data\\n11:38 engineering i think data scientists are\\n11:40 very well prepared there's obviously\\n11:42 things we need to learn but it there's a\\n11:44 lot\\n11:45 i've seen of i've often found that\\n11:47 people that come from peers of\\n11:49 engineering don't have a feeling for\\n11:50 data that they struggle more to move\\n11:52 into that space than people that come\\n11:54 that have a data science background and\\n11:56 just need to level up on\\n11:58 software engineering and collaboration\\n12:00 skills\\n12:01 what is this feeling of data in your\\n12:04 opinion what is that\\n12:06 yeah that that means understanding\\n12:08 it's a lot of things about\", 'video_id': '3TTu-hYzxeg', '_id': 622}, {'start': 46500, 'content': \"on it's for us\\n45:30 just a\\n45:31 decision to build this data governance\\n45:33 solution and\\n45:34 better understanding what kind of data\\n45:36 the process and\\n45:37 what kind of data we have inside just\\n45:39 from multiple people having multiple\\n45:41 tables and\\n45:42 no one knows what's in there\\n45:46 i assume that data scientists\\n45:49 also they produce a lot of data so their\\n45:52 models produce data\\n45:53 they also need to document the data\\n45:55 right do they use the same tool for that\\n45:58 yeah they just use the same time\\n46:01 description\\n46:02 or recommendation confluence so you have\\n46:05 the central place\\n46:06 for implementation for your data for\\n46:08 data that\\n46:10 data scientists produce and then it's\\n46:12 just once interface base\\n46:14 okay cool thanks uh we have a question\\n46:18 from ak\\n46:19 shot is\\n46:22 i think\\n46:26 so how much of data engineering should\\n46:27 one ideally know\\n46:29 i think we covered that um\\n46:32 a bit but um yeah so we talked about\\n46:36 that like how much data engineering\\n46:38 skills data scientists need to know\\n46:40 ideally um\\n46:43 but yeah we were more talking about like\\n46:45 if data scientists want to transition\\n46:47 into data engineering\\n46:48 but to be able to successfully do work\\n46:51 as data scientists\\n46:53 what kind of data engineering skills\\n46:55 they should have\\n46:58 i would say that coding skills it's also\\n47:00 important because i know that some\\n47:02 data scientists somewhere on the\\n47:03 mathematical side and they\\n47:05 more interested in building algorithms\\n47:07 than to write code\\n47:08 and it actually influences the quality\\n47:10 of the creation\\n47:12 because they you can either build just\\n47:15 everything for example in one notebook\\n47:17 and it would be hard to deploy it in\\n47:19 some way or they would build the whole\\n47:21 solution this libraries and for example\\n47:24 classes in python\\n47:25 maybe object-oriented programming so it\\n47:28 would be more like software engineering\\n47:30 way to do things\\n47:31 and the databases for sure as well\\n47:34 because they do need to read the data\\n47:36 or write some results there right\\n47:39 okay so basically uh improve your\\n47:41 software engineering skills\\n47:43 yeah yeah i think the trend i see\\n47:47 is now most data scientists in most\\n47:50 companies that\\n47:52 i see there is a requirement of being a\\n47:54 good\\n47:55 developer so maybe they don't need to be\\n47:58 as good as software engineers\\n48:00 but they need to be decent with coding\\n48:06 um yeah there is a comment about uh for\\n48:08 getting started with kubernetes there is\\n48:10 a good resource\\n48:11 called catacoda and\\n48:14 i think i saw it um i know have you seen\\n48:16 it\\n48:17 yeah i tried it once it was in the\\n48:20 beginning it's quite useful you can just\\n48:22 try out\\n48:22 different commands and see what happens\\n48:25 yeah i think\\n48:26 i saw uh one with kubernetes and one\\n48:28 with\\n48:29 i think and it's pretty cool so they\\n48:32 just\\n48:33 set up a local kubernetes for \", 'video_id': 'yg3d1lFd7Uo', '_id': 7552}, {'start': 37500, 'content': \"3 we also want to S out like if somebody\\n36:45 has to do this for another city like\\n36:47 what would be the correct way to do it\\n36:49 or like the best way to do it\\n36:52 MH as and as As I understood the project\\n36:55 you did before\\n36:57 um it had also like something geospatial\\n37:00 right and when you were looking for your\\n37:04 first freelance\\n37:06 job uh actually the the company you\\n37:09 ended up working for needed the exact\\n37:12 skills that you developed during this uh\\n37:15 this project yeah yeah that's exactly\\n37:17 what happened and maybe that will happen\\n37:20 again here I don't know maybe my next\\n37:22 fre L will be exactly like like the\\n37:25 scenario but I think that's a a really\\n37:27 good good story like you learn a skill\\n37:30 in a project hands on and I mean forena\\n37:34 there's no expectation that you would\\n37:36 work 20 hours or 15 hours it's really\\n37:38 like if you have five hours in a week\\n37:41 just like a half a day or after work for\\n37:43 two or to three days you just join a\\n37:47 project and you work with other people\\n37:48 to try to come up with a solution it's a\\n37:51 very I think it's a cool way to learn\\n37:53 new skills and a lot less overwhelming\\n37:55 if you do like with a team mhm would you\\n37:59 say that uh it typically happens that\\n38:01 the skills you pick up uh on such\\n38:03 projects they are handon Hands-On skills\\n38:06 that translate to job skills I think so\\n38:10 first I\\n38:11 think I think everybody gives the same\\n38:13 advice when it comes to data science\\n38:14 like build your portfolio do this do do\\n38:17 that there are so many ways of doing\\n38:19 that right exactly there are a lot of\\n38:21 different ways of doing that but like as\\n38:23 I grow in my here I realize that people\\n38:26 are also looking for soft skills right\\n38:28 when they hire you they just don't want\\n38:30 to somebody who's great at their job but\\n38:33 cannot work with anybody else and I\\n38:35 think when you do projects like this you\\n38:37 are forced to pick up soft skills\\n38:39 because if you have 80 people working on\\n38:42 the same project you have to communicate\\n38:44 well you have to be able to follow up\\n38:46 what's going on you have to be able to\\n38:50 access resources and figure things on\\n38:52 your own to not be overwhelmed when you\\n38:55 open Slack and there are 30 messages on\\n38:58 one single Channel and you don't know\\n38:59 where to look for I think those it's\\n39:02 also a great place to develop those\\n39:03 skills because a lot of I think a lot of\\n39:06 engineering and data science also the\\n39:08 mindset that you applied to what you're\\n39:11 doing and the like if you were alone\\n39:14 you're working alone I'm sure that you\\n39:15 are developing very hard skills and very\\n39:17 technical skills but then maybe you\\n39:19 missing out on developing a little a\\n39:21 little bit more of the mindset and also\\n39:23 when you work alone you don't\\n39:24 necessarily know uh what are the\\n39:27 kind of good relevant skills it's true\\n39:30 and wh\", 'video_id': 'GifY8Zn-pnU', '_id': 2677}, {'start': 22500, 'content': \"ll\\n26:24 of them yeah so which means that um\\n26:29 let's say somebody wants to take our\\n26:32 courses they should do some of this work\\n26:34 even before they take courses right yeah\\n26:36 yeah exactly then you have more Focus\\n26:39 from the very beginning and you know\\n26:40 okay I want to focus on data engineering\\n26:42 so I take data\\n26:44 engineering and then uh yeah just after\\n26:48 the course perhaps instead of taking the\\n26:49 other courses focus on developing the\\n26:52 skills in this area focus on doing more\\n26:54 projects in this area exactly and then\\n26:57 get interviews in that area right and\\n27:00 try to understand where you stand what\\n27:02 else is needed required to get a job\\n27:05 hopefully after finishing our course you\\n27:07 get all the skills right yeah yeah but\\n27:10 sometimes some companies might require\\n27:13 something specific right that we don't\\n27:15 cover and then this is where you can\\n27:18 understand that okay yeah and then try\\n27:20 to focus on I know building a project\\n27:23 with this particular skill yeah it's\\n27:25 it's important to not get lost in doing\\n27:28 all the courses I don't know if if\\n27:29 really all of them do all uh all the\\n27:32 courses before starting a new course\\n27:34 just take some time and okay maybe have\\n27:37 a project even if so I finish data\\n27:40 engineering I do a project I do a a\\n27:43 project and I see if I enjoy doing it\\n27:46 okay I I suppose the hypothesis is\\n27:49 something that I would like but okay I\\n27:51 finish data engineering let me practice\\n27:54 let me show that I developed skills in\\n27:57 data\\n27:59 engineering and then think about another\\n28:02 course but going from uh one course to\\n28:06 another\\n28:07 is like I don't know the wor but yeah\\n28:11 it's better to avoid it like especially\\n28:14 like that's circle like you get on the\\n28:16 train of course after course after\\n28:19 course because I feel like I still don't\\n28:20 have enough qualifications but remember\\n28:24 you have also skills you have strs you\\n28:27 have experience\\n28:29 so don't forget about\\n28:32 that and when it comes to having even\\n28:35 more Focus cuz like okay we you\\n28:38 mentioned that when it comes to data\\n28:40 science it's such a broad topic it can\\n28:43 mean anything from analysts to hardcore\\n28:47 deep learning whatever right\\n28:50 um and when you read one job description\\n28:54 for data scientist it can be super\\n28:56 different from another description of\\n28:58 data scientist and the same thing with\\n29:00 data Engineers so you can be a data\\n29:01 engineer that builds a data platform you\\n29:04 can be a data engineer that helps\\n29:06 analyst you can be a data engineer that\\n29:08 works with data scientists right so\\n29:10 there are also\\n29:14 speci and like do if I already know okay\\n29:18 I want to do data science or I want to\\n29:19 do data engineering do I already should\\n29:23 I already have even more focus and think\\n29:26 okay like I want to focus on this\\n29:28 particular type of data science job or\\n29:31 \", 'video_id': 'PchwbIs0tOg', '_id': 4621}, {'start': 3000, 'content': \"mething\\n3:03 so i became a secret developer and i\\n3:06 learned very well\\n3:08 how very well how to work with\\n3:10 databases and reports\\n3:12 so and quite quickly it turned out that\\n3:16 my strong points are analytic skills and\\n3:18 contact with clients so i continued my\\n3:22 career as a business intelligence\\n3:23 analyst\\n3:25 being responsible for the analytic parts\\n3:27 of the data warehouse construction and\\n3:30 reporting projects\\n3:32 and i also prepared some\\n3:34 user visualizations and data analysis\\n3:38 and at the same time i also became one\\n3:41 of\\n3:42 the leaders in our bi department so i\\n3:45 also developed my leadership skills\\n3:48 but\\n3:49 always i felt that we could do something\\n3:52 more with data some advanced analytics\\n3:55 my goal was to gain more insight from\\n3:58 data and one day we decided\\n4:01 to build our own data science team so\\n4:04 after\\n4:05 some time i became a data science\\n4:07 manager and i got the opportunity to\\n4:10 build my own team and take\\n4:12 responsibility for the whole area\\n4:15 and now with my team we are building\\n4:17 machine learning solutions so this is\\n4:19 very short story of my career journey\\n4:23 oh what kind of solutions you're\\n4:24 building\\n4:26 now\\n4:27 we have two main topics um\\n4:30 one is modal\\n4:32 uh\\n4:33 which should predict uh for people who\\n4:36 are uh sick\\n4:38 for bipolar disease or depression the\\n4:42 your face will change or not\\n4:45 because it's important for doctors and\\n4:48 the other solution is small commercial\\n4:51 this is uh demand forecasting and\\n4:54 recommendation so inventory optimization\\n4:58 that's quite interesting yeah thanks for\\n5:00 sharing so uh i've been following you on\\n5:03 linkedin for quite a while and uh i\\n5:06 think you post regularly like every like\\n5:08 maybe every week every two weeks\\n5:11 i see posts from you then some time ago\\n5:14 i think maybe it was six months ago like\\n5:16 it wasn't super recent uh\\n5:19 i think it goes uh like a few months ago\\n5:22 yeah so you shared the link and\\n5:25 you shared the sort of post and the post\\n5:28 started with\\n5:29 do you need\\n5:30 a data science manager or a data science\\n5:33 expert can you tell us more about this\\n5:35 post\\n5:37 yeah uh i remember this post very well\\n5:40 and this post was about differences\\n5:42 between data science manager and data\\n5:45 science expert\\n5:46 and these two positions are often\\n5:49 confused even in data science world and\\n5:52 often uh people forgot many aspects of\\n5:56 managerial tasks\\n5:58 so\\n5:59 i often got\\n6:01 job offers from various head hunters on\\n6:04 nicotine\\n6:05 and job titles were data science manager\\n6:08 or data science team leader\\n6:10 but when i analyzed requirements i could\\n6:14 see that 80 percent of them were very\\n6:17 technical for example python programming\\n6:20 machine learning solutions deployment\\n6:22 kubernetes docker\\n6:24 advanced libraries such as tensorflow\\n6:27 python etc\\n6:29 and only 20\\n6:31 of the requirements had anything to do\\n6:34 with soft skills typical \", 'video_id': 'hFmIgaN-F8Y', '_id': 2872}]\n",
      "RES  ← search call_KPyHfQs0oO7Bv344WhMJzqqb [{'start': 1500, 'content': \"during the interview and that's\\n1:33 all i have\\n1:37 for the introduction are you ready to\\n1:38 start yeah\\n1:40 okay so let me just\\n1:47 pull my notes\\n1:52 okay we have um today we will talk about\\n1:55 uh the difference between uh\\n1:57 big data engineers and data scientists\\n2:00 and we have special guests today\\n2:02 rexella ruxlana works as a big data\\n2:04 engineer\\n2:05 in uh captify right yeah and\\n2:09 uh yeah so today she will talk about\\n2:13 the role of a data engineer and data\\n2:14 scientist welcome\\n2:17 thank you before we go before we start\\n2:20 with our\\n2:21 main topic let's talk a bit about your\\n2:24 background\\n2:25 can you tell us a bit about your career\\n2:26 journey so far\\n2:28 yeah sure so i have a software\\n2:31 engineering degree\\n2:32 in one of the key universities it's both\\n2:35 bachelor and\\n2:36 master's degree and after that i was\\n2:38 working some time as\\n2:40 a background engineer in java mostly and\\n2:43 just at some point i\\n2:44 learned about data science big data\\n2:46 engineering and\\n2:48 i had some time to make a decision what\\n2:50 exactly i would want to do\\n2:52 and kind of back-end engineering at some\\n2:54 point just got a bit boring for me so\\n2:56 i switched into big data engineering\\n2:59 learned the\\n2:59 scala programming language and that's my\\n3:02 main programming language\\n3:04 now and um for a few years i worked at\\n3:07 a company called sql it's quite famous\\n3:10 in ukraine because it's\\n3:11 quite big company one of the top five\\n3:13 and\\n3:14 it's an outsourcing company which works\\n3:16 with clients and\\n3:18 as well as has some research so i was\\n3:21 working at the\\n3:22 r d department we had some internal\\n3:24 research stuff and\\n3:26 also i worked for some client projects\\n3:28 and\\n3:29 only two years ago i joined captify\\n3:32 which is\\n3:33 a product company they are building a\\n3:35 product in the sphere of\\n3:37 advertising and actually a company is\\n3:40 british it's based in uk\\n3:41 but it has a part of the engineering\\n3:44 team in cave\\n3:44 where i'm based and mostly working on\\n3:48 the product part specifically\\n3:50 in the big data engineering team\\n3:53 yeah i've heard that in advertising\\n3:55 there are there is so much data\\n3:57 that this data engineering big data\\n4:00 engineering becomes really important\\n4:01 because\\n4:02 these companies every day gets get\\n4:04 terabytes of data and they need to\\n4:06 effectively\\n4:07 uh process this data right yeah\\n4:10 and also what kind of makes uh the\\n4:12 solution of creptify unique\\n4:14 is data insights which are obviously\\n4:17 delivered to the help of\\n4:19 big data engineering team by having\\n4:21 different\\n4:22 sources of data and ways to transform\\n4:24 this data and deliver it to the clients\\n4:27 so what do you do at work uh what do you\\n4:29 usually do\\n4:30 as a big data engineer so my main\\n4:33 responsibility is building data\\n4:35 pipelines uh usually it's etl format\\n4:37 extract transform load so kind of\\n4:39 reading the data from some source\\n4:42 building transformations s\", 'video_id': 'yg3d1lFd7Uo', '_id': 7522}, {'start': 0, 'content': \"0:01 so welcome everyone\\n0:04 i'm excited to be here thanks integra\\n0:06 for joining me so this is the first day\\n0:08 of our data talks club summer marathon\\n0:11 so which is a conference but not really\\n0:13 a conference it's more like a bunch of\\n0:14 meetups so for two weeks\\n0:16 every day we'll have a small talk like a\\n0:20 small meet up\\n0:21 and today is the first day so the first\\n0:23 week we'll talk about different topics\\n0:26 in career in data and the next week\\n0:28 we'll talk about machine learning\\n0:30 production so this is the lineup we have\\n0:33 for this week\\n0:34 and uh so first today we are talking\\n0:37 with santiago about\\n0:39 um what transitions from software\\n0:41 engineering to machine learning then\\n0:44 tomorrow we'll talk with daliana about\\n0:46 getting a promotion in data science so\\n0:48 the talk will be the next level of your\\n0:50 data science career then we'll talk\\n0:53 about data engineering and how data\\n0:54 scientists can build their own data\\n0:56 pipelines\\n0:58 on thursday we'll talk about two\\n1:00 different roles big data engineer and\\n1:02 data scientist and what are the\\n1:03 difference between them\\n1:04 and we will end this week with a talk\\n1:06 about building a machining startup with\\n1:08 elena\\n1:10 and if you haven't registered for our\\n1:12 conference\\n1:13 there is a link a link in description\\n1:16 you can just go there\\n1:17 and you can sign up for the uh other\\n1:20 days and then finally uh subscribe to\\n1:23 our youtube channel to stay up to date\\n1:25 with\\n1:26 all our events and join our slack to\\n1:29 talk about different data topics\\n1:32 during today interview with santiago you\\n1:35 can ask any question you want\\n1:36 and for that please use a pinned link in\\n1:39 in the description in the live chat so\\n1:42 just click on this link\\n1:43 and ask any question you want and\\n1:47 yes santiago was kind enough to provide\\n1:50 10\\n1:50 copies of his course and here are the\\n1:53 winners of his course i will announce\\n1:54 this later but\\n1:56 thanks a lot for taking part and\\n1:57 congratulations on winning this course\\n2:01 and last but not least\\n2:04 this event is supported by many of our\\n2:07 partners by\\n2:08 eight of them uh thanks a lot for your\\n2:10 support\\n2:11 for uh helping us with organizing this\\n2:14 event for promoting it\\n2:16 and uh please go to our conference\\n2:18 website and check them out\\n2:20 all of them are doing really cool stuff\\n2:23 and that's all for the introduction and\\n2:27 now i should stop sharing my screen and\\n2:31 yeah santiago are you ready i am ready\\n2:35 okay so let's start\\n2:38 absolutely yes so today we'll talk about\\n2:41 career transitioning from software\\n2:43 engineering to machine learning\\n2:45 and we have a special guest today\\n2:46 santiago so santiago is a director\\n2:48 of computer vision solutions at levitas\\n2:52 and there he leads a small small team of\\n2:56 software engineers and machinery\\n2:57 engineers\\n2:58 santiago is computers is a computer\\n3:00 scientist who focuses on applied machine\\n3:02 \", 'video_id': 'xVYOdRrN7hw', '_id': 7397}, {'start': 0, 'content': \"0:00 hey everyone Welcome to our event this\\n0:03 event is brought to you by data talks\\n0:04 club which is a community of people who\\n0:06 have data\\n0:07 we have weekly events this is one of\\n0:09 such events if you want to find out more\\n0:11 about the events we have there is a link\\n0:13 in the description go there click on\\n0:15 this link and you'll see all the events\\n0:16 we have in our pipeline very important\\n0:19 don't forget to subscribe to our YouTube\\n0:21 channel then you will not miss on\\n0:23 interviews like today today is going to\\n0:26 be an awesome interview and subscribe\\n0:28 not to miss others\\n0:30 then we have an amazing slack community\\n0:32 the link is also in the description\\n0:34 check it out and register to hang out\\n0:37 with other data enthusiasts\\n0:40 during today's interview you can ask any\\n0:42 question you want there is a link in the\\n0:45 it's pinned in the live chat so go there\\n0:47 click on this link and ask your\\n0:50 questions there\\n0:51 now I will stop sharing my screen\\n0:54 I will open the questions that will\\n0:57 prepare for you\\n0:59 and\\n1:01 if you're ready we can start let's do\\n1:03 this\\n1:04 so this week we'll talk about changing\\n1:07 career from software engineering to data\\n1:11 science management and we have a special\\n1:12 guest today Sadat Sadat and I are\\n1:15 colleagues we both work at elix group he\\n1:17 joined to elix as a software engineer\\n1:19 then he got promoted to an engineering\\n1:21 manager and finally he decided to change\\n1:24 his career and switch to data science\\n1:26 management so I invited Sadat to talk\\n1:29 more about his career transition welcome\\n1:32 thank you very much super happy to be\\n1:34 here and and talk to the community\\n1:36 yeah happy to have you here too so\\n1:39 before we go into our main topic and\\n1:42 discuss your career transitioning in\\n1:44 details maybe we can briefly go over\\n1:47 your career Journey so far so how did it\\n1:50 start sure\\n1:52 here's a fun fact that I think now not a\\n1:55 lot of people know but I actually always\\n1:57 wanted to become a doctor an inspiration\\n1:59 that I had from my father so engineering\\n2:01 or maybe data science management was\\n2:04 really not something that became a\\n2:07 reality much later on in this journey\\n2:11 um I think yeah\\n2:12 adolescence uh teenagers is when I\\n2:15 realized that I'm super curious about\\n2:17 technology those things fascinated me it\\n2:19 turns out engineering is then a better\\n2:21 option\\n2:23 um I have a bachelor's in electronics\\n2:25 and then I have a masters in inform\\n2:28 informatic or information technology\\n2:30 from uh from a university in Germany in\\n2:34 Stuttgart in between my bachelor's and\\n2:36 Masters I worked for a brief period in\\n2:38 India around two and a half three years\\n2:42 um not to be honest the best part of my\\n2:44 career I wasn't doing something crazy\\n2:47 but I think my Master's changed a lot of\\n2:49 that during my Master's while I was a\\n2:52 student I was also working for the front\\n2:55 offer Institute which is a\", 'video_id': 'xyTfqIWeKf8', '_id': 7479}, {'start': 4500, 'content': \"o i think it\\n4:39 was one\\n4:40 month ago i was checking my twitter and\\n4:43 i saw your\\n4:44 thread on twitter and after reading this\\n4:47 thread\\n4:48 i decided to contact you\\n4:51 and it got my attention it was really\\n4:54 interesting so the threat was\\n4:55 about 12 career hacks\\n4:59 so can you tell us about this threat so\\n5:02 what are these\\n5:03 career hacks yeah so basically on the\\n5:06 twitter i was\\n5:07 talking about career change because it's\\n5:09 very popular topic\\n5:11 uh you know everybody actually changes\\n5:14 career\\n5:15 at least couple of times in their\\n5:16 lifetime but the first time is always\\n5:19 tricky so people always worry like oh\\n5:21 career change\\n5:22 and they always ask questions on how to\\n5:24 do it and how to approach\\n5:26 that challenge and i was uh feeling the\\n5:29 twitter\\n5:29 uh with useful hacks that i learned\\n5:32 during my career change\\n5:34 i learned it hard way so i decided maybe\\n5:36 i better share my\\n5:38 experience so people can uh hopefully\\n5:41 speed up the process a bit uh using my\\n5:44 advices if they find it useful\\n5:46 so the first career hack and one of the\\n5:49 most important ones\\n5:51 is to change your social circle to be\\n5:53 careful about your social circle\\n5:55 so basically if you have you know\\n5:59 great friends from childhood and parents\\n6:01 obviously you don't change them but you\\n6:02 have a lot of\\n6:03 colleagues and you have a lot of shallow\\n6:06 uh acquaintance not really difference in\\n6:09 your\\n6:10 network and if they are not helping you\\n6:12 in in your career change if they keep\\n6:14 telling you\\n6:14 that you're gonna fail it's a bad idea\\n6:17 you have a good job while you're\\n6:19 changing your career\\n6:20 changing career and maternity leave that\\n6:22 does not work nobody does it you know\\n6:25 in this case this uh circle doesn't\\n6:28 really help you and\\n6:30 it's important to cut off such social\\n6:32 interactions\\n6:34 and then you will have a space for new\\n6:36 people to come into your life because\\n6:37 you will have more free time than\\n6:39 and uh then you can be people\\n6:43 that are more supportive and that\\n6:45 already changed career and that can help\\n6:47 you and guide you through that\\n6:49 so that's essentially what i did i cut\\n6:51 off about like 70 percent of my\\n6:53 communications with\\n6:54 ex-colleagues and all those pessimistic\\n6:57 people who are telling me that\\n6:58 i will fail and change inquiry is a bad\\n7:00 idea and\\n7:02 when i stopped communicating with them\\n7:05 i started to look for options and\\n7:08 that's how i found the ods community\\n7:12 and i entered the community and that's\\n7:15 where i found\\n7:16 my new network in a career and not only\\n7:19 career now i also\\n7:20 have friends there and that was very\\n7:23 supportive because\\n7:25 there is a saying that uh your average\\n7:28 of like uh three to nine people you\\n7:31 you're friends with so it's important to\\n7:34 be careful in choosing your friends\\n7:36 and choosing your circles so and that's\\n7:38 what\\n7:39 that's a talk \", 'video_id': 'wJPi6Ip9PX0', '_id': 7065}, {'start': 4500, 'content': \"alized\\n4:14 i didn't really enjoy data science as\\n4:16 much because it was very black box it\\n4:18 fell to me because i never was felt like\\n4:20 i was feeding some model but i didn't\\n4:22 really understand what's going on which\\n4:23 is partially due to the fact that my\\n4:24 mathematics background isn't that strong\\n4:27 so i didn't never really got the theory\\n4:29 behind it\\n4:30 but also i realized i kind of miss more\\n4:32 the engineering parts of it and\\n4:34 that was also the time when data\\n4:36 engineering became more of a thing\\n4:37 because companies realized that they\\n4:38 need not just data scientists but also\\n4:40 people that actually before come before\\n4:42 them and\\n4:43 make data available for data science\\n4:45 because that's at the time was a common\\n4:47 frustration for data scientists to not\\n4:48 have data\\n4:51 great ambitions but no data\\n4:54 and then i went\\n4:56 got an offer at native instruments to be\\n4:58 one of their first data engineers\\n5:01 i did that for a while um i still had\\n5:04 the ambition back then to transition\\n5:05 back into data science but i left native\\n5:07 instruments for unrelated reasons before\\n5:10 that happened\\n5:12 then i got another job at another\\n5:13 company as a bi developer\\n5:18 my title was data scientists but really\\n5:19 what i did was\\n5:21 develop custom\\n5:23 with data visualizations\\n5:26 and i realized eventually that this was\\n5:28 kind of a dead end for me\\n5:30 and so i\\n5:32 i remembered my software engineering\\n5:34 background which i actually enjoyed\\n5:36 except it was a repetitive and then\\n5:38 at the time i was speaking to somebody\\n5:40 at thoughtworks she was the first data\\n5:42 scientist at the thoughtworks in germany\\n5:44 at the time and she told me that\\n5:46 thoughtworks was planning to expand its\\n5:48 data engineering offering and what i'd\\n5:49 be interested in\\n5:52 in becoming the solidworks germany's\\n5:54 first data engineer and help her expand\\n5:56 that offering and i thought it was\\n5:58 really exciting and\\n5:59 especially since southwark is a great\\n6:01 place for really learning good software\\n6:03 engineering practices which as a data\\n6:05 engineer is always frustrated as a data\\n6:07 scientist that always frustrated me that\\n6:09 the quality of the code and the\\n6:11 collaboration wasn't as good as i was i\\n6:13 remembered it from my back in\\n6:14 engineering days\\n6:16 and so i jumped on that and that's when\\n6:17 i finally decided to stay in data\\n6:19 engineering which i had done on and off\\n6:21 before\\n6:23 and then then yeah after that was i went\\n6:26 to where i'm now it was my transfers and\\n6:28 built up data engineering there which\\n6:29 way i'm now heading a team\\n6:32 that's quite a story and thanks for\\n6:33 sharing so uh what i also wanted to ask\\n6:36 you the next question i prepared is that\\n6:38 you were a data scientist and then you\\n6:40 switched to data engineering and i\\n6:41 wanted to ask why i think you partly\\n6:43 answered that so you said that\\n6:47 data science was a bit too black boxy\", 'video_id': '3TTu-hYzxeg', '_id': 618}]\n",
      "RES  ← search call_I1zHYs2jFV46b525GqTYZBYw [{'start': 46500, 'content': \"all companies\\n43:30 and this is part of the prep\\n43:32 um all companies will have different\\n43:34 expectations and what they're going to\\n43:35 speak to you about so\\n43:37 for me I would never prepare for\\n43:39 specific questions I would practice\\n43:41 questions in case they come up but when\\n43:44 it comes to preparation for technical\\n43:46 interviews you what we need to do is\\n43:50 really under or try to understand the\\n43:52 expectations of the individual customers\\n43:55 that we're trying to work with right or\\n43:57 the individual companies that we're\\n43:58 trying to join so the questions I mean I\\n44:02 could tell you something but they're not\\n44:03 going to be relevant for everyone else\\n44:04 right but what is relevant is\\n44:08 um\\n44:09 setting the expectations or under trying\\n44:11 to understand the expectations of the\\n44:13 clients that you're interviewing with so\\n44:15 again if you had someone on the inside\\n44:17 or a HR Talent person that you're\\n44:19 working with or a recruiter when you get\\n44:21 to a technical interview the first thing\\n44:24 that you should be asking is what are\\n44:25 the expectations of this interview you\\n44:27 should never ever in my opinion go into\\n44:30 an interview and say it's a technical\\n44:33 interview and that's all you know that\\n44:35 is blasphemy here my word\\n44:38 um\\n44:39 every single time you go into any\\n44:41 interview you should really understand\\n44:42 at least from an agenda perspective\\n44:46 the context of what you're going into\\n44:48 and speaking about right because you\\n44:50 need something to base your prep offers\\n44:54 um so yeah number one I'd always do this\\n44:56 before so let's say\\n44:59 and working with you so I am over like I\\n45:03 passed this introduction stage and now\\n45:05 you set\\n45:07 an interview a technical interview with\\n45:10 oh like somebody I don't know senior\\n45:12 data scientist\\n45:14 so what I do do I ask you or do I ask\\n45:16 that person like what are your\\n45:18 expectations in email before the\\n45:20 interview so I know what to expect\\n45:22 yeah this is what you're saying yeah so\\n45:25 let's say you got through the the intro\\n45:28 stage and that went really well look I'm\\n45:30 really Keen to continue\\n45:32 um what's the next stage and what are\\n45:33 the expectations so if we're in that\\n45:35 technical stage I should be able to give\\n45:37 you a very strong or at least some\\n45:40 pointers in terms of what they're going\\n45:41 to be looking for within that technical\\n45:43 stage right and that's the kind of\\n45:45 Baseline for your preparation what we\\n45:47 don't want to do is go really broad\\n45:49 really generic and kind of not really\\n45:51 know what goal we're shooting at and yes\\n45:54 there are some really good sites out\\n45:56 there where you can go and practice like\\n45:57 coding questions and Link code and\\n46:00 hackarack and code forces and stuff like\\n46:02 that but generally I think when we are\\n46:05 prepping for\\n46:06 an organization we want to keep it as\\n46:09 focused towards our \", 'video_id': 'NnZjlMowkWA', '_id': 4299}, {'start': 1500, 'content': \"during the interview and that's\\n1:33 all i have\\n1:37 for the introduction are you ready to\\n1:38 start yeah\\n1:40 okay so let me just\\n1:47 pull my notes\\n1:52 okay we have um today we will talk about\\n1:55 uh the difference between uh\\n1:57 big data engineers and data scientists\\n2:00 and we have special guests today\\n2:02 rexella ruxlana works as a big data\\n2:04 engineer\\n2:05 in uh captify right yeah and\\n2:09 uh yeah so today she will talk about\\n2:13 the role of a data engineer and data\\n2:14 scientist welcome\\n2:17 thank you before we go before we start\\n2:20 with our\\n2:21 main topic let's talk a bit about your\\n2:24 background\\n2:25 can you tell us a bit about your career\\n2:26 journey so far\\n2:28 yeah sure so i have a software\\n2:31 engineering degree\\n2:32 in one of the key universities it's both\\n2:35 bachelor and\\n2:36 master's degree and after that i was\\n2:38 working some time as\\n2:40 a background engineer in java mostly and\\n2:43 just at some point i\\n2:44 learned about data science big data\\n2:46 engineering and\\n2:48 i had some time to make a decision what\\n2:50 exactly i would want to do\\n2:52 and kind of back-end engineering at some\\n2:54 point just got a bit boring for me so\\n2:56 i switched into big data engineering\\n2:59 learned the\\n2:59 scala programming language and that's my\\n3:02 main programming language\\n3:04 now and um for a few years i worked at\\n3:07 a company called sql it's quite famous\\n3:10 in ukraine because it's\\n3:11 quite big company one of the top five\\n3:13 and\\n3:14 it's an outsourcing company which works\\n3:16 with clients and\\n3:18 as well as has some research so i was\\n3:21 working at the\\n3:22 r d department we had some internal\\n3:24 research stuff and\\n3:26 also i worked for some client projects\\n3:28 and\\n3:29 only two years ago i joined captify\\n3:32 which is\\n3:33 a product company they are building a\\n3:35 product in the sphere of\\n3:37 advertising and actually a company is\\n3:40 british it's based in uk\\n3:41 but it has a part of the engineering\\n3:44 team in cave\\n3:44 where i'm based and mostly working on\\n3:48 the product part specifically\\n3:50 in the big data engineering team\\n3:53 yeah i've heard that in advertising\\n3:55 there are there is so much data\\n3:57 that this data engineering big data\\n4:00 engineering becomes really important\\n4:01 because\\n4:02 these companies every day gets get\\n4:04 terabytes of data and they need to\\n4:06 effectively\\n4:07 uh process this data right yeah\\n4:10 and also what kind of makes uh the\\n4:12 solution of creptify unique\\n4:14 is data insights which are obviously\\n4:17 delivered to the help of\\n4:19 big data engineering team by having\\n4:21 different\\n4:22 sources of data and ways to transform\\n4:24 this data and deliver it to the clients\\n4:27 so what do you do at work uh what do you\\n4:29 usually do\\n4:30 as a big data engineer so my main\\n4:33 responsibility is building data\\n4:35 pipelines uh usually it's etl format\\n4:37 extract transform load so kind of\\n4:39 reading the data from some source\\n4:42 building transformations s\", 'video_id': 'yg3d1lFd7Uo', '_id': 7522}, {'start': 1500, 'content': \" right now\\n1:19 great yeah\\n1:21 so let me get\\n1:24 let me grab a copy of my book\\n1:26 okay yes of course that's even better\\n1:31 done so let me just quickly post it\\n1:37 then\\n1:38 how many live viewers do we have now\\n1:40 i don't know let me check the first time\\n1:43 posted\\n1:44 yeah yeah\\n1:45 17.\\n1:47 amazing\\n1:48 okay so now i have my notes\\n1:52 and are you ready\\n1:55 yeah let's do it yeah\\n1:58 um this week we'll talk about\\n1:59 non-technical parts of the data science\\n2:01 interview we already had an episode\\n2:04 where we talked about\\n2:05 cv like how do you prepare your cv and\\n2:08 other aspects of the interview process\\n2:10 you can go and check our website\\n2:12 we didn't talk a lot about the\\n2:15 behavioral interviews and other less\\n2:16 technical parts of the data science\\n2:19 interview which is what we\\n2:20 we are going to cover today\\n2:23 so we have a special guest today nick\\n2:26 nick started his career as software\\n2:28 engineer on facebook's growth team and\\n2:31 then he worked as safegraph started like\\n2:34 application analytics startup\\n2:36 um\\n2:37 he graduated from the university of\\n2:38 virginia with a degree in system\\n2:41 engineering\\n2:42 and uh yeah so you interned at microsoft\\n2:46 and uh at google google\\n2:49 and as we already know nick is an author\\n2:52 of a book about past async data science\\n2:55 interview i think this is the name ace\\n2:57 the data science interview we can see\\n2:59 exactly around there are like twin and\\n3:01 yeah right here and actually\\n3:04 i also have\\n3:06 yeah amazing just just left\\n3:08 amazing i mean yeah just in time for the\\n3:10 for that okay anyways welcome nick\\n3:14 thank you for having me i'm really\\n3:15 excited to be part of your community and\\n3:17 give a little talk as well as do the\\n3:18 book of the week a little bit later on\\n3:20 in the month\\n3:21 yeah thanks so before we go into our\\n3:24 main topic of icing ace in the\\n3:25 interviews specifically behavioral\\n3:27 interviews let's start with your\\n3:29 background can you tell us about your\\n3:31 career journey so far\\n3:32 yeah absolutely so i've had a pretty\\n3:34 interesting background that's all around\\n3:37 data but um in indirect ways so in\\n3:39 school i studied systems engineering\\n3:41 which is sort of a mix of like\\n3:43 operations research business math i was\\n3:46 on the data infrastructure team as an\\n3:48 intern at google i was a growth engineer\\n3:51 and did\\n3:52 data driven experimentation ran and\\n3:54 implemented many a b tests at facebook\\n3:56 and then i joined a location analytics\\n3:59 startup safe graph that sold alternative\\n4:02 data to hedge funds and retail analytics\\n4:04 companies and most recently i wrote the\\n4:06 book ace the data science interview\\n4:07 which is kind of like the cracking the\\n4:09 coding interview or the lead code\\n4:11 for data scientists machine learning\\n4:13 engineers and data analysts so that's\\n4:15 kind of my background around data\\n4:17 and when i read your\\n4:20 bio i think in a book has your biography\\n4:23 and the\", 'video_id': 'tRdLVUKU7Bo', '_id': 6397}, {'start': 4500, 'content': \"alized\\n4:14 i didn't really enjoy data science as\\n4:16 much because it was very black box it\\n4:18 fell to me because i never was felt like\\n4:20 i was feeding some model but i didn't\\n4:22 really understand what's going on which\\n4:23 is partially due to the fact that my\\n4:24 mathematics background isn't that strong\\n4:27 so i didn't never really got the theory\\n4:29 behind it\\n4:30 but also i realized i kind of miss more\\n4:32 the engineering parts of it and\\n4:34 that was also the time when data\\n4:36 engineering became more of a thing\\n4:37 because companies realized that they\\n4:38 need not just data scientists but also\\n4:40 people that actually before come before\\n4:42 them and\\n4:43 make data available for data science\\n4:45 because that's at the time was a common\\n4:47 frustration for data scientists to not\\n4:48 have data\\n4:51 great ambitions but no data\\n4:54 and then i went\\n4:56 got an offer at native instruments to be\\n4:58 one of their first data engineers\\n5:01 i did that for a while um i still had\\n5:04 the ambition back then to transition\\n5:05 back into data science but i left native\\n5:07 instruments for unrelated reasons before\\n5:10 that happened\\n5:12 then i got another job at another\\n5:13 company as a bi developer\\n5:18 my title was data scientists but really\\n5:19 what i did was\\n5:21 develop custom\\n5:23 with data visualizations\\n5:26 and i realized eventually that this was\\n5:28 kind of a dead end for me\\n5:30 and so i\\n5:32 i remembered my software engineering\\n5:34 background which i actually enjoyed\\n5:36 except it was a repetitive and then\\n5:38 at the time i was speaking to somebody\\n5:40 at thoughtworks she was the first data\\n5:42 scientist at the thoughtworks in germany\\n5:44 at the time and she told me that\\n5:46 thoughtworks was planning to expand its\\n5:48 data engineering offering and what i'd\\n5:49 be interested in\\n5:52 in becoming the solidworks germany's\\n5:54 first data engineer and help her expand\\n5:56 that offering and i thought it was\\n5:58 really exciting and\\n5:59 especially since southwark is a great\\n6:01 place for really learning good software\\n6:03 engineering practices which as a data\\n6:05 engineer is always frustrated as a data\\n6:07 scientist that always frustrated me that\\n6:09 the quality of the code and the\\n6:11 collaboration wasn't as good as i was i\\n6:13 remembered it from my back in\\n6:14 engineering days\\n6:16 and so i jumped on that and that's when\\n6:17 i finally decided to stay in data\\n6:19 engineering which i had done on and off\\n6:21 before\\n6:23 and then then yeah after that was i went\\n6:26 to where i'm now it was my transfers and\\n6:28 built up data engineering there which\\n6:29 way i'm now heading a team\\n6:32 that's quite a story and thanks for\\n6:33 sharing so uh what i also wanted to ask\\n6:36 you the next question i prepared is that\\n6:38 you were a data scientist and then you\\n6:40 switched to data engineering and i\\n6:41 wanted to ask why i think you partly\\n6:43 answered that so you said that\\n6:47 data science was a bit too black boxy\", 'video_id': '3TTu-hYzxeg', '_id': 618}, {'start': 0, 'content': \"0:01 hi everyone Welcome to our event this\\n0:03 event is brought to you by dat do club\\n0:05 which is a community of people who love\\n0:07 data we have weekly events and today is\\n0:09 one of such events if you want to find\\n0:10 out more about the events we have there\\n0:12 is a link in the description click on\\n0:14 that link and you'll see all the other\\n0:16 events we have in our pipeline um do not\\n0:19 forget to subscribe to our YouTube\\n0:20 channel this way you'll stay up to date\\n0:22 with all our future events and you'll\\n0:25 get notifications when they start and\\n0:27 last but not least don't forget to join\\n0:30 our slack Community where you can hang\\n0:33 out with other data into US during\\n0:35 today's interview you can ask any\\n0:37 question you want there is a pin Link in\\n0:39 the live chat click on that link ask\\n0:42 your questions and we will be covering\\n0:43 these questions during the\\n0:47 interview I also\\n0:50 open this on my mobile phone so I'm\\n0:54 still sharing my screen right um so then\\n0:57 uh I see if something is in the live\\n1:02 chat but yeah ad if you're ready we can\\n1:05 start\\n1:07 definitely so this week we'll talk about\\n1:10 Trends in data engineering and we have a\\n1:12 special guest today Adrian\\n1:14 Adrian is a returning guest now\\n1:18 it's third time if we just count\\n1:21 podcasts but if we count other things\\n1:23 like workshops open source demos and\\n1:26 like I don't know what\\n1:28 else people probably know you already\\n1:31 and have seen so many times so Adrian is\\n1:35 a co-founder of DT Hub and which is the\\n1:39 company behind DLT and this is one of\\n1:42 the things we will talk about today too\\n1:44 uh but in general we wanted to talk\\n1:45 about transends of data engineering\\n1:47 because this is um when we launched our\\n1:50 course recently data engineering Zoom\\n1:52 Camp uh one of the questions um there\\n1:56 from the audience from the participants\\n1:58 was\\n2:00 how do you see data engineering evolving\\n2:03 and what are the trends in data\\n2:05 engineering and I realized that I don't\\n2:09 know the answer to this question I\\n2:11 cannot really answer and I thought who\\n2:12 might have the answer and then of course\\n2:15 I thought about you Adrian so welcome to\\n2:18 our event Welcome to our podcast\\n2:19 interview it's a really great pleasure\\n2:21 to have you again here pleasure is mine\\n2:24 to join um I don't have the answers\\n2:27 either you know I just have my view of\\n2:29 what I can see and you know I can\\n2:31 speculate a little bit I can talk about\\n2:33 what I\\n2:34 observed and this is what\\n2:37 it was what makes it interesting right I\\n2:40 mean everyone has opinions uh so uh and\\n2:44 you're way closer to date engineering\\n2:46 than I am uh so we can talk about that\\n2:51 and as always the questions for today's\\n2:53 interview are prepared by johana Bayer\\n2:55 thanks Johanna for your help and before\\n2:57 we go into talking about Trends in\\n3:00 engineering maybe I know it's third time\\n3:03 you will need to do this but maybe you\\n3:04 \", 'video_id': 'AlCFKbFIEM8', '_id': 1229}]\n",
      "RES  ← search call_iAH9afrQLxz8BQPDMTl4YjTf [{'start': 16500, 'content': \"not forget anything it's\\n18:53 uh\\n18:54 uh I tried a lot of\\n18:57 scripting languages I ended up using\\n19:00 python because it was the most used in\\n19:03 the industry just I didn't think more\\n19:06 about it uh\\n19:09 it's being used I'm gonna use this okay\\n19:12 same for the cloud you are the the\\n19:18 AWS at that time the Google Cloud was\\n19:22 somewhat there and the Azure was just\\n19:24 investing a lot of it in it so save a\\n19:28 lot of my company was using the Azure\\n19:31 cloud of course and\\n19:33 um\\n19:34 a lot of jobs posts postings anyway\\n19:36 there were recruiting for people using\\n19:40 Python and the Azure Cloud so for me it\\n19:43 was the let's say a very data driven and\\n19:46 practical choice to\\n19:48 to just go for this but in the end as a\\n19:51 feedback all the clouds they are really\\n19:53 more similar and dissimilar what you\\n19:57 will find in a platform will look mostly\\n19:59 the same into another cloud provider\\n20:02 don't focus on\\n20:05 I would say Do not focus on getting\\n20:07 certifications to prove that you know\\n20:09 the cloud or whatever because what is\\n20:12 the most important is the\\n20:15 is the to grasp the very strong basics\\n20:18 of what is a trade operation what are\\n20:20 the types of services you have access to\\n20:22 to store your data what are your\\n20:26 options to build what are your tools\\n20:28 available in this platform and if you\\n20:30 know that you need a hammer to just uh\\n20:34 uh insert a nail into a wood blank you\\n20:37 will find your wood plank you will find\\n20:39 your nail you will find your Hammer into\\n20:41 this new platform no worries this is\\n20:44 what I will provide and that's uh\\n20:48 advice you share as a data manager right\\n20:50 now I mean a data engineering manager\\n20:53 because you heard the engineers\\n20:54 currently right\\n20:56 say it again do you hire data Engineers\\n20:59 currently at your current role yeah yeah\\n21:01 I actually I had one that I didn't know\\n21:05 which has the guy has more experience\\n21:07 than my cell phone the lot of bi and\\n21:11 that architecture side of things you\\n21:12 know but still when it comes to uh big\\n21:15 data and using spark and new platform\\n21:19 like the the data bricks and whatever\\n21:22 there's still a transition to do but\\n21:24 when I hired basically the interview\\n21:28 was more focused on\\n21:31 for me you have some scars about about\\n21:34 doing data pipeline projects you know\\n21:36 and tell me how it's going to go wrong\\n21:38 and what did you do uh\\n21:41 uh somewhat changing the\\n21:44 the strong opinions on good practices\\n21:48 versus reality uh\\n21:51 Etc so\\n21:52 uh yeah when I hire for data engineering\\n21:56 role I don't look for perfect\\n21:59 certifications I look for experience and\\n22:03 I look for the scale of the projects\\n22:05 people have been working on the scale of\\n22:07 the teams that I've been working on\\n22:10 the\\n22:12 in general the attitude towards solving\\n22:15 the problem with the tools you have you\\n22:17 know\\n22:18 if people are afraid for exam\", 'video_id': 'qWG--iYO2uc', '_id': 5071}, {'start': 1500, 'content': \"during the interview and that's\\n1:33 all i have\\n1:37 for the introduction are you ready to\\n1:38 start yeah\\n1:40 okay so let me just\\n1:47 pull my notes\\n1:52 okay we have um today we will talk about\\n1:55 uh the difference between uh\\n1:57 big data engineers and data scientists\\n2:00 and we have special guests today\\n2:02 rexella ruxlana works as a big data\\n2:04 engineer\\n2:05 in uh captify right yeah and\\n2:09 uh yeah so today she will talk about\\n2:13 the role of a data engineer and data\\n2:14 scientist welcome\\n2:17 thank you before we go before we start\\n2:20 with our\\n2:21 main topic let's talk a bit about your\\n2:24 background\\n2:25 can you tell us a bit about your career\\n2:26 journey so far\\n2:28 yeah sure so i have a software\\n2:31 engineering degree\\n2:32 in one of the key universities it's both\\n2:35 bachelor and\\n2:36 master's degree and after that i was\\n2:38 working some time as\\n2:40 a background engineer in java mostly and\\n2:43 just at some point i\\n2:44 learned about data science big data\\n2:46 engineering and\\n2:48 i had some time to make a decision what\\n2:50 exactly i would want to do\\n2:52 and kind of back-end engineering at some\\n2:54 point just got a bit boring for me so\\n2:56 i switched into big data engineering\\n2:59 learned the\\n2:59 scala programming language and that's my\\n3:02 main programming language\\n3:04 now and um for a few years i worked at\\n3:07 a company called sql it's quite famous\\n3:10 in ukraine because it's\\n3:11 quite big company one of the top five\\n3:13 and\\n3:14 it's an outsourcing company which works\\n3:16 with clients and\\n3:18 as well as has some research so i was\\n3:21 working at the\\n3:22 r d department we had some internal\\n3:24 research stuff and\\n3:26 also i worked for some client projects\\n3:28 and\\n3:29 only two years ago i joined captify\\n3:32 which is\\n3:33 a product company they are building a\\n3:35 product in the sphere of\\n3:37 advertising and actually a company is\\n3:40 british it's based in uk\\n3:41 but it has a part of the engineering\\n3:44 team in cave\\n3:44 where i'm based and mostly working on\\n3:48 the product part specifically\\n3:50 in the big data engineering team\\n3:53 yeah i've heard that in advertising\\n3:55 there are there is so much data\\n3:57 that this data engineering big data\\n4:00 engineering becomes really important\\n4:01 because\\n4:02 these companies every day gets get\\n4:04 terabytes of data and they need to\\n4:06 effectively\\n4:07 uh process this data right yeah\\n4:10 and also what kind of makes uh the\\n4:12 solution of creptify unique\\n4:14 is data insights which are obviously\\n4:17 delivered to the help of\\n4:19 big data engineering team by having\\n4:21 different\\n4:22 sources of data and ways to transform\\n4:24 this data and deliver it to the clients\\n4:27 so what do you do at work uh what do you\\n4:29 usually do\\n4:30 as a big data engineer so my main\\n4:33 responsibility is building data\\n4:35 pipelines uh usually it's etl format\\n4:37 extract transform load so kind of\\n4:39 reading the data from some source\\n4:42 building transformations s\", 'video_id': 'yg3d1lFd7Uo', '_id': 7522}, {'start': 12000, 'content': \" it's not not for\\n12:06 profit allows just a different\\n12:09 more flexibility more\\n12:12 um\\n12:13 more freedom in the curriculum more tips\\n12:16 more stories from my own experience when\\n12:19 somebody needs extra help\\n12:22 um and the summer I was all uh designed\\n12:25 a curriculum together with a couple of\\n12:26 people at AI Guild and\\n12:29 um what fraud fraud detection and\\n12:31 chargeback as well\\n12:34 fancy class it's actually one of the\\n12:37 questions I uh I have about that so in\\n12:42 your LinkedIn\\n12:43 um you have this experience with AI\\n12:45 Guild that you mentioned and the title\\n12:48 that you have for this for this job is\\n12:51 program manager so responsibilities\\n12:53 according to your profile is designing\\n12:55 the fintech data science curriculum\\n12:57 collecting market Standard practices\\n13:00 data sets and exercises per topic and\\n13:03 finding teachers so yeah I was I got\\n13:05 really curious because we also in data\\n13:07 talks Club also do courses\\n13:10 and yeah this is something I I also need\\n13:13 to do often so I really wanted to ask\\n13:16 you more about this uh and uh I I'll\\n13:20 write my employer was the idea that that\\n13:22 Daniel and Chris I don't know it's a\\n13:24 small community we know each other\\n13:27 um yeah it was\\n13:30 I mean first I was I think I was asked\\n13:32 to be a teacher and I I said I had a lot\\n13:34 of ideas about the the program itself\\n13:36 and how one can update a little bit the\\n13:39 curriculum to make it a bit more modern\\n13:42 and that's all I got to work together\\n13:44 with Daniel on this and then um I got\\n13:47 inspired that maybe we should have some\\n13:49 Google certification or Cloud\\n13:51 certifications if we work in bigquery\\n13:53 and do anything data related we might as\\n13:56 well get some certifications for those\\n13:58 students so you know putting my\\n14:00 connections at Google and got them\\n14:02 access to this um there is a learning\\n14:04 platform that if you are a Google\\n14:05 customer you can have access to it\\n14:08 so now on top of everything the students\\n14:11 also get certification so I think that's\\n14:13 pretty unique\\n14:15 um in in that sense\\n14:16 and\\n14:18 you know what what other questions would\\n14:20 you have around yeah the question was uh\\n14:22 yeah you actually didn't answer that yet\\n14:25 um\\n14:25 so you said you be asked you AI Guild\\n14:29 asked you to join them as a teacher but\\n14:31 you were more interested in uh\\n14:35 you did both okay\\n14:38 and I'm I'm really curious um like what\\n14:41 does it mean what does it mean to design\\n14:44 a curriculum what what did you do there\\n14:46 exactly so this I didn't alone it was\\n14:50 also done yeah right credit credit is\\n14:52 due so you plural I guess\\n14:55 happy\\n14:56 um we we first of all we I well here I I\\n15:01 was interviewing Financial techies so\\n15:04 managers of data in fintech companies or\\n15:09 in fintech departments or in fraud\\n15:11 departments what kind of methodologies\\n15:13 they have implemented in their\\n15:16 um in t\", 'video_id': 'saaRRzgHsmE', '_id': 5734}, {'start': 4500, 'content': \"alized\\n4:14 i didn't really enjoy data science as\\n4:16 much because it was very black box it\\n4:18 fell to me because i never was felt like\\n4:20 i was feeding some model but i didn't\\n4:22 really understand what's going on which\\n4:23 is partially due to the fact that my\\n4:24 mathematics background isn't that strong\\n4:27 so i didn't never really got the theory\\n4:29 behind it\\n4:30 but also i realized i kind of miss more\\n4:32 the engineering parts of it and\\n4:34 that was also the time when data\\n4:36 engineering became more of a thing\\n4:37 because companies realized that they\\n4:38 need not just data scientists but also\\n4:40 people that actually before come before\\n4:42 them and\\n4:43 make data available for data science\\n4:45 because that's at the time was a common\\n4:47 frustration for data scientists to not\\n4:48 have data\\n4:51 great ambitions but no data\\n4:54 and then i went\\n4:56 got an offer at native instruments to be\\n4:58 one of their first data engineers\\n5:01 i did that for a while um i still had\\n5:04 the ambition back then to transition\\n5:05 back into data science but i left native\\n5:07 instruments for unrelated reasons before\\n5:10 that happened\\n5:12 then i got another job at another\\n5:13 company as a bi developer\\n5:18 my title was data scientists but really\\n5:19 what i did was\\n5:21 develop custom\\n5:23 with data visualizations\\n5:26 and i realized eventually that this was\\n5:28 kind of a dead end for me\\n5:30 and so i\\n5:32 i remembered my software engineering\\n5:34 background which i actually enjoyed\\n5:36 except it was a repetitive and then\\n5:38 at the time i was speaking to somebody\\n5:40 at thoughtworks she was the first data\\n5:42 scientist at the thoughtworks in germany\\n5:44 at the time and she told me that\\n5:46 thoughtworks was planning to expand its\\n5:48 data engineering offering and what i'd\\n5:49 be interested in\\n5:52 in becoming the solidworks germany's\\n5:54 first data engineer and help her expand\\n5:56 that offering and i thought it was\\n5:58 really exciting and\\n5:59 especially since southwark is a great\\n6:01 place for really learning good software\\n6:03 engineering practices which as a data\\n6:05 engineer is always frustrated as a data\\n6:07 scientist that always frustrated me that\\n6:09 the quality of the code and the\\n6:11 collaboration wasn't as good as i was i\\n6:13 remembered it from my back in\\n6:14 engineering days\\n6:16 and so i jumped on that and that's when\\n6:17 i finally decided to stay in data\\n6:19 engineering which i had done on and off\\n6:21 before\\n6:23 and then then yeah after that was i went\\n6:26 to where i'm now it was my transfers and\\n6:28 built up data engineering there which\\n6:29 way i'm now heading a team\\n6:32 that's quite a story and thanks for\\n6:33 sharing so uh what i also wanted to ask\\n6:36 you the next question i prepared is that\\n6:38 you were a data scientist and then you\\n6:40 switched to data engineering and i\\n6:41 wanted to ask why i think you partly\\n6:43 answered that so you said that\\n6:47 data science was a bit too black boxy\", 'video_id': '3TTu-hYzxeg', '_id': 618}, {'start': 13500, 'content': \"and that's all I got to work together\\n13:44 with Daniel on this and then um I got\\n13:47 inspired that maybe we should have some\\n13:49 Google certification or Cloud\\n13:51 certifications if we work in bigquery\\n13:53 and do anything data related we might as\\n13:56 well get some certifications for those\\n13:58 students so you know putting my\\n14:00 connections at Google and got them\\n14:02 access to this um there is a learning\\n14:04 platform that if you are a Google\\n14:05 customer you can have access to it\\n14:08 so now on top of everything the students\\n14:11 also get certification so I think that's\\n14:13 pretty unique\\n14:15 um in in that sense\\n14:16 and\\n14:18 you know what what other questions would\\n14:20 you have around yeah the question was uh\\n14:22 yeah you actually didn't answer that yet\\n14:25 um\\n14:25 so you said you be asked you AI Guild\\n14:29 asked you to join them as a teacher but\\n14:31 you were more interested in uh\\n14:35 you did both okay\\n14:38 and I'm I'm really curious um like what\\n14:41 does it mean what does it mean to design\\n14:44 a curriculum what what did you do there\\n14:46 exactly so this I didn't alone it was\\n14:50 also done yeah right credit credit is\\n14:52 due so you plural I guess\\n14:55 happy\\n14:56 um we we first of all we I well here I I\\n15:01 was interviewing Financial techies so\\n15:04 managers of data in fintech companies or\\n15:09 in fintech departments or in fraud\\n15:11 departments what kind of methodologies\\n15:13 they have implemented in their\\n15:16 um in their teams and if this is an\\n15:20 exhaustive list and I came up with the\\n15:21 list like money laundering identity\\n15:23 theft so on identity management and so\\n15:27 on and so forth then I audited some\\n15:30 Coursera classes and see what is the\\n15:32 fraud class because there are classes on\\n15:34 fraud massive massive classes like it\\n15:38 could be a semester but just to glean a\\n15:40 couple of Concepts from them\\n15:43 um so as I said the specifically\\n15:45 curriculum was fintech and after getting\\n15:48 the the high level topics uh we decided\\n15:52 to spend maybe a couple of days on each\\n15:54 topic find the data sets that would\\n15:56 support it\\n15:58 um think of complexity trying ourselves\\n16:00 to actually recode with the problems\\n16:03 ourselves before uh before\\n16:07 putting out the curriculum because what\\n16:09 if it's too hard right I need to like as\\n16:12 a manager I need to understand the\\n16:13 internships piece you know like I have\\n16:16 to work that that part\\n16:19 um and we had also\\n16:20 so that this curriculum was\\n16:22 um it's a company that wanted to have it\\n16:25 to hire these people and we thought like\\n16:28 well since the company is paying for\\n16:30 this pilot we could have also like add\\n16:33 Cloud certification on top\\n16:36 um add a little bit of some business\\n16:38 knowledge or notes related to why we are\\n16:41 doing these types of models\\n16:43 um with lots of examples like what does\\n16:45 it mean in Commerce what does it mean\\n16:47 dating what does it m\", 'video_id': 'saaRRzgHsmE', '_id': 5735}]\n"
     ]
    }
   ],
   "source": [
    "stage2 = await do_research(\n",
    "    stage=2,\n",
    "    stage_instructions=\"continue research\",\n",
    "    previous_stages=[stage1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b91c1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"stage\": 2,\n",
      " \"explored_keywords\": [\n",
      "  {\n",
      "   \"keyword\": \"data engineering projects for beginners\",\n",
      "   \"relevant_references\": [\n",
      "    {\n",
      "     \"document_id\": 6845,\n",
      "     \"quote\": \"...one useful data set could be car parking data because we collect uh car parking figures in real time...\",\n",
      "     \"timestamp\": \"47:07\",\n",
      "     \"relevance_to_keyword\": \"This quote provides a concrete example of a beginner project involving real-time data.\",\n",
      "     \"relevance_to_user_intent\": \"It suggests a practical project idea that can help beginners apply data engineering skills.\"\n",
      "    },\n",
      "    {\n",
      "     \"document_id\": 2284,\n",
      "     \"quote\": \"...first if you start with the source systems where data exists right it could be relational database flat files cloud s3...\",\n",
      "     \"timestamp\": \"58:12\",\n",
      "     \"relevance_to_keyword\": \"This snippet discusses the foundational steps in data engineering that beginners should understand.\",\n",
      "     \"relevance_to_user_intent\": \"It conveys basics of data engineering project workflow, useful for beginners.\"\n",
      "    }\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"verifiable_insights\": [\n",
      "  {\n",
      "   \"insight\": \"Building projects using real-time data sets, such as car parking data, is a recommended practice for beginners in data engineering.\",\n",
      "   \"references\": [\n",
      "    {\n",
      "     \"document_id\": 6845,\n",
      "     \"quote\": \"...one useful data set could be car parking data because we collect um car parking figures in real time...\",\n",
      "     \"timestamp\": \"47:07\",\n",
      "     \"relevance_to_keyword\": \"This highlights a specific project that beginners can undertake to gain practical experience.\",\n",
      "     \"relevance_to_user_intent\": \"It provides actionable guidance for beginners on how to apply their knowledge.\"\n",
      "    }\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"insight\": \"Understanding the full data pipeline, from source systems to data consumption, is crucial for aspiring data engineers.\",\n",
      "   \"references\": [\n",
      "    {\n",
      "     \"document_id\": 2284,\n",
      "     \"quote\": \"...first if you start with the source systems where data exists right it could be relational database flat files cloud s3...\",\n",
      "     \"timestamp\": \"58:12\",\n",
      "     \"relevance_to_keyword\": \"This explains the essential steps in data engineering projects, which are foundational for beginners.\",\n",
      "     \"relevance_to_user_intent\": \"It informs beginners about the comprehensive process in data engineering.\"\n",
      "    }\n",
      "   ]\n",
      "  },\n",
      "  {\n",
      "   \"insight\": \"Online courses and structured projects can greatly enhance the learning experience for beginners in data engineering.\",\n",
      "   \"references\": [\n",
      "    {\n",
      "     \"document_id\": 2965,\n",
      "     \"quote\": \"...I felt that before I had that sort of guidance I was just kind of fumbling around in the dark...\",\n",
      "     \"timestamp\": \"19:40\",\n",
      "     \"relevance_to_keyword\": \"This indicates that guided learning paths increase comprehension and retention for beginners.\",\n",
      "     \"relevance_to_user_intent\": \"It suggests that finding structured courses is essential for beginners.\"\n",
      "    }\n",
      "   ]\n",
      "  }\n",
      " ],\n",
      " \"stage_summary\": \"In this stage, we explored various projects suitable for beginners in data engineering, emphasizing the importance of working with real-time data sets and understanding the end-to-end data pipeline. Recommendations for online courses and project-based learning reinforced the need for structured guidance as beginners navigate the complexities of data engineering. The insights gathered can help users build practical skills and enhance their knowledge in a meaningful way.\",\n",
      " \"recommended_next_steps\": \"For the next stage, we should delve deeper into advanced data engineering skills, certifications, mentorship opportunities, and real-world applications. Additionally, it may be beneficial to look into strategies for transitioning from academic learning to professional roles in data engineering.\",\n",
      " \"recommended_next_keywords\": [\n",
      "  \"advanced data engineering skills\",\n",
      "  \"data engineering certifications\",\n",
      "  \"mentorship opportunities in data engineering\",\n",
      "  \"real-world applications of data engineering\",\n",
      "  \"transitioning from academic to professional in data engineering\",\n",
      "  \"data engineering interview preparation\",\n",
      "  \"best practices for data engineering projects\"\n",
      " ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(stage2.model_dump_json(indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3cef6bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALL → search {'query': 'advanced data engineering skills'} call_eTeG4HivalZD0buG00WbnrGs\n",
      "CALL → search {'query': 'data engineering certifications'} call_yBPGq2JqrMa7OJOLStxrNvrT\n",
      "CALL → search {'query': 'mentorship opportunities in data engineering'} call_JRcEzrYwbG0n1yXJxmnpG4Bm\n",
      "CALL → search {'query': 'real-world applications of data engineering'} call_sr2t5sXOGm3J4tVZZT9wYk8a\n",
      "CALL → search {'query': 'transitioning from academic to professional in data engineering'} call_rlwea5ceH7pdTrohhqqTqEiD\n",
      "CALL → search {'query': 'data engineering interview preparation'} call_X43dMzO9YaXAUsvqk1yplPSv\n",
      "CALL → search {'query': 'best practices for data engineering projects'} call_uifSsg3Dqdk1p34CpozmH2qV\n",
      "RES  ← search call_yBPGq2JqrMa7OJOLStxrNvrT [{'start': 16500, 'content': \"not forget anything it's\\n18:53 uh\\n18:54 uh I tried a lot of\\n18:57 scripting languages I ended up using\\n19:00 python because it was the most used in\\n19:03 the industry just I didn't think more\\n19:06 about it uh\\n19:09 it's being used I'm gonna use this okay\\n19:12 same for the cloud you are the the\\n19:18 AWS at that time the Google Cloud was\\n19:22 somewhat there and the Azure was just\\n19:24 investing a lot of it in it so save a\\n19:28 lot of my company was using the Azure\\n19:31 cloud of course and\\n19:33 um\\n19:34 a lot of jobs posts postings anyway\\n19:36 there were recruiting for people using\\n19:40 Python and the Azure Cloud so for me it\\n19:43 was the let's say a very data driven and\\n19:46 practical choice to\\n19:48 to just go for this but in the end as a\\n19:51 feedback all the clouds they are really\\n19:53 more similar and dissimilar what you\\n19:57 will find in a platform will look mostly\\n19:59 the same into another cloud provider\\n20:02 don't focus on\\n20:05 I would say Do not focus on getting\\n20:07 certifications to prove that you know\\n20:09 the cloud or whatever because what is\\n20:12 the most important is the\\n20:15 is the to grasp the very strong basics\\n20:18 of what is a trade operation what are\\n20:20 the types of services you have access to\\n20:22 to store your data what are your\\n20:26 options to build what are your tools\\n20:28 available in this platform and if you\\n20:30 know that you need a hammer to just uh\\n20:34 uh insert a nail into a wood blank you\\n20:37 will find your wood plank you will find\\n20:39 your nail you will find your Hammer into\\n20:41 this new platform no worries this is\\n20:44 what I will provide and that's uh\\n20:48 advice you share as a data manager right\\n20:50 now I mean a data engineering manager\\n20:53 because you heard the engineers\\n20:54 currently right\\n20:56 say it again do you hire data Engineers\\n20:59 currently at your current role yeah yeah\\n21:01 I actually I had one that I didn't know\\n21:05 which has the guy has more experience\\n21:07 than my cell phone the lot of bi and\\n21:11 that architecture side of things you\\n21:12 know but still when it comes to uh big\\n21:15 data and using spark and new platform\\n21:19 like the the data bricks and whatever\\n21:22 there's still a transition to do but\\n21:24 when I hired basically the interview\\n21:28 was more focused on\\n21:31 for me you have some scars about about\\n21:34 doing data pipeline projects you know\\n21:36 and tell me how it's going to go wrong\\n21:38 and what did you do uh\\n21:41 uh somewhat changing the\\n21:44 the strong opinions on good practices\\n21:48 versus reality uh\\n21:51 Etc so\\n21:52 uh yeah when I hire for data engineering\\n21:56 role I don't look for perfect\\n21:59 certifications I look for experience and\\n22:03 I look for the scale of the projects\\n22:05 people have been working on the scale of\\n22:07 the teams that I've been working on\\n22:10 the\\n22:12 in general the attitude towards solving\\n22:15 the problem with the tools you have you\\n22:17 know\\n22:18 if people are afraid for exam\", 'video_id': 'qWG--iYO2uc', '_id': 5071}, {'start': 1500, 'content': \"during the interview and that's\\n1:33 all i have\\n1:37 for the introduction are you ready to\\n1:38 start yeah\\n1:40 okay so let me just\\n1:47 pull my notes\\n1:52 okay we have um today we will talk about\\n1:55 uh the difference between uh\\n1:57 big data engineers and data scientists\\n2:00 and we have special guests today\\n2:02 rexella ruxlana works as a big data\\n2:04 engineer\\n2:05 in uh captify right yeah and\\n2:09 uh yeah so today she will talk about\\n2:13 the role of a data engineer and data\\n2:14 scientist welcome\\n2:17 thank you before we go before we start\\n2:20 with our\\n2:21 main topic let's talk a bit about your\\n2:24 background\\n2:25 can you tell us a bit about your career\\n2:26 journey so far\\n2:28 yeah sure so i have a software\\n2:31 engineering degree\\n2:32 in one of the key universities it's both\\n2:35 bachelor and\\n2:36 master's degree and after that i was\\n2:38 working some time as\\n2:40 a background engineer in java mostly and\\n2:43 just at some point i\\n2:44 learned about data science big data\\n2:46 engineering and\\n2:48 i had some time to make a decision what\\n2:50 exactly i would want to do\\n2:52 and kind of back-end engineering at some\\n2:54 point just got a bit boring for me so\\n2:56 i switched into big data engineering\\n2:59 learned the\\n2:59 scala programming language and that's my\\n3:02 main programming language\\n3:04 now and um for a few years i worked at\\n3:07 a company called sql it's quite famous\\n3:10 in ukraine because it's\\n3:11 quite big company one of the top five\\n3:13 and\\n3:14 it's an outsourcing company which works\\n3:16 with clients and\\n3:18 as well as has some research so i was\\n3:21 working at the\\n3:22 r d department we had some internal\\n3:24 research stuff and\\n3:26 also i worked for some client projects\\n3:28 and\\n3:29 only two years ago i joined captify\\n3:32 which is\\n3:33 a product company they are building a\\n3:35 product in the sphere of\\n3:37 advertising and actually a company is\\n3:40 british it's based in uk\\n3:41 but it has a part of the engineering\\n3:44 team in cave\\n3:44 where i'm based and mostly working on\\n3:48 the product part specifically\\n3:50 in the big data engineering team\\n3:53 yeah i've heard that in advertising\\n3:55 there are there is so much data\\n3:57 that this data engineering big data\\n4:00 engineering becomes really important\\n4:01 because\\n4:02 these companies every day gets get\\n4:04 terabytes of data and they need to\\n4:06 effectively\\n4:07 uh process this data right yeah\\n4:10 and also what kind of makes uh the\\n4:12 solution of creptify unique\\n4:14 is data insights which are obviously\\n4:17 delivered to the help of\\n4:19 big data engineering team by having\\n4:21 different\\n4:22 sources of data and ways to transform\\n4:24 this data and deliver it to the clients\\n4:27 so what do you do at work uh what do you\\n4:29 usually do\\n4:30 as a big data engineer so my main\\n4:33 responsibility is building data\\n4:35 pipelines uh usually it's etl format\\n4:37 extract transform load so kind of\\n4:39 reading the data from some source\\n4:42 building transformations s\", 'video_id': 'yg3d1lFd7Uo', '_id': 7522}, {'start': 12000, 'content': \" it's not not for\\n12:06 profit allows just a different\\n12:09 more flexibility more\\n12:12 um\\n12:13 more freedom in the curriculum more tips\\n12:16 more stories from my own experience when\\n12:19 somebody needs extra help\\n12:22 um and the summer I was all uh designed\\n12:25 a curriculum together with a couple of\\n12:26 people at AI Guild and\\n12:29 um what fraud fraud detection and\\n12:31 chargeback as well\\n12:34 fancy class it's actually one of the\\n12:37 questions I uh I have about that so in\\n12:42 your LinkedIn\\n12:43 um you have this experience with AI\\n12:45 Guild that you mentioned and the title\\n12:48 that you have for this for this job is\\n12:51 program manager so responsibilities\\n12:53 according to your profile is designing\\n12:55 the fintech data science curriculum\\n12:57 collecting market Standard practices\\n13:00 data sets and exercises per topic and\\n13:03 finding teachers so yeah I was I got\\n13:05 really curious because we also in data\\n13:07 talks Club also do courses\\n13:10 and yeah this is something I I also need\\n13:13 to do often so I really wanted to ask\\n13:16 you more about this uh and uh I I'll\\n13:20 write my employer was the idea that that\\n13:22 Daniel and Chris I don't know it's a\\n13:24 small community we know each other\\n13:27 um yeah it was\\n13:30 I mean first I was I think I was asked\\n13:32 to be a teacher and I I said I had a lot\\n13:34 of ideas about the the program itself\\n13:36 and how one can update a little bit the\\n13:39 curriculum to make it a bit more modern\\n13:42 and that's all I got to work together\\n13:44 with Daniel on this and then um I got\\n13:47 inspired that maybe we should have some\\n13:49 Google certification or Cloud\\n13:51 certifications if we work in bigquery\\n13:53 and do anything data related we might as\\n13:56 well get some certifications for those\\n13:58 students so you know putting my\\n14:00 connections at Google and got them\\n14:02 access to this um there is a learning\\n14:04 platform that if you are a Google\\n14:05 customer you can have access to it\\n14:08 so now on top of everything the students\\n14:11 also get certification so I think that's\\n14:13 pretty unique\\n14:15 um in in that sense\\n14:16 and\\n14:18 you know what what other questions would\\n14:20 you have around yeah the question was uh\\n14:22 yeah you actually didn't answer that yet\\n14:25 um\\n14:25 so you said you be asked you AI Guild\\n14:29 asked you to join them as a teacher but\\n14:31 you were more interested in uh\\n14:35 you did both okay\\n14:38 and I'm I'm really curious um like what\\n14:41 does it mean what does it mean to design\\n14:44 a curriculum what what did you do there\\n14:46 exactly so this I didn't alone it was\\n14:50 also done yeah right credit credit is\\n14:52 due so you plural I guess\\n14:55 happy\\n14:56 um we we first of all we I well here I I\\n15:01 was interviewing Financial techies so\\n15:04 managers of data in fintech companies or\\n15:09 in fintech departments or in fraud\\n15:11 departments what kind of methodologies\\n15:13 they have implemented in their\\n15:16 um in t\", 'video_id': 'saaRRzgHsmE', '_id': 5734}, {'start': 4500, 'content': \"alized\\n4:14 i didn't really enjoy data science as\\n4:16 much because it was very black box it\\n4:18 fell to me because i never was felt like\\n4:20 i was feeding some model but i didn't\\n4:22 really understand what's going on which\\n4:23 is partially due to the fact that my\\n4:24 mathematics background isn't that strong\\n4:27 so i didn't never really got the theory\\n4:29 behind it\\n4:30 but also i realized i kind of miss more\\n4:32 the engineering parts of it and\\n4:34 that was also the time when data\\n4:36 engineering became more of a thing\\n4:37 because companies realized that they\\n4:38 need not just data scientists but also\\n4:40 people that actually before come before\\n4:42 them and\\n4:43 make data available for data science\\n4:45 because that's at the time was a common\\n4:47 frustration for data scientists to not\\n4:48 have data\\n4:51 great ambitions but no data\\n4:54 and then i went\\n4:56 got an offer at native instruments to be\\n4:58 one of their first data engineers\\n5:01 i did that for a while um i still had\\n5:04 the ambition back then to transition\\n5:05 back into data science but i left native\\n5:07 instruments for unrelated reasons before\\n5:10 that happened\\n5:12 then i got another job at another\\n5:13 company as a bi developer\\n5:18 my title was data scientists but really\\n5:19 what i did was\\n5:21 develop custom\\n5:23 with data visualizations\\n5:26 and i realized eventually that this was\\n5:28 kind of a dead end for me\\n5:30 and so i\\n5:32 i remembered my software engineering\\n5:34 background which i actually enjoyed\\n5:36 except it was a repetitive and then\\n5:38 at the time i was speaking to somebody\\n5:40 at thoughtworks she was the first data\\n5:42 scientist at the thoughtworks in germany\\n5:44 at the time and she told me that\\n5:46 thoughtworks was planning to expand its\\n5:48 data engineering offering and what i'd\\n5:49 be interested in\\n5:52 in becoming the solidworks germany's\\n5:54 first data engineer and help her expand\\n5:56 that offering and i thought it was\\n5:58 really exciting and\\n5:59 especially since southwark is a great\\n6:01 place for really learning good software\\n6:03 engineering practices which as a data\\n6:05 engineer is always frustrated as a data\\n6:07 scientist that always frustrated me that\\n6:09 the quality of the code and the\\n6:11 collaboration wasn't as good as i was i\\n6:13 remembered it from my back in\\n6:14 engineering days\\n6:16 and so i jumped on that and that's when\\n6:17 i finally decided to stay in data\\n6:19 engineering which i had done on and off\\n6:21 before\\n6:23 and then then yeah after that was i went\\n6:26 to where i'm now it was my transfers and\\n6:28 built up data engineering there which\\n6:29 way i'm now heading a team\\n6:32 that's quite a story and thanks for\\n6:33 sharing so uh what i also wanted to ask\\n6:36 you the next question i prepared is that\\n6:38 you were a data scientist and then you\\n6:40 switched to data engineering and i\\n6:41 wanted to ask why i think you partly\\n6:43 answered that so you said that\\n6:47 data science was a bit too black boxy\", 'video_id': '3TTu-hYzxeg', '_id': 618}, {'start': 13500, 'content': \"and that's all I got to work together\\n13:44 with Daniel on this and then um I got\\n13:47 inspired that maybe we should have some\\n13:49 Google certification or Cloud\\n13:51 certifications if we work in bigquery\\n13:53 and do anything data related we might as\\n13:56 well get some certifications for those\\n13:58 students so you know putting my\\n14:00 connections at Google and got them\\n14:02 access to this um there is a learning\\n14:04 platform that if you are a Google\\n14:05 customer you can have access to it\\n14:08 so now on top of everything the students\\n14:11 also get certification so I think that's\\n14:13 pretty unique\\n14:15 um in in that sense\\n14:16 and\\n14:18 you know what what other questions would\\n14:20 you have around yeah the question was uh\\n14:22 yeah you actually didn't answer that yet\\n14:25 um\\n14:25 so you said you be asked you AI Guild\\n14:29 asked you to join them as a teacher but\\n14:31 you were more interested in uh\\n14:35 you did both okay\\n14:38 and I'm I'm really curious um like what\\n14:41 does it mean what does it mean to design\\n14:44 a curriculum what what did you do there\\n14:46 exactly so this I didn't alone it was\\n14:50 also done yeah right credit credit is\\n14:52 due so you plural I guess\\n14:55 happy\\n14:56 um we we first of all we I well here I I\\n15:01 was interviewing Financial techies so\\n15:04 managers of data in fintech companies or\\n15:09 in fintech departments or in fraud\\n15:11 departments what kind of methodologies\\n15:13 they have implemented in their\\n15:16 um in their teams and if this is an\\n15:20 exhaustive list and I came up with the\\n15:21 list like money laundering identity\\n15:23 theft so on identity management and so\\n15:27 on and so forth then I audited some\\n15:30 Coursera classes and see what is the\\n15:32 fraud class because there are classes on\\n15:34 fraud massive massive classes like it\\n15:38 could be a semester but just to glean a\\n15:40 couple of Concepts from them\\n15:43 um so as I said the specifically\\n15:45 curriculum was fintech and after getting\\n15:48 the the high level topics uh we decided\\n15:52 to spend maybe a couple of days on each\\n15:54 topic find the data sets that would\\n15:56 support it\\n15:58 um think of complexity trying ourselves\\n16:00 to actually recode with the problems\\n16:03 ourselves before uh before\\n16:07 putting out the curriculum because what\\n16:09 if it's too hard right I need to like as\\n16:12 a manager I need to understand the\\n16:13 internships piece you know like I have\\n16:16 to work that that part\\n16:19 um and we had also\\n16:20 so that this curriculum was\\n16:22 um it's a company that wanted to have it\\n16:25 to hire these people and we thought like\\n16:28 well since the company is paying for\\n16:30 this pilot we could have also like add\\n16:33 Cloud certification on top\\n16:36 um add a little bit of some business\\n16:38 knowledge or notes related to why we are\\n16:41 doing these types of models\\n16:43 um with lots of examples like what does\\n16:45 it mean in Commerce what does it mean\\n16:47 dating what does it m\", 'video_id': 'saaRRzgHsmE', '_id': 5735}]\n",
      "RES  ← search call_rlwea5ceH7pdTrohhqqTqEiD [{'start': 9000, 'content': \"g side of\\n10:36 this which was\\n10:38 maybe the\\n10:41 when I think about it it was maybe\\n10:43 linked to the fact that I really liked\\n10:45 software programming and this was the\\n10:47 the parts that I could have the more\\n10:50 control over\\n10:51 uh maybe this is just maybe\\n10:55 liking the controlling side of it\\n10:59 but also as you mentioned you have a\\n11:01 degree in civil engineering so for you\\n11:03 all these data from sensors that was\\n11:06 coming from sensors about cracks\\n11:08 settlements and all this stuff you could\\n11:10 really make sense from this data right\\n11:12 you could make sense of this data you\\n11:14 could understand what's happening there\\n11:16 you have all you had all this the main\\n11:17 knowledge so for you maybe\\n11:21 did it actually help you with the\\n11:23 transitioning from being a data manager\\n11:25 to data engineering so what helped with\\n11:29 the transitioning was\\n11:31 been spending a lot of time on my spare\\n11:34 time learning about software engineering\\n11:36 good practices uh\\n11:40 reading about all the database\\n11:43 management and create operations and all\\n11:47 of this you know more like investing my\\n11:50 personal time on learning the data\\n11:52 engineering fields but this is true that\\n11:56 as I knew Wu was going to consume the\\n11:59 data we were producing\\n12:01 it was a big\\n12:03 big plus because I knew when something\\n12:06 was wrong I could diagnose where the the\\n12:10 data quality problem started to happen\\n12:13 or whatever you know\\n12:14 so in the end his first job as a data\\n12:19 manager transitioning into Data\\n12:20 engineering was really the perfect job\\n12:23 because it was in the civil engineering\\n12:25 industry I was reporting to civil\\n12:27 engineer construction managers uh\\n12:30 um but I got a two fits inside the data\\n12:35 space straight away\\n12:37 so\\n12:39 it was a perfect transition from my\\n12:43 degree so we are talking about the\\n12:46 condition from data manager to that\\n12:48 architect of course the other\\n12:49 engineering but the solution was\\n12:51 actually from civil engineering\\n12:53 background to the data space\\n12:56 and if you look today in the market\\n13:00 a lot of people are switching carriers\\n13:04 and usually it's they do it after a few\\n13:08 years in the work like they do I don't\\n13:10 know they work in finance for every year\\n13:12 and then they realize okay what I really\\n13:14 liked was the data whatever\\n13:16 but in my case uh just straight after my\\n13:21 diploma like the graduation I knew I\\n13:25 wanted to\\n13:26 to do something else than civil\\n13:29 engineering and it's very fun because at\\n13:31 the in the school where I was studied\\n13:33 there was always these\\n13:36 shocked about what the people in the\\n13:39 school are becoming like 10 years down\\n13:40 the road you know and there was this\\n13:42 category of 15 to 20 percent of the\\n13:45 students they do they work in a field\\n13:48 that is in no way related to what they\\n13:51 studied so I because I'm in this\\n13:54 category right now\\n13:\", 'video_id': 'qWG--iYO2uc', '_id': 5066}, {'start': 0, 'content': \"0:00 hello everyone welcome to our event this\\n0:03 event is brought to you by data talks\\n0:04 club which is a community of people who\\n0:06 love data we have weekly events this\\n0:09 event is one of such events if you want\\n0:11 to find out more about the events we\\n0:12 have there is a link in the description\\n0:15 go there click on this link and you will\\n0:16 see all the events we have in our\\n0:18 pipeline\\n0:20 and of course now you're watching this\\n0:22 on youtube please subscribe to our\\n0:24 youtube channel this way you will stay\\n0:26 up to date with all the videos all the\\n0:28 streams we have on our channel last but\\n0:30 not least we have an amazing slack\\n0:32 community if you haven't joined it yet\\n0:34 it's time to do this\\n0:36 you will get a chance to talk to other\\n0:38 data enthusiasts there\\n0:41 during today's interview you can ask any\\n0:43 question you want there is a pinned link\\n0:45 in the live chat click on this link ask\\n0:47 your question and i will be covering\\n0:49 these questions during the interview\\n0:53 so i think that's all i have\\n0:56 so now i will need to open the questions\\n1:01 okay i have the questions now\\n1:05 um\\n1:07 i think i'm ready are you\\n1:09 yeah i am\\n1:11 let's go\\n1:12 okay\\n1:13 uh this week we'll talk about\\n1:15 transitioning from data science to data\\n1:17 engineering and we have a special guest\\n1:19 today ellen ellen is the head of data\\n1:22 engineer at where is my transport which\\n1:24 is a company that provides mobility and\\n1:26 location data for emerging markets\\n1:29 she has been working in software\\n1:30 engineering data science and data\\n1:32 engineering\\n1:33 roles\\n1:34 over for over a decade\\n1:37 and a common theme across your career is\\n1:39 her passion for building high quality\\n1:41 technology of which data is a core\\n1:42 component she also enjoys teaching\\n1:45 speaking and writing about data topics\\n1:47 welcome ellen\\n1:48 thank you i'm happy to be here\\n1:51 i'm happy to have you so before we go\\n1:53 into our main topic of transitioning to\\n1:55 data engineering let's start with your\\n1:57 background can us can you tell us about\\n1:59 your career journey so far\\n2:01 of course i can so\\n2:03 um i studied computer science when i\\n2:05 yeah in uni that was my first degree and\\n2:08 i really enjoyed it\\n2:10 and i specialized in software\\n2:11 engineering and what's called in german\\n2:13 virtual informatic which translates to\\n2:15 like business applications of computer\\n2:17 science\\n2:18 and\\n2:19 then i\\n2:21 worked as a backer as a software\\n2:22 engineer for a bit\\n2:24 in different countries and then i but\\n2:27 then i got really bored with backend\\n2:29 engineering because i felt i was doing\\n2:30 this to building the same kind of\\n2:32 read data from a database show it some\\n2:35 put it into an api and get data from an\\n2:37 api and put it back into the database\\n2:39 thing for\\n2:40 over and over and\\n2:42 i at the same time i started a\\n2:43 psychology part-time degree and\\n2:46 i didn't really enjoy the psychology\\n2:48 part that muc\", 'video_id': '3TTu-hYzxeg', '_id': 615}, {'start': 7500, 'content': \"if I automated the the the the end\\n8:52 of the process\\n8:54 maybe it's going to be interesting to\\n8:56 automate the the homeless data source to\\n9:00 the consumption of the data and\\n9:03 I really enjoyed automating the the end\\n9:07 result and so\\n9:08 I was like okay\\n9:10 I could basically do this for a living\\n9:13 like automating the data processes so\\n9:16 this is how I got into uh data\\n9:19 engineering\\n9:20 so you became a data engineer within the\\n9:23 same company right yeah exactly\\n9:26 um the data management at six cents was\\n9:29 very Broad in terms of practice\\n9:33 um you could have so we would understand\\n9:35 iot devices and you had to configure all\\n9:38 the the data loggers for example to\\n9:40 reach a data from sites uh the ETL\\n9:43 process to load it into database and\\n9:46 then the reporting process as well from\\n9:49 database to the software solution we\\n9:52 were providing\\n9:53 and all of this required\\n9:56 call to maintain the full data pipeline\\n10:01 so yeah the world was very so there were\\n10:04 a lot of different aspects to the data\\n10:06 manager position it was a very broad uh\\n10:10 role but you could do most data analysts\\n10:13 a bit of data engineering and sometimes\\n10:16 when you add through those statistics on\\n10:19 your latter to understand the trends and\\n10:20 so on it was that I slashed a bit of\\n10:23 data scientists to understand what was\\n10:25 causing the trend or whatever\\n10:27 so very bold role data management and I\\n10:33 really liked the the engineering side of\\n10:36 this which was\\n10:38 maybe the\\n10:41 when I think about it it was maybe\\n10:43 linked to the fact that I really liked\\n10:45 software programming and this was the\\n10:47 the parts that I could have the more\\n10:50 control over\\n10:51 uh maybe this is just maybe\\n10:55 liking the controlling side of it\\n10:59 but also as you mentioned you have a\\n11:01 degree in civil engineering so for you\\n11:03 all these data from sensors that was\\n11:06 coming from sensors about cracks\\n11:08 settlements and all this stuff you could\\n11:10 really make sense from this data right\\n11:12 you could make sense of this data you\\n11:14 could understand what's happening there\\n11:16 you have all you had all this the main\\n11:17 knowledge so for you maybe\\n11:21 did it actually help you with the\\n11:23 transitioning from being a data manager\\n11:25 to data engineering so what helped with\\n11:29 the transitioning was\\n11:31 been spending a lot of time on my spare\\n11:34 time learning about software engineering\\n11:36 good practices uh\\n11:40 reading about all the database\\n11:43 management and create operations and all\\n11:47 of this you know more like investing my\\n11:50 personal time on learning the data\\n11:52 engineering fields but this is true that\\n11:56 as I knew Wu was going to consume the\\n11:59 data we were producing\\n12:01 it was a big\\n12:03 big plus because I knew when something\\n12:06 was wrong I could diagnose where the the\\n12:10 data quality problem started to happen\\n12:13 or whatever you know\\n12:14 \", 'video_id': 'qWG--iYO2uc', '_id': 5065}, {'start': 24000, 'content': \"ith regards to your customers needs\\n27:22 and being able to\\n27:24 derive a roadmap and strategy\\n27:27 that\\n27:28 address\\n27:30 these\\n27:33 expected and unexpected needs\\n27:36 of your customers\\n27:38 so understanding the trends\\n27:41 of these products the trends of the\\n27:43 market the trends of your customers\\n27:46 behaviors because needs change over time\\n27:49 so a product sense to me is more of a\\n27:52 mindset\\n27:54 that\\n27:55 entails different things from\\n27:57 understanding the external and internal\\n27:59 forces that drive the performance of\\n28:02 your product\\n28:04 and this is something that everyone can\\n28:06 have it's not only a thing to have for\\n28:09 product managers every\\n28:11 uh everyone on the team\\n28:14 data professional non-data professional\\n28:16 well i don't know who could be front-end\\n28:18 engineer back and engineer everyone can\\n28:20 have that right and it's uh about\\n28:24 how you said understanding\\n28:25 characteristics of your product right\\n28:28 understanding musicians yes limitations\\n28:31 and\\n28:32 we also mentioned defining road maps and\\n28:35 strategies right so this is also a part\\n28:37 of of that so how as a data professional\\n28:40 i can take part in defining roadmap\\n28:43 because i assume this is usually what a\\n28:45 product manager is doing right so how\\n28:47 can i help my product manager work on a\\n28:50 roadmap and what do i need for that\\n28:53 yeah um\\n28:55 so\\n28:56 if you're a data professional\\n28:58 um\\n28:59 you're\\n29:00 either on the busy stream other day as a\\n29:03 data analyst business analyst\\n29:05 or you're on the tech side\\n29:07 um\\n29:08 i mean even an ml engineer a data\\n29:11 engineer\\n29:13 etc\\n29:14 i think\\n29:16 uh\\n29:16 because product roadmaps are led by\\n29:20 uh product managers the best practices\\n29:23 for\\n29:24 involving all your stakeholders\\n29:27 into this because you need to understand\\n29:30 whether you will be able to deliver\\n29:33 what you promise to deliver\\n29:35 and uh that\\n29:38 especially the technical side will be\\n29:40 responsible for t-shirt sizing\\n29:43 the efforts\\n29:44 it takes to\\n29:46 you know deploy the key features\\n29:49 of your product\\n29:51 so as a data professional the\\n29:53 contribution that you can make is\\n29:56 uh\\n29:57 provide that that t-shirt t-shirt sizing\\n30:00 in terms of effort for example if a\\n30:03 feature requires\\n30:05 the build of\\n30:07 key data pipelines for example that\\n30:09 require\\n30:11 uh\\n30:12 real-time inference\\n30:14 from machine learning\\n30:16 a technical\\n30:17 a data professional on the technical\\n30:19 side is responsible for\\n30:22 uh providing advice and aligning on\\n30:25 timeline\\n30:27 uh\\n30:28 to ensure that the underlying\\n30:30 infrastructure\\n30:31 is either present or there's a strategy\\n30:34 for\\n30:34 establishing that infrastructure that\\n30:36 gives you those key pipelines\\n30:39 which in turn enable\\n30:41 these features that you want to release\\n30:42 in xyz time frame\\n30:44 so\\n30:45 when you think about it\\n30:47 it's definitely something that d\", 'video_id': 'p4wg0Vd2uD4', '_id': 4586}, {'start': 7500, 'content': \"hat\\n7:00 or at least some creators would organize\\n7:01 it was called makeover Monday so\\n7:03 somebody would give you like a data set\\n7:05 you can just copy it over and then based\\n7:07 on that you would create uh narratives\\n7:09 and create the corresponding charts it\\n7:10 was a very usual um it was a useful\\n7:12 exercise for me to just figure out how\\n7:14 would you kind of like present all this\\n7:16 information and then moving into Data\\n7:18 engineering it was also kind of like the\\n7:20 understanding that um I had a really\\n7:21 good manager at the time and she told me\\n7:24 that I think um whenever I talked\\n7:25 through about Tableau or the dashboards\\n7:28 or whatever alteric pipeline that I\\n7:29 built my eyes would always lit up so\\n7:31 that was probably when I realized that\\n7:33 my skill actually came from working on\\n7:36 the technical side of things so that's\\n7:38 why I feel that I kind of wanted to\\n7:40 Pivot my career more into the uh backend\\n7:43 side of data which is just data\\n7:44 engineering Y and it's actually one of\\n7:48 um a few common questions we had have in\\n7:51 our data engineering course um so our\\n7:55 course is designed for people who are\\n7:56 coming from the software engineering\\n7:58 background but the question we get is\\n8:00 like I'm a data analyst can I like is it\\n8:03 going to be easy for me to become a data\\n8:04 engineer and I think it's pretty a\\n8:06 pretty relevant background right yep\\n8:09 from from an analyst to become a date\\n8:12 engineer correct yep yep absolutely and\\n8:15 I will definitely uh shout out uh to\\n8:16 what you guys have have done as well\\n8:18 because I think uh through kind of like\\n8:21 my connections at my organization at\\n8:23 Home Depot uh some of the folks that was\\n8:26 working from the US told me about data\\n8:27 talks Club that's how I heard about this\\n8:29 data engineering Zoom camp and I\\n8:31 remembered I think it was such an\\n8:33 interesting approach because the first\\n8:34 thing that you guys were teaching was\\n8:36 Docker and terraform and for all of us\\n8:38 kind of like data folks it's like what\\n8:40 is this it was kind like working through\\n8:41 the command line and it it it got like\\n8:44 for us a little bit um uh what's it\\n8:46 called overwhelming because I guess most\\n8:48 data analysts work on a UI so I I think\\n8:51 I came from that um alter X background\\n8:53 you get like a low code approach but in\\n8:54 this case because you're you're you're\\n8:56 transitioning directly to a command line\\n8:58 interface there there is is kind of like\\n9:00 that uh beding in Period um but now I\\n9:03 think as a function of just getting used\\n9:05 to working in kind of like that data\\n9:07 engineering mindset yeah uh Docker or\\n9:09 terraform eventually all the languages\\n9:12 are just the same and you just figure\\n9:13 out what you need to do right and I\\n9:14 think that that's kind of like the most\\n9:15 interesting part about I guess uh\\n9:17 working in the data engineering space is\\n9:20 uh it doesn't really matter how you\\n9\", 'video_id': '7ePp6wuxM5s', '_id': 863}]\n",
      "RES  ← search call_JRcEzrYwbG0n1yXJxmnpG4Bm [{'start': 46500, 'content': \"n quickly check like tabue\\n47:00 or um basic SQL stuff and then just get\\n47:04 going on learning on your own self-\\n47:06 learning is crucial but it I feel those\\n47:10 roles still require some effort because\\n47:11 you do need to spend sometime hardcore\\n47:14 learning those Technologies but product\\n47:17 manager I think it's easier to get\\n47:20 through MH yeah and um yeah so we talked\\n47:25 about Eugene and Eugene also lives in\\n47:27 Seattle\\n47:29 yes I didn't realize that you from the\\n47:32 same city and uh yeah but it's a big\\n47:35 city right it's not like you can\\n47:36 randomly St like running to people on\\n47:38 the street yeah I mean uh I'm very close\\n47:42 to the area where all these Amazon\\n47:43 offices are so yeah every day I do look\\n47:48 some I do come across someone familiar\\n47:51 either from my undergrad Masters or just\\n47:53 from LinkedIn yeah very very active\\n47:56 people yeah\\n47:58 so another question can you please\\n48:00 highlight me mentorship networking\\n48:01 opportunities which were\\n48:04 helpful um so is this about um getting\\n48:07 those opportunities for to be a\\n48:10 mentor so I the way I interpret\\n48:13 interpret this question is you had some\\n48:16 mentorship opportunities but then some\\n48:18 of them ended being helpful for you in\\n48:23 some way oh I see uh yeah I think so\\n48:28 getting those Mentor roles is uh\\n48:31 typically just through reach outs um\\n48:34 cold emailing LinkedIn messages um stuff\\n48:38 like that uh and once you build like\\n48:40 certain rappo with these people these\\n48:42 are huge communities then it becomes a\\n48:44 word of mouth so if you have done like\\n48:47 good networking putter good um good name\\n48:50 to your work um then it becomes a word\\n48:54 of mouth and that's how you kind of\\n48:56 excel in these community-driven uh\\n48:58 programs um because cold emailing or\\n49:01 these stuff can get you into it but like\\n49:04 to build you know a good uh trustworthy\\n49:07 uh relationships or networking as we\\n49:09 call it it's mainly through Word of\\n49:11 Mouth in my opinion yeah actually so now\\n49:16 again speaking of the our conversation\\n49:19 the earlier conversation um so I\\n49:22 scrolled up and saw that we talked about\\n49:24 mentorship and the reason I asked you\\n49:26 about that is because I was doing some\\n49:28 mentorship myself back then so I was\\n49:29 interested in your perspective on these\\n49:33 things and\\n49:35 um for me what was helpful is\\n49:40 uh maybe just structuring my knowledge\\n49:43 around things so people come to you with\\n49:45 requests and then you try to help and\\n49:48 then this way when you speak when you\\n49:50 say things out loud it helps to\\n49:53 structure these things in your head and\\n49:54 then it becomes easier to use this\\n49:57 information like in other settings that\\n49:59 was the main kind of highlight for me\\n50:01 and then like when\\n50:03 people one year after that right hey\\n50:06 like thanks because of the interview\\n50:09 because of the session we did together\\n50:11 like now I work at\", 'video_id': 'ekG5zJioyFs', '_id': 2236}, {'start': 57000, 'content': \"57:21 data is a huge mess so it's a great you\\n57:24 know it's a great experience for you to\\n57:26 learn the real mess of of data and to\\n57:29 deal with it and then you mentioned that\\n57:31 in one of the hackaton you also build\\n57:34 dashboard not only like a model but also\\n57:36 a dashboard and in order to build the\\n57:38 dashboard you need to have the\\n57:39 foundation you have to you have to have\\n57:41 the data in the right form such that you\\n57:43 can present it and then this is\\n57:45 something that data Engineers usually do\\n57:47 yeah but like usually for example you\\n57:50 know when you're doing this with a with\\n57:51 with a with a with all everyone an AI\\n57:55 engineer you kind of like learn a couple\\n57:57 of skills that have nothing to do with\\n57:59 your with your title and that's actually\\n58:01 one of the things that are really cool\\n58:03 is that you get to touch up all the\\n58:05 parts that you might be that you might\\n58:08 want to explore but normally in an\\n58:10 organization they won't give you the\\n58:12 chance to touch it because you don't\\n58:14 have the\\n58:16 skills we don't have a lot of time so\\n58:18 there's one last question and you\\n58:22 mentioned when you were looking for\\n58:23 opportunities and and you still look for\\n58:26 I think yeah so I asked you how do you\\n58:28 usually find this opportunities and you\\n58:30 said social media but right now I'm\\n58:32 cutting down on that uh I'm only doing\\n58:35 it from desktop but you also mentioned\\n58:37 that you're subscribed to newsletter yes\\n58:40 where you get this opportunities from so\\n58:43 can you mention which newsletters are\\n58:46 this yeah so for example women women in\\n58:50 machine\\n58:51 learning they have like they keep every\\n58:55 they keep posting every day about\\n58:57 opportunities PhD opportun PhD students\\n59:00 opportunities uh job opportunities for\\n59:03 all for all um expertise levels so\\n59:06 please subscribe to to their Google\\n59:08 Groups uh you know mailin maining list\\n59:12 and also um neps has its own maining\\n59:15 list but neps is only active during the\\n59:18 conference days that's where usually\\n59:20 they share about opportunities and they\\n59:23 might request you to send in your CV so\\n59:25 they can send you these specific\\n59:27 opportunities apart from that there is\\n59:29 like a couple of great newsletters but\\n59:32 it's for French people for people who\\n59:34 are in in France or knows how to speak\\n59:36 French there are lots of couple of great\\n59:39 uh research newsletters there are a lot\\n59:42 of them so yeah just Google them and\\n59:45 then you will find them all over they\\n59:47 have great opportunities as well but\\n59:49 there are like couple of other\\n59:50 newsletters like for example your new\\n59:53 your newsletter as well does provide\\n59:55 sometimes about like opportunities so\\n59:58 just subscribe to the newsletters that\\n1:00:00 are AI specific and especially for for\\n1:00:03 communities like usually as communities\\n1:00:06 that share these kind of of relevant job\", 'video_id': 'aHdaIwOEI8Q', '_id': 1227}, {'start': 58500, 'content': \"ibed to newsletter yes\\n58:40 where you get this opportunities from so\\n58:43 can you mention which newsletters are\\n58:46 this yeah so for example women women in\\n58:50 machine\\n58:51 learning they have like they keep every\\n58:55 they keep posting every day about\\n58:57 opportunities PhD opportun PhD students\\n59:00 opportunities uh job opportunities for\\n59:03 all for all um expertise levels so\\n59:06 please subscribe to to their Google\\n59:08 Groups uh you know mailin maining list\\n59:12 and also um neps has its own maining\\n59:15 list but neps is only active during the\\n59:18 conference days that's where usually\\n59:20 they share about opportunities and they\\n59:23 might request you to send in your CV so\\n59:25 they can send you these specific\\n59:27 opportunities apart from that there is\\n59:29 like a couple of great newsletters but\\n59:32 it's for French people for people who\\n59:34 are in in France or knows how to speak\\n59:36 French there are lots of couple of great\\n59:39 uh research newsletters there are a lot\\n59:42 of them so yeah just Google them and\\n59:45 then you will find them all over they\\n59:47 have great opportunities as well but\\n59:49 there are like couple of other\\n59:50 newsletters like for example your new\\n59:53 your newsletter as well does provide\\n59:55 sometimes about like opportunities so\\n59:58 just subscribe to the newsletters that\\n1:00:00 are AI specific and especially for for\\n1:00:03 communities like usually as communities\\n1:00:06 that share these kind of of relevant job\\n1:00:08 offers opportunities but if it's one\\n1:00:11 person newsletter or something you know\\n1:00:13 specific they might not share about them\\n1:00:15 because that's not their interest like\\n1:00:17 they it's not what Their audience wants\\n1:00:19 from\\n1:00:21 them okay thank you Sarah welcome that\\n1:00:25 is that was nice it's really great to to\\n1:00:29 speak with you and yeah thanks for\\n1:00:31 sharing all your experience with us it\\n1:00:34 was very motivating and I'm sure you\\n1:00:37 managed to convince a few of the\\n1:00:39 listeners to actually give it a try so\\n1:00:41 thanks a lot for doing that I hope so\\n1:00:44 yeah you're welcome it's a great\\n1:00:46 pleasure and please you know like reach\\n1:00:48 out to me whenever you need\\n1:00:50 anything and then um so people were\\n1:00:53 asking for your LinkedIn I already\\n1:00:55 shared it thank you so yeah you like\\n1:00:59 connection requests\\n1:01:02 right you like connection request do you\\n1:01:05 yes did okay okay then that's all we\\n1:01:08 have time for today so thanks everyone\\n1:01:11 and uh yeah have a great rest of your\\n1:01:14 day of the week and see you soon yes\\n1:01:18 thank you thank you\", 'video_id': 'aHdaIwOEI8Q', '_id': 1228}, {'start': 34500, 'content': \"58 for it i would recommend to do\\n33:00 long-term mentorship because\\n33:03 it's difficult to understand the entire\\n33:06 context\\n33:07 and background in one conversation\\n33:10 it's always useful to you know um get to\\n33:14 know\\n33:14 each other a little bit more over time\\n33:16 and then you you\\n33:18 really get more productive with the\\n33:20 mental\\n33:21 mentoring process i guess\\n33:24 it makes more sense to find somebody in\\n33:27 your company\\n33:28 in your work workplace for this kind of\\n33:31 relationships right for a long term\\n33:33 mentorship relationship right not\\n33:36 necessarily if your\\n33:38 organization has either a formal program\\n33:41 or informally you know somebody you can\\n33:42 reach out to\\n33:43 i think that works out wonders so yeah\\n33:48 mariam is asking um how do you set\\n33:50 boundaries for long-term\\n33:52 mentorship relationships like uh of\\n33:54 course\\n33:55 uh like you as a mentor you also\\n33:58 you have other things right you cannot\\n34:00 uh spend all your time\\n34:02 helping your mentees and there are\\n34:04 perhaps other things so how do you set\\n34:06 up how do you set these boundaries\\n34:09 yeah and that's really good as i said\\n34:11 earlier right so um\\n34:12 and sometimes it's more meaningful\\n34:15 to have a paid relationship in those\\n34:18 aspects because you know\\n34:20 then both parties are more committed to\\n34:22 it and and it's easier to create those\\n34:24 boundaries and expectations\\n34:26 versus uh just a regular long-term\\n34:28 mentorship because then you don't know\\n34:30 what to expect from each other\\n34:32 um if if that was the question around\\n34:34 boundaries if i understood that question\\n34:36 correctly\\n34:36 yeah i think this is how i understood as\\n34:38 well um\\n34:40 yeah thank you and sometimes you know\\n34:42 it's also about like i have\\n34:43 i have a couple of people i mentor long\\n34:45 term and it's it's it's also about\\n34:49 telling them look it it's not meaningful\\n34:52 to have\\n34:53 a next conversation unless there is a\\n34:55 change in a situation you know\\n34:57 and and it's not just about meeting\\n34:59 every week and talking about things if\\n35:01 it's not if\\n35:02 you want to point it it starts showing\\n35:03 diminishing returns\\n35:05 so just setting those expectations also\\n35:07 clearly often helps in one question\\n35:09 like as a mentor sometimes if someone\\n35:11 reaches out for for regular mentorship i\\n35:13 say do you really want to talk to me\\n35:14 because\\n35:15 is there anything different that we\\n35:17 would talk about versus what we spoke\\n35:19 about\\n35:19 a month ago and if the answer is no then\\n35:21 maybe\\n35:22 there is a there's no point in the\\n35:24 discussion\\n35:25 it's so basically\\n35:29 being mindful uh like from both sides\\n35:32 and\\n35:32 asking hey do you really think we should\\n35:34 have this would be beneficial for\\n35:36 for you to have this uh extra session\\n35:41 okay um yeah so\\n35:45 ruslan is asking what do you think about\\n35:46 paid mentoring i think you\\n35:48 already covered that y\", 'video_id': 'LQvwTNQbPg4', '_id': 4037}, {'start': 45000, 'content': \"w can a career\\n45:27 pivoter somebody who's changing career\\n45:29 career changer changer without a\\n45:32 computer science degree or the main\\n45:34 background break into\\n45:37 Data yeah um I think uh there's lot of\\n45:42 uh okay when we talk about data there\\n45:44 are lot of data roles at least in the\\n45:46 industry that I know uh I'm in Seattle\\n45:48 it's a hub of Microsoft and um Amazon\\n45:53 lot of people here are from non uh CS\\n45:56 backgrounds couple of them in my own\\n45:58 friend Circle um all working for these\\n46:01 big Tech Giants uh in data roles so I\\n46:04 think the main thing that comes to my\\n46:06 mind if you're completely non uh Tech\\n46:09 person a pro technical product manager\\n46:12 is something that people find easier to\\n46:14 get into because uh you have this\\n46:16 business Acumen uh on your hand you have\\n46:19 these those skills and all you need to\\n46:21 do is know a little bit about how\\n46:24 software engineering works not like\\n46:26 actual coding or stuff like that but\\n46:29 just how you know SQL works or things\\n46:31 like that uh that's a very good entry\\n46:33 point technical product manager uh my\\n46:35 friend who did like civil engineering\\n46:38 did his Masters also in civil\\n46:40 engineering and then got into senior\\n46:42 Tech uh product manager in uh Amazon so\\n46:46 um yeah I think product manager is one\\n46:49 thing and then if you are uh early in\\n46:51 your career I believe like bi roles\\n46:53 that's also quick dirty uh some skills\\n46:57 uh that you can quickly check like tabue\\n47:00 or um basic SQL stuff and then just get\\n47:04 going on learning on your own self-\\n47:06 learning is crucial but it I feel those\\n47:10 roles still require some effort because\\n47:11 you do need to spend sometime hardcore\\n47:14 learning those Technologies but product\\n47:17 manager I think it's easier to get\\n47:20 through MH yeah and um yeah so we talked\\n47:25 about Eugene and Eugene also lives in\\n47:27 Seattle\\n47:29 yes I didn't realize that you from the\\n47:32 same city and uh yeah but it's a big\\n47:35 city right it's not like you can\\n47:36 randomly St like running to people on\\n47:38 the street yeah I mean uh I'm very close\\n47:42 to the area where all these Amazon\\n47:43 offices are so yeah every day I do look\\n47:48 some I do come across someone familiar\\n47:51 either from my undergrad Masters or just\\n47:53 from LinkedIn yeah very very active\\n47:56 people yeah\\n47:58 so another question can you please\\n48:00 highlight me mentorship networking\\n48:01 opportunities which were\\n48:04 helpful um so is this about um getting\\n48:07 those opportunities for to be a\\n48:10 mentor so I the way I interpret\\n48:13 interpret this question is you had some\\n48:16 mentorship opportunities but then some\\n48:18 of them ended being helpful for you in\\n48:23 some way oh I see uh yeah I think so\\n48:28 getting those Mentor roles is uh\\n48:31 typically just through reach outs um\\n48:34 cold emailing LinkedIn messages um stuff\\n48:38 like that uh and once you build like\\n48:40 certain \", 'video_id': 'ekG5zJioyFs', '_id': 2235}]\n",
      "RES  ← search call_eTeG4HivalZD0buG00WbnrGs [{'start': 10500, 'content': \" i've\\n9:37 experienced it in quite a few places\\n9:41 and uh but as a data engineer i guess as\\n9:44 a data scientist you already needed to\\n9:46 do some things that data engineers would\\n9:48 do right so you mentioned that at\\n9:50 soundcloud so you not only did modeling\\n9:54 but also everything that it was before\\n9:55 modeling like building data pipelines\\n9:58 and after modeling i guess deploying the\\n10:00 model so how does it overlap with what\\n10:04 data engineers usually do what you did\\n10:05 as a data scientist yes there's a lot of\\n10:07 overlap and\\n10:09 so there as the data scientists usually\\n10:12 are often you you don't work with\\n10:14 perfectly clean and perfectly delivered\\n10:16 data you will still build up your own\\n10:18 pipelines to make the data accessible\\n10:20 and especially if you move into more\\n10:23 production level\\n10:25 and\\n10:26 i mean the\\n10:27 data size is a very loose title and what\\n10:29 you do under this role can be very\\n10:30 different but there's often a lot of\\n10:33 pipelining work that you do on yourself\\n10:35 and i think\\n10:36 it's a good thing that data scientists\\n10:38 do that and don't just rely on data\\n10:40 engineers to kind of do handhold them\\n10:42 through these steps\\n10:45 and so there's a lot of transferable\\n10:46 skills it also depends great and also\\n10:48 data engineering is a very broad topic\\n10:51 and i never did the more kafka real-time\\n10:53 data engineering kind of stuff i've\\n10:54 carefully navigated myself around that\\n10:57 i've always done more what is now\\n10:58 considered analytics engineering maybe\\n11:01 which is more like the preparing data\\n11:03 for vi and data warehouses and\\n11:06 scheduling batch processing and all\\n11:08 these kind of things\\n11:10 so that was more my realm of data\\n11:12 engineering\\n11:13 and there's there's a this whole other\\n11:15 universe of data engineering that i've\\n11:16 never really touched and that i don't\\n11:18 feel i think where you need a better\\n11:20 understanding of distributed system and\\n11:21 things like that which i don't have\\n11:23 and so that is that's often more the\\n11:25 playground for people with a really\\n11:27 strong distributed computer science\\n11:29 background\\n11:31 and that isn't just not my round but in\\n11:33 for another for anything that's more in\\n11:35 the world of what is now analytics\\n11:36 engineering that kind of branch of data\\n11:38 engineering i think data scientists are\\n11:40 very well prepared there's obviously\\n11:42 things we need to learn but it there's a\\n11:44 lot\\n11:45 i've seen of i've often found that\\n11:47 people that come from peers of\\n11:49 engineering don't have a feeling for\\n11:50 data that they struggle more to move\\n11:52 into that space than people that come\\n11:54 that have a data science background and\\n11:56 just need to level up on\\n11:58 software engineering and collaboration\\n12:00 skills\\n12:01 what is this feeling of data in your\\n12:04 opinion what is that\\n12:06 yeah that that means understanding\\n12:08 it's a lot of things about\", 'video_id': '3TTu-hYzxeg', '_id': 622}, {'start': 46500, 'content': \"on it's for us\\n45:30 just a\\n45:31 decision to build this data governance\\n45:33 solution and\\n45:34 better understanding what kind of data\\n45:36 the process and\\n45:37 what kind of data we have inside just\\n45:39 from multiple people having multiple\\n45:41 tables and\\n45:42 no one knows what's in there\\n45:46 i assume that data scientists\\n45:49 also they produce a lot of data so their\\n45:52 models produce data\\n45:53 they also need to document the data\\n45:55 right do they use the same tool for that\\n45:58 yeah they just use the same time\\n46:01 description\\n46:02 or recommendation confluence so you have\\n46:05 the central place\\n46:06 for implementation for your data for\\n46:08 data that\\n46:10 data scientists produce and then it's\\n46:12 just once interface base\\n46:14 okay cool thanks uh we have a question\\n46:18 from ak\\n46:19 shot is\\n46:22 i think\\n46:26 so how much of data engineering should\\n46:27 one ideally know\\n46:29 i think we covered that um\\n46:32 a bit but um yeah so we talked about\\n46:36 that like how much data engineering\\n46:38 skills data scientists need to know\\n46:40 ideally um\\n46:43 but yeah we were more talking about like\\n46:45 if data scientists want to transition\\n46:47 into data engineering\\n46:48 but to be able to successfully do work\\n46:51 as data scientists\\n46:53 what kind of data engineering skills\\n46:55 they should have\\n46:58 i would say that coding skills it's also\\n47:00 important because i know that some\\n47:02 data scientists somewhere on the\\n47:03 mathematical side and they\\n47:05 more interested in building algorithms\\n47:07 than to write code\\n47:08 and it actually influences the quality\\n47:10 of the creation\\n47:12 because they you can either build just\\n47:15 everything for example in one notebook\\n47:17 and it would be hard to deploy it in\\n47:19 some way or they would build the whole\\n47:21 solution this libraries and for example\\n47:24 classes in python\\n47:25 maybe object-oriented programming so it\\n47:28 would be more like software engineering\\n47:30 way to do things\\n47:31 and the databases for sure as well\\n47:34 because they do need to read the data\\n47:36 or write some results there right\\n47:39 okay so basically uh improve your\\n47:41 software engineering skills\\n47:43 yeah yeah i think the trend i see\\n47:47 is now most data scientists in most\\n47:50 companies that\\n47:52 i see there is a requirement of being a\\n47:54 good\\n47:55 developer so maybe they don't need to be\\n47:58 as good as software engineers\\n48:00 but they need to be decent with coding\\n48:06 um yeah there is a comment about uh for\\n48:08 getting started with kubernetes there is\\n48:10 a good resource\\n48:11 called catacoda and\\n48:14 i think i saw it um i know have you seen\\n48:16 it\\n48:17 yeah i tried it once it was in the\\n48:20 beginning it's quite useful you can just\\n48:22 try out\\n48:22 different commands and see what happens\\n48:25 yeah i think\\n48:26 i saw uh one with kubernetes and one\\n48:28 with\\n48:29 i think and it's pretty cool so they\\n48:32 just\\n48:33 set up a local kubernetes for \", 'video_id': 'yg3d1lFd7Uo', '_id': 7552}, {'start': 37500, 'content': \"3 we also want to S out like if somebody\\n36:45 has to do this for another city like\\n36:47 what would be the correct way to do it\\n36:49 or like the best way to do it\\n36:52 MH as and as As I understood the project\\n36:55 you did before\\n36:57 um it had also like something geospatial\\n37:00 right and when you were looking for your\\n37:04 first freelance\\n37:06 job uh actually the the company you\\n37:09 ended up working for needed the exact\\n37:12 skills that you developed during this uh\\n37:15 this project yeah yeah that's exactly\\n37:17 what happened and maybe that will happen\\n37:20 again here I don't know maybe my next\\n37:22 fre L will be exactly like like the\\n37:25 scenario but I think that's a a really\\n37:27 good good story like you learn a skill\\n37:30 in a project hands on and I mean forena\\n37:34 there's no expectation that you would\\n37:36 work 20 hours or 15 hours it's really\\n37:38 like if you have five hours in a week\\n37:41 just like a half a day or after work for\\n37:43 two or to three days you just join a\\n37:47 project and you work with other people\\n37:48 to try to come up with a solution it's a\\n37:51 very I think it's a cool way to learn\\n37:53 new skills and a lot less overwhelming\\n37:55 if you do like with a team mhm would you\\n37:59 say that uh it typically happens that\\n38:01 the skills you pick up uh on such\\n38:03 projects they are handon Hands-On skills\\n38:06 that translate to job skills I think so\\n38:10 first I\\n38:11 think I think everybody gives the same\\n38:13 advice when it comes to data science\\n38:14 like build your portfolio do this do do\\n38:17 that there are so many ways of doing\\n38:19 that right exactly there are a lot of\\n38:21 different ways of doing that but like as\\n38:23 I grow in my here I realize that people\\n38:26 are also looking for soft skills right\\n38:28 when they hire you they just don't want\\n38:30 to somebody who's great at their job but\\n38:33 cannot work with anybody else and I\\n38:35 think when you do projects like this you\\n38:37 are forced to pick up soft skills\\n38:39 because if you have 80 people working on\\n38:42 the same project you have to communicate\\n38:44 well you have to be able to follow up\\n38:46 what's going on you have to be able to\\n38:50 access resources and figure things on\\n38:52 your own to not be overwhelmed when you\\n38:55 open Slack and there are 30 messages on\\n38:58 one single Channel and you don't know\\n38:59 where to look for I think those it's\\n39:02 also a great place to develop those\\n39:03 skills because a lot of I think a lot of\\n39:06 engineering and data science also the\\n39:08 mindset that you applied to what you're\\n39:11 doing and the like if you were alone\\n39:14 you're working alone I'm sure that you\\n39:15 are developing very hard skills and very\\n39:17 technical skills but then maybe you\\n39:19 missing out on developing a little a\\n39:21 little bit more of the mindset and also\\n39:23 when you work alone you don't\\n39:24 necessarily know uh what are the\\n39:27 kind of good relevant skills it's true\\n39:30 and wh\", 'video_id': 'GifY8Zn-pnU', '_id': 2677}, {'start': 22500, 'content': \"ll\\n26:24 of them yeah so which means that um\\n26:29 let's say somebody wants to take our\\n26:32 courses they should do some of this work\\n26:34 even before they take courses right yeah\\n26:36 yeah exactly then you have more Focus\\n26:39 from the very beginning and you know\\n26:40 okay I want to focus on data engineering\\n26:42 so I take data\\n26:44 engineering and then uh yeah just after\\n26:48 the course perhaps instead of taking the\\n26:49 other courses focus on developing the\\n26:52 skills in this area focus on doing more\\n26:54 projects in this area exactly and then\\n26:57 get interviews in that area right and\\n27:00 try to understand where you stand what\\n27:02 else is needed required to get a job\\n27:05 hopefully after finishing our course you\\n27:07 get all the skills right yeah yeah but\\n27:10 sometimes some companies might require\\n27:13 something specific right that we don't\\n27:15 cover and then this is where you can\\n27:18 understand that okay yeah and then try\\n27:20 to focus on I know building a project\\n27:23 with this particular skill yeah it's\\n27:25 it's important to not get lost in doing\\n27:28 all the courses I don't know if if\\n27:29 really all of them do all uh all the\\n27:32 courses before starting a new course\\n27:34 just take some time and okay maybe have\\n27:37 a project even if so I finish data\\n27:40 engineering I do a project I do a a\\n27:43 project and I see if I enjoy doing it\\n27:46 okay I I suppose the hypothesis is\\n27:49 something that I would like but okay I\\n27:51 finish data engineering let me practice\\n27:54 let me show that I developed skills in\\n27:57 data\\n27:59 engineering and then think about another\\n28:02 course but going from uh one course to\\n28:06 another\\n28:07 is like I don't know the wor but yeah\\n28:11 it's better to avoid it like especially\\n28:14 like that's circle like you get on the\\n28:16 train of course after course after\\n28:19 course because I feel like I still don't\\n28:20 have enough qualifications but remember\\n28:24 you have also skills you have strs you\\n28:27 have experience\\n28:29 so don't forget about\\n28:32 that and when it comes to having even\\n28:35 more Focus cuz like okay we you\\n28:38 mentioned that when it comes to data\\n28:40 science it's such a broad topic it can\\n28:43 mean anything from analysts to hardcore\\n28:47 deep learning whatever right\\n28:50 um and when you read one job description\\n28:54 for data scientist it can be super\\n28:56 different from another description of\\n28:58 data scientist and the same thing with\\n29:00 data Engineers so you can be a data\\n29:01 engineer that builds a data platform you\\n29:04 can be a data engineer that helps\\n29:06 analyst you can be a data engineer that\\n29:08 works with data scientists right so\\n29:10 there are also\\n29:14 speci and like do if I already know okay\\n29:18 I want to do data science or I want to\\n29:19 do data engineering do I already should\\n29:23 I already have even more focus and think\\n29:26 okay like I want to focus on this\\n29:28 particular type of data science job or\\n29:31 \", 'video_id': 'PchwbIs0tOg', '_id': 4621}, {'start': 3000, 'content': \"mething\\n3:03 so i became a secret developer and i\\n3:06 learned very well\\n3:08 how very well how to work with\\n3:10 databases and reports\\n3:12 so and quite quickly it turned out that\\n3:16 my strong points are analytic skills and\\n3:18 contact with clients so i continued my\\n3:22 career as a business intelligence\\n3:23 analyst\\n3:25 being responsible for the analytic parts\\n3:27 of the data warehouse construction and\\n3:30 reporting projects\\n3:32 and i also prepared some\\n3:34 user visualizations and data analysis\\n3:38 and at the same time i also became one\\n3:41 of\\n3:42 the leaders in our bi department so i\\n3:45 also developed my leadership skills\\n3:48 but\\n3:49 always i felt that we could do something\\n3:52 more with data some advanced analytics\\n3:55 my goal was to gain more insight from\\n3:58 data and one day we decided\\n4:01 to build our own data science team so\\n4:04 after\\n4:05 some time i became a data science\\n4:07 manager and i got the opportunity to\\n4:10 build my own team and take\\n4:12 responsibility for the whole area\\n4:15 and now with my team we are building\\n4:17 machine learning solutions so this is\\n4:19 very short story of my career journey\\n4:23 oh what kind of solutions you're\\n4:24 building\\n4:26 now\\n4:27 we have two main topics um\\n4:30 one is modal\\n4:32 uh\\n4:33 which should predict uh for people who\\n4:36 are uh sick\\n4:38 for bipolar disease or depression the\\n4:42 your face will change or not\\n4:45 because it's important for doctors and\\n4:48 the other solution is small commercial\\n4:51 this is uh demand forecasting and\\n4:54 recommendation so inventory optimization\\n4:58 that's quite interesting yeah thanks for\\n5:00 sharing so uh i've been following you on\\n5:03 linkedin for quite a while and uh i\\n5:06 think you post regularly like every like\\n5:08 maybe every week every two weeks\\n5:11 i see posts from you then some time ago\\n5:14 i think maybe it was six months ago like\\n5:16 it wasn't super recent uh\\n5:19 i think it goes uh like a few months ago\\n5:22 yeah so you shared the link and\\n5:25 you shared the sort of post and the post\\n5:28 started with\\n5:29 do you need\\n5:30 a data science manager or a data science\\n5:33 expert can you tell us more about this\\n5:35 post\\n5:37 yeah uh i remember this post very well\\n5:40 and this post was about differences\\n5:42 between data science manager and data\\n5:45 science expert\\n5:46 and these two positions are often\\n5:49 confused even in data science world and\\n5:52 often uh people forgot many aspects of\\n5:56 managerial tasks\\n5:58 so\\n5:59 i often got\\n6:01 job offers from various head hunters on\\n6:04 nicotine\\n6:05 and job titles were data science manager\\n6:08 or data science team leader\\n6:10 but when i analyzed requirements i could\\n6:14 see that 80 percent of them were very\\n6:17 technical for example python programming\\n6:20 machine learning solutions deployment\\n6:22 kubernetes docker\\n6:24 advanced libraries such as tensorflow\\n6:27 python etc\\n6:29 and only 20\\n6:31 of the requirements had anything to do\\n6:34 with soft skills typical \", 'video_id': 'hFmIgaN-F8Y', '_id': 2872}]\n",
      "RES  ← search call_X43dMzO9YaXAUsvqk1yplPSv [{'start': 46500, 'content': \"all companies\\n43:30 and this is part of the prep\\n43:32 um all companies will have different\\n43:34 expectations and what they're going to\\n43:35 speak to you about so\\n43:37 for me I would never prepare for\\n43:39 specific questions I would practice\\n43:41 questions in case they come up but when\\n43:44 it comes to preparation for technical\\n43:46 interviews you what we need to do is\\n43:50 really under or try to understand the\\n43:52 expectations of the individual customers\\n43:55 that we're trying to work with right or\\n43:57 the individual companies that we're\\n43:58 trying to join so the questions I mean I\\n44:02 could tell you something but they're not\\n44:03 going to be relevant for everyone else\\n44:04 right but what is relevant is\\n44:08 um\\n44:09 setting the expectations or under trying\\n44:11 to understand the expectations of the\\n44:13 clients that you're interviewing with so\\n44:15 again if you had someone on the inside\\n44:17 or a HR Talent person that you're\\n44:19 working with or a recruiter when you get\\n44:21 to a technical interview the first thing\\n44:24 that you should be asking is what are\\n44:25 the expectations of this interview you\\n44:27 should never ever in my opinion go into\\n44:30 an interview and say it's a technical\\n44:33 interview and that's all you know that\\n44:35 is blasphemy here my word\\n44:38 um\\n44:39 every single time you go into any\\n44:41 interview you should really understand\\n44:42 at least from an agenda perspective\\n44:46 the context of what you're going into\\n44:48 and speaking about right because you\\n44:50 need something to base your prep offers\\n44:54 um so yeah number one I'd always do this\\n44:56 before so let's say\\n44:59 and working with you so I am over like I\\n45:03 passed this introduction stage and now\\n45:05 you set\\n45:07 an interview a technical interview with\\n45:10 oh like somebody I don't know senior\\n45:12 data scientist\\n45:14 so what I do do I ask you or do I ask\\n45:16 that person like what are your\\n45:18 expectations in email before the\\n45:20 interview so I know what to expect\\n45:22 yeah this is what you're saying yeah so\\n45:25 let's say you got through the the intro\\n45:28 stage and that went really well look I'm\\n45:30 really Keen to continue\\n45:32 um what's the next stage and what are\\n45:33 the expectations so if we're in that\\n45:35 technical stage I should be able to give\\n45:37 you a very strong or at least some\\n45:40 pointers in terms of what they're going\\n45:41 to be looking for within that technical\\n45:43 stage right and that's the kind of\\n45:45 Baseline for your preparation what we\\n45:47 don't want to do is go really broad\\n45:49 really generic and kind of not really\\n45:51 know what goal we're shooting at and yes\\n45:54 there are some really good sites out\\n45:56 there where you can go and practice like\\n45:57 coding questions and Link code and\\n46:00 hackarack and code forces and stuff like\\n46:02 that but generally I think when we are\\n46:05 prepping for\\n46:06 an organization we want to keep it as\\n46:09 focused towards our \", 'video_id': 'NnZjlMowkWA', '_id': 4299}, {'start': 1500, 'content': \"during the interview and that's\\n1:33 all i have\\n1:37 for the introduction are you ready to\\n1:38 start yeah\\n1:40 okay so let me just\\n1:47 pull my notes\\n1:52 okay we have um today we will talk about\\n1:55 uh the difference between uh\\n1:57 big data engineers and data scientists\\n2:00 and we have special guests today\\n2:02 rexella ruxlana works as a big data\\n2:04 engineer\\n2:05 in uh captify right yeah and\\n2:09 uh yeah so today she will talk about\\n2:13 the role of a data engineer and data\\n2:14 scientist welcome\\n2:17 thank you before we go before we start\\n2:20 with our\\n2:21 main topic let's talk a bit about your\\n2:24 background\\n2:25 can you tell us a bit about your career\\n2:26 journey so far\\n2:28 yeah sure so i have a software\\n2:31 engineering degree\\n2:32 in one of the key universities it's both\\n2:35 bachelor and\\n2:36 master's degree and after that i was\\n2:38 working some time as\\n2:40 a background engineer in java mostly and\\n2:43 just at some point i\\n2:44 learned about data science big data\\n2:46 engineering and\\n2:48 i had some time to make a decision what\\n2:50 exactly i would want to do\\n2:52 and kind of back-end engineering at some\\n2:54 point just got a bit boring for me so\\n2:56 i switched into big data engineering\\n2:59 learned the\\n2:59 scala programming language and that's my\\n3:02 main programming language\\n3:04 now and um for a few years i worked at\\n3:07 a company called sql it's quite famous\\n3:10 in ukraine because it's\\n3:11 quite big company one of the top five\\n3:13 and\\n3:14 it's an outsourcing company which works\\n3:16 with clients and\\n3:18 as well as has some research so i was\\n3:21 working at the\\n3:22 r d department we had some internal\\n3:24 research stuff and\\n3:26 also i worked for some client projects\\n3:28 and\\n3:29 only two years ago i joined captify\\n3:32 which is\\n3:33 a product company they are building a\\n3:35 product in the sphere of\\n3:37 advertising and actually a company is\\n3:40 british it's based in uk\\n3:41 but it has a part of the engineering\\n3:44 team in cave\\n3:44 where i'm based and mostly working on\\n3:48 the product part specifically\\n3:50 in the big data engineering team\\n3:53 yeah i've heard that in advertising\\n3:55 there are there is so much data\\n3:57 that this data engineering big data\\n4:00 engineering becomes really important\\n4:01 because\\n4:02 these companies every day gets get\\n4:04 terabytes of data and they need to\\n4:06 effectively\\n4:07 uh process this data right yeah\\n4:10 and also what kind of makes uh the\\n4:12 solution of creptify unique\\n4:14 is data insights which are obviously\\n4:17 delivered to the help of\\n4:19 big data engineering team by having\\n4:21 different\\n4:22 sources of data and ways to transform\\n4:24 this data and deliver it to the clients\\n4:27 so what do you do at work uh what do you\\n4:29 usually do\\n4:30 as a big data engineer so my main\\n4:33 responsibility is building data\\n4:35 pipelines uh usually it's etl format\\n4:37 extract transform load so kind of\\n4:39 reading the data from some source\\n4:42 building transformations s\", 'video_id': 'yg3d1lFd7Uo', '_id': 7522}, {'start': 1500, 'content': \" right now\\n1:19 great yeah\\n1:21 so let me get\\n1:24 let me grab a copy of my book\\n1:26 okay yes of course that's even better\\n1:31 done so let me just quickly post it\\n1:37 then\\n1:38 how many live viewers do we have now\\n1:40 i don't know let me check the first time\\n1:43 posted\\n1:44 yeah yeah\\n1:45 17.\\n1:47 amazing\\n1:48 okay so now i have my notes\\n1:52 and are you ready\\n1:55 yeah let's do it yeah\\n1:58 um this week we'll talk about\\n1:59 non-technical parts of the data science\\n2:01 interview we already had an episode\\n2:04 where we talked about\\n2:05 cv like how do you prepare your cv and\\n2:08 other aspects of the interview process\\n2:10 you can go and check our website\\n2:12 we didn't talk a lot about the\\n2:15 behavioral interviews and other less\\n2:16 technical parts of the data science\\n2:19 interview which is what we\\n2:20 we are going to cover today\\n2:23 so we have a special guest today nick\\n2:26 nick started his career as software\\n2:28 engineer on facebook's growth team and\\n2:31 then he worked as safegraph started like\\n2:34 application analytics startup\\n2:36 um\\n2:37 he graduated from the university of\\n2:38 virginia with a degree in system\\n2:41 engineering\\n2:42 and uh yeah so you interned at microsoft\\n2:46 and uh at google google\\n2:49 and as we already know nick is an author\\n2:52 of a book about past async data science\\n2:55 interview i think this is the name ace\\n2:57 the data science interview we can see\\n2:59 exactly around there are like twin and\\n3:01 yeah right here and actually\\n3:04 i also have\\n3:06 yeah amazing just just left\\n3:08 amazing i mean yeah just in time for the\\n3:10 for that okay anyways welcome nick\\n3:14 thank you for having me i'm really\\n3:15 excited to be part of your community and\\n3:17 give a little talk as well as do the\\n3:18 book of the week a little bit later on\\n3:20 in the month\\n3:21 yeah thanks so before we go into our\\n3:24 main topic of icing ace in the\\n3:25 interviews specifically behavioral\\n3:27 interviews let's start with your\\n3:29 background can you tell us about your\\n3:31 career journey so far\\n3:32 yeah absolutely so i've had a pretty\\n3:34 interesting background that's all around\\n3:37 data but um in indirect ways so in\\n3:39 school i studied systems engineering\\n3:41 which is sort of a mix of like\\n3:43 operations research business math i was\\n3:46 on the data infrastructure team as an\\n3:48 intern at google i was a growth engineer\\n3:51 and did\\n3:52 data driven experimentation ran and\\n3:54 implemented many a b tests at facebook\\n3:56 and then i joined a location analytics\\n3:59 startup safe graph that sold alternative\\n4:02 data to hedge funds and retail analytics\\n4:04 companies and most recently i wrote the\\n4:06 book ace the data science interview\\n4:07 which is kind of like the cracking the\\n4:09 coding interview or the lead code\\n4:11 for data scientists machine learning\\n4:13 engineers and data analysts so that's\\n4:15 kind of my background around data\\n4:17 and when i read your\\n4:20 bio i think in a book has your biography\\n4:23 and the\", 'video_id': 'tRdLVUKU7Bo', '_id': 6397}, {'start': 4500, 'content': \"alized\\n4:14 i didn't really enjoy data science as\\n4:16 much because it was very black box it\\n4:18 fell to me because i never was felt like\\n4:20 i was feeding some model but i didn't\\n4:22 really understand what's going on which\\n4:23 is partially due to the fact that my\\n4:24 mathematics background isn't that strong\\n4:27 so i didn't never really got the theory\\n4:29 behind it\\n4:30 but also i realized i kind of miss more\\n4:32 the engineering parts of it and\\n4:34 that was also the time when data\\n4:36 engineering became more of a thing\\n4:37 because companies realized that they\\n4:38 need not just data scientists but also\\n4:40 people that actually before come before\\n4:42 them and\\n4:43 make data available for data science\\n4:45 because that's at the time was a common\\n4:47 frustration for data scientists to not\\n4:48 have data\\n4:51 great ambitions but no data\\n4:54 and then i went\\n4:56 got an offer at native instruments to be\\n4:58 one of their first data engineers\\n5:01 i did that for a while um i still had\\n5:04 the ambition back then to transition\\n5:05 back into data science but i left native\\n5:07 instruments for unrelated reasons before\\n5:10 that happened\\n5:12 then i got another job at another\\n5:13 company as a bi developer\\n5:18 my title was data scientists but really\\n5:19 what i did was\\n5:21 develop custom\\n5:23 with data visualizations\\n5:26 and i realized eventually that this was\\n5:28 kind of a dead end for me\\n5:30 and so i\\n5:32 i remembered my software engineering\\n5:34 background which i actually enjoyed\\n5:36 except it was a repetitive and then\\n5:38 at the time i was speaking to somebody\\n5:40 at thoughtworks she was the first data\\n5:42 scientist at the thoughtworks in germany\\n5:44 at the time and she told me that\\n5:46 thoughtworks was planning to expand its\\n5:48 data engineering offering and what i'd\\n5:49 be interested in\\n5:52 in becoming the solidworks germany's\\n5:54 first data engineer and help her expand\\n5:56 that offering and i thought it was\\n5:58 really exciting and\\n5:59 especially since southwark is a great\\n6:01 place for really learning good software\\n6:03 engineering practices which as a data\\n6:05 engineer is always frustrated as a data\\n6:07 scientist that always frustrated me that\\n6:09 the quality of the code and the\\n6:11 collaboration wasn't as good as i was i\\n6:13 remembered it from my back in\\n6:14 engineering days\\n6:16 and so i jumped on that and that's when\\n6:17 i finally decided to stay in data\\n6:19 engineering which i had done on and off\\n6:21 before\\n6:23 and then then yeah after that was i went\\n6:26 to where i'm now it was my transfers and\\n6:28 built up data engineering there which\\n6:29 way i'm now heading a team\\n6:32 that's quite a story and thanks for\\n6:33 sharing so uh what i also wanted to ask\\n6:36 you the next question i prepared is that\\n6:38 you were a data scientist and then you\\n6:40 switched to data engineering and i\\n6:41 wanted to ask why i think you partly\\n6:43 answered that so you said that\\n6:47 data science was a bit too black boxy\", 'video_id': '3TTu-hYzxeg', '_id': 618}, {'start': 0, 'content': \"0:01 hi everyone Welcome to our event this\\n0:03 event is brought to you by dat do club\\n0:05 which is a community of people who love\\n0:07 data we have weekly events and today is\\n0:09 one of such events if you want to find\\n0:10 out more about the events we have there\\n0:12 is a link in the description click on\\n0:14 that link and you'll see all the other\\n0:16 events we have in our pipeline um do not\\n0:19 forget to subscribe to our YouTube\\n0:20 channel this way you'll stay up to date\\n0:22 with all our future events and you'll\\n0:25 get notifications when they start and\\n0:27 last but not least don't forget to join\\n0:30 our slack Community where you can hang\\n0:33 out with other data into US during\\n0:35 today's interview you can ask any\\n0:37 question you want there is a pin Link in\\n0:39 the live chat click on that link ask\\n0:42 your questions and we will be covering\\n0:43 these questions during the\\n0:47 interview I also\\n0:50 open this on my mobile phone so I'm\\n0:54 still sharing my screen right um so then\\n0:57 uh I see if something is in the live\\n1:02 chat but yeah ad if you're ready we can\\n1:05 start\\n1:07 definitely so this week we'll talk about\\n1:10 Trends in data engineering and we have a\\n1:12 special guest today Adrian\\n1:14 Adrian is a returning guest now\\n1:18 it's third time if we just count\\n1:21 podcasts but if we count other things\\n1:23 like workshops open source demos and\\n1:26 like I don't know what\\n1:28 else people probably know you already\\n1:31 and have seen so many times so Adrian is\\n1:35 a co-founder of DT Hub and which is the\\n1:39 company behind DLT and this is one of\\n1:42 the things we will talk about today too\\n1:44 uh but in general we wanted to talk\\n1:45 about transends of data engineering\\n1:47 because this is um when we launched our\\n1:50 course recently data engineering Zoom\\n1:52 Camp uh one of the questions um there\\n1:56 from the audience from the participants\\n1:58 was\\n2:00 how do you see data engineering evolving\\n2:03 and what are the trends in data\\n2:05 engineering and I realized that I don't\\n2:09 know the answer to this question I\\n2:11 cannot really answer and I thought who\\n2:12 might have the answer and then of course\\n2:15 I thought about you Adrian so welcome to\\n2:18 our event Welcome to our podcast\\n2:19 interview it's a really great pleasure\\n2:21 to have you again here pleasure is mine\\n2:24 to join um I don't have the answers\\n2:27 either you know I just have my view of\\n2:29 what I can see and you know I can\\n2:31 speculate a little bit I can talk about\\n2:33 what I\\n2:34 observed and this is what\\n2:37 it was what makes it interesting right I\\n2:40 mean everyone has opinions uh so uh and\\n2:44 you're way closer to date engineering\\n2:46 than I am uh so we can talk about that\\n2:51 and as always the questions for today's\\n2:53 interview are prepared by johana Bayer\\n2:55 thanks Johanna for your help and before\\n2:57 we go into talking about Trends in\\n3:00 engineering maybe I know it's third time\\n3:03 you will need to do this but maybe you\\n3:04 \", 'video_id': 'AlCFKbFIEM8', '_id': 1229}]\n",
      "RES  ← search call_uifSsg3Dqdk1p34CpozmH2qV [{'start': 37500, 'content': \" to build uh you\\n38:38 know a set of best practices\\n38:40 and you need within one team what makes\\n38:43 it easier that if this all of those\\n38:46 people under one team it's easier to\\n38:48 popularize those best practices and\\n38:51 integrate and deploy those best practice\\n38:52 and what I mean by Best Practices it\\n38:54 starts with Talent Acquisitions and\\n38:57 hiring of understanding vichar what are\\n38:59 the actual roles what are the difference\\n39:02 between research scientists machine\\n39:04 learning engineer data engineer quality\\n39:07 data quality engineer and other\\n39:09 professions and really understanding\\n39:12 what the qual what what the difference\\n39:13 between those having actually job\\n39:15 descriptions for those because when you\\n39:18 start actually HR you come to HR and\\n39:19 they don't know what you know who would\\n39:22 who do we need to hire and when you hire\\n39:23 wrong people everything is wrong after\\n39:25 that it starts from you know aligning on\\n39:29 a particular set of infrastructure and\\n39:31 tools right so which Cloud are we going\\n39:34 to be using are we going to be using\\n39:36 Cloud are we going to be using on-prem\\n39:38 we can be using our own\\n39:41 deployments what kind of tools we are\\n39:43 going to be using are we going to write\\n39:44 our own experiment tracking system or\\n39:47 we're going to be using uh you know\\n39:49 other tools on the markets from weights\\n39:52 and biases Neptune call Matt and and so\\n39:54 on and so forth whatever how we're going\\n39:57 to be productizing uh and deploying\\n39:59 those models and things like that so you\\n40:02 when when you are within one team it's\\n40:04 it's a lot easier to uh and faster to\\n40:07 build those those best practices\\n40:09 and and really align the team on on\\n40:12 those best practices but the trick is to\\n40:15 centralized approach is actually it's\\n40:18 it's uh\\n40:20 how I think and I could be it's it's\\n40:22 really subjective it's not the moment\\n40:24 it's not the best way of of managing uh\\n40:27 data organizations but it's it's the the\\n40:29 step that you have to go through you\\n40:32 know on the way to to more to higher\\n40:34 maturity\\n40:35 so\\n40:36 in in the way you start with ad hoc\\n40:39 approach where you build uh you know one\\n40:41 major proof of concept you go to a\\n40:43 centralized model where you get the team\\n40:46 together and you build set of practices\\n40:48 by working on on more projects but this\\n40:52 is not the most efficient way of of\\n40:54 running data teams most in most cases\\n40:57 just because when when you have a\\n41:00 centralized team and let's say a product\\n41:03 manager comes to you and say hey we need\\n41:05 to build this let's say a recommendation\\n41:07 engine for for our website can you give\\n41:10 us you know a data scientist and so you\\n41:13 have a list of projects that you work on\\n41:16 as a centralized team and then you you\\n41:19 need to you know Market your team\\n41:21 internally so product managers or\\n41:23 engineering managers come to you and y\", 'video_id': 'XbDQv8FTA4U', '_id': 7279}, {'start': 4500, 'content': \"alized\\n4:14 i didn't really enjoy data science as\\n4:16 much because it was very black box it\\n4:18 fell to me because i never was felt like\\n4:20 i was feeding some model but i didn't\\n4:22 really understand what's going on which\\n4:23 is partially due to the fact that my\\n4:24 mathematics background isn't that strong\\n4:27 so i didn't never really got the theory\\n4:29 behind it\\n4:30 but also i realized i kind of miss more\\n4:32 the engineering parts of it and\\n4:34 that was also the time when data\\n4:36 engineering became more of a thing\\n4:37 because companies realized that they\\n4:38 need not just data scientists but also\\n4:40 people that actually before come before\\n4:42 them and\\n4:43 make data available for data science\\n4:45 because that's at the time was a common\\n4:47 frustration for data scientists to not\\n4:48 have data\\n4:51 great ambitions but no data\\n4:54 and then i went\\n4:56 got an offer at native instruments to be\\n4:58 one of their first data engineers\\n5:01 i did that for a while um i still had\\n5:04 the ambition back then to transition\\n5:05 back into data science but i left native\\n5:07 instruments for unrelated reasons before\\n5:10 that happened\\n5:12 then i got another job at another\\n5:13 company as a bi developer\\n5:18 my title was data scientists but really\\n5:19 what i did was\\n5:21 develop custom\\n5:23 with data visualizations\\n5:26 and i realized eventually that this was\\n5:28 kind of a dead end for me\\n5:30 and so i\\n5:32 i remembered my software engineering\\n5:34 background which i actually enjoyed\\n5:36 except it was a repetitive and then\\n5:38 at the time i was speaking to somebody\\n5:40 at thoughtworks she was the first data\\n5:42 scientist at the thoughtworks in germany\\n5:44 at the time and she told me that\\n5:46 thoughtworks was planning to expand its\\n5:48 data engineering offering and what i'd\\n5:49 be interested in\\n5:52 in becoming the solidworks germany's\\n5:54 first data engineer and help her expand\\n5:56 that offering and i thought it was\\n5:58 really exciting and\\n5:59 especially since southwark is a great\\n6:01 place for really learning good software\\n6:03 engineering practices which as a data\\n6:05 engineer is always frustrated as a data\\n6:07 scientist that always frustrated me that\\n6:09 the quality of the code and the\\n6:11 collaboration wasn't as good as i was i\\n6:13 remembered it from my back in\\n6:14 engineering days\\n6:16 and so i jumped on that and that's when\\n6:17 i finally decided to stay in data\\n6:19 engineering which i had done on and off\\n6:21 before\\n6:23 and then then yeah after that was i went\\n6:26 to where i'm now it was my transfers and\\n6:28 built up data engineering there which\\n6:29 way i'm now heading a team\\n6:32 that's quite a story and thanks for\\n6:33 sharing so uh what i also wanted to ask\\n6:36 you the next question i prepared is that\\n6:38 you were a data scientist and then you\\n6:40 switched to data engineering and i\\n6:41 wanted to ask why i think you partly\\n6:43 answered that so you said that\\n6:47 data science was a bit too black boxy\", 'video_id': '3TTu-hYzxeg', '_id': 618}, {'start': 1500, 'content': \"during the interview and that's\\n1:33 all i have\\n1:37 for the introduction are you ready to\\n1:38 start yeah\\n1:40 okay so let me just\\n1:47 pull my notes\\n1:52 okay we have um today we will talk about\\n1:55 uh the difference between uh\\n1:57 big data engineers and data scientists\\n2:00 and we have special guests today\\n2:02 rexella ruxlana works as a big data\\n2:04 engineer\\n2:05 in uh captify right yeah and\\n2:09 uh yeah so today she will talk about\\n2:13 the role of a data engineer and data\\n2:14 scientist welcome\\n2:17 thank you before we go before we start\\n2:20 with our\\n2:21 main topic let's talk a bit about your\\n2:24 background\\n2:25 can you tell us a bit about your career\\n2:26 journey so far\\n2:28 yeah sure so i have a software\\n2:31 engineering degree\\n2:32 in one of the key universities it's both\\n2:35 bachelor and\\n2:36 master's degree and after that i was\\n2:38 working some time as\\n2:40 a background engineer in java mostly and\\n2:43 just at some point i\\n2:44 learned about data science big data\\n2:46 engineering and\\n2:48 i had some time to make a decision what\\n2:50 exactly i would want to do\\n2:52 and kind of back-end engineering at some\\n2:54 point just got a bit boring for me so\\n2:56 i switched into big data engineering\\n2:59 learned the\\n2:59 scala programming language and that's my\\n3:02 main programming language\\n3:04 now and um for a few years i worked at\\n3:07 a company called sql it's quite famous\\n3:10 in ukraine because it's\\n3:11 quite big company one of the top five\\n3:13 and\\n3:14 it's an outsourcing company which works\\n3:16 with clients and\\n3:18 as well as has some research so i was\\n3:21 working at the\\n3:22 r d department we had some internal\\n3:24 research stuff and\\n3:26 also i worked for some client projects\\n3:28 and\\n3:29 only two years ago i joined captify\\n3:32 which is\\n3:33 a product company they are building a\\n3:35 product in the sphere of\\n3:37 advertising and actually a company is\\n3:40 british it's based in uk\\n3:41 but it has a part of the engineering\\n3:44 team in cave\\n3:44 where i'm based and mostly working on\\n3:48 the product part specifically\\n3:50 in the big data engineering team\\n3:53 yeah i've heard that in advertising\\n3:55 there are there is so much data\\n3:57 that this data engineering big data\\n4:00 engineering becomes really important\\n4:01 because\\n4:02 these companies every day gets get\\n4:04 terabytes of data and they need to\\n4:06 effectively\\n4:07 uh process this data right yeah\\n4:10 and also what kind of makes uh the\\n4:12 solution of creptify unique\\n4:14 is data insights which are obviously\\n4:17 delivered to the help of\\n4:19 big data engineering team by having\\n4:21 different\\n4:22 sources of data and ways to transform\\n4:24 this data and deliver it to the clients\\n4:27 so what do you do at work uh what do you\\n4:29 usually do\\n4:30 as a big data engineer so my main\\n4:33 responsibility is building data\\n4:35 pipelines uh usually it's etl format\\n4:37 extract transform load so kind of\\n4:39 reading the data from some source\\n4:42 building transformations s\", 'video_id': 'yg3d1lFd7Uo', '_id': 7522}, {'start': 6000, 'content': \" you know is is\\n5:47 the report refreshed did all the data\\n5:49 arrive\\n5:50 did someone make a schema change\\n5:52 somewhere that sort of messed everything\\n5:53 downstream right\\n5:54 it started this guessing game of what's\\n5:56 going on right\\n5:58 and so there's a few problems one data\\n6:00 teams are often the last to know about\\n6:02 these issues they often find out about\\n6:04 these problems from consumers of data\\n6:06 whether that is\\n6:07 executives or business units or\\n6:09 consumers or actually like users of your\\n6:11 product\\n6:12 and the second it often takes ages to\\n6:14 actually understand what the problem is\\n6:16 and identify root cause\\n6:18 our systems are so complex today that it\\n6:21 there's literally you know the ability\\n6:22 to pinpoint the root causes\\n6:23 is extremely complicated especially when\\n6:25 done in a manual way\\n6:27 um and so in seeing this problem come up\\n6:29 again and again both for myself\\n6:31 but also for data teams with other\\n6:33 organizations i was like\\n6:35 are we crazy you know am i crazy like\\n6:38 how\\n6:38 how is it that we you know are that this\\n6:41 problem exists right how can it be that\\n6:43 we don't have a better way to do this um\\n6:46 and that basically inspired uh you know\\n6:48 kind of the\\n6:49 realization that there is a better way\\n6:51 to do it and the better way to do it is\\n6:52 actually based on best practices from\\n6:54 engineering\\n6:56 and speaking about best practices so uh\\n6:58 data observability and i did a bit of\\n7:00 googling before uh before\\n7:02 our talk today so data observability is\\n7:05 based on the concept of observability\\n7:07 which is a concept from\\n7:08 the devops world right so maybe before\\n7:12 we go into data observability you can\\n7:14 tell us a bit\\n7:15 uh what it means in the devops world\\n7:17 what what is this best practice you're\\n7:19 talking about\\n7:20 yeah absolutely um i will say in general\\n7:23 in data\\n7:24 you know we um the the data space has\\n7:26 been evolving very very quickly\\n7:28 um we're still quite behind in terms of\\n7:30 sort of methodologies and frameworks\\n7:32 compared to engineering\\n7:33 um and so it is actually worthwhile\\n7:36 spending time understanding what are\\n7:37 these concepts like devops and others in\\n7:39 software engineering\\n7:40 that can help us navigate the space of\\n7:43 data and navigate what we want to\\n7:45 accomplish in a better way\\n7:46 um and so the idea of devops basically\\n7:49 has you know\\n7:50 emerging last couple of decades and as a\\n7:52 result of\\n7:54 companies that move from basically\\n7:58 basically the underlying tech stack\\n8:00 become way more complicated similarly to\\n8:02 how they are in data right\\n8:03 um for example you know for an\\n8:05 organization that's moving from a\\n8:06 monolith to a micro service architecture\\n8:08 or something that\\n8:09 you know almost every organization is\\n8:10 doing um and\\n8:12 as a result of that there has been the\\n8:14 rise of devops\\n8:15 um which is basically teams that help\\n8:18 have a constant pulse on the h\", 'video_id': 'TrMG1SOqZkQ', '_id': 6451}, {'start': 36000, 'content': \"ull full\\n37:04 cycle of uh running of collecting data\\n37:08 running experiments identifying which\\n37:10 model is the best knowing changing the\\n37:13 infrastructure and having the roles of\\n37:16 people who would work on the\\n37:17 infrastructure to be able to product uh\\n37:19 productize those models monitor those\\n37:22 models retrain those models essentially\\n37:24 having a whole end-to-end and end-to-end\\n37:27 cycle and this is where you know I would\\n37:30 say you know put the major focus on\\n37:32 having at least one project that is that\\n37:35 is successful instead of having 10\\n37:37 projects that that fail\\n37:39 because if you have 10 projects that\\n37:40 fail what actually also what happens is\\n37:42 that data science gets a bad reputation\\n37:45 and and people get actually a lot more\\n37:48 negative about uh building uh data\\n37:51 enabled products so I would here put put\\n37:55 most of my ads in one basket and running\\n37:58 and end to end and this is where you\\n38:00 switch into the next phase phase of data\\n38:04 maturity and you build a centralized\\n38:08 centralized practice that means you want\\n38:10 to\\n38:12 um now get all the all the efforts and\\n38:16 all the scientists in one organization\\n38:19 and really start building when working\\n38:22 on your photos you mean like a team\\n38:24 right right\\n38:26 and in in early stages it's good to to\\n38:29 collect all of them in one team or all\\n38:32 in one organization\\n38:33 and centralize them and what I mean by\\n38:36 that is that you need to build uh you\\n38:38 know a set of best practices\\n38:40 and you need within one team what makes\\n38:43 it easier that if this all of those\\n38:46 people under one team it's easier to\\n38:48 popularize those best practices and\\n38:51 integrate and deploy those best practice\\n38:52 and what I mean by Best Practices it\\n38:54 starts with Talent Acquisitions and\\n38:57 hiring of understanding vichar what are\\n38:59 the actual roles what are the difference\\n39:02 between research scientists machine\\n39:04 learning engineer data engineer quality\\n39:07 data quality engineer and other\\n39:09 professions and really understanding\\n39:12 what the qual what what the difference\\n39:13 between those having actually job\\n39:15 descriptions for those because when you\\n39:18 start actually HR you come to HR and\\n39:19 they don't know what you know who would\\n39:22 who do we need to hire and when you hire\\n39:23 wrong people everything is wrong after\\n39:25 that it starts from you know aligning on\\n39:29 a particular set of infrastructure and\\n39:31 tools right so which Cloud are we going\\n39:34 to be using are we going to be using\\n39:36 Cloud are we going to be using on-prem\\n39:38 we can be using our own\\n39:41 deployments what kind of tools we are\\n39:43 going to be using are we going to write\\n39:44 our own experiment tracking system or\\n39:47 we're going to be using uh you know\\n39:49 other tools on the markets from weights\\n39:52 and biases Neptune call Matt and and so\\n39:54 on and so forth whatever how we're goin\", 'video_id': 'XbDQv8FTA4U', '_id': 7278}]\n",
      "RES  ← search call_sr2t5sXOGm3J4tVZZT9wYk8a [{'start': 10500, 'content': \" i've\\n9:37 experienced it in quite a few places\\n9:41 and uh but as a data engineer i guess as\\n9:44 a data scientist you already needed to\\n9:46 do some things that data engineers would\\n9:48 do right so you mentioned that at\\n9:50 soundcloud so you not only did modeling\\n9:54 but also everything that it was before\\n9:55 modeling like building data pipelines\\n9:58 and after modeling i guess deploying the\\n10:00 model so how does it overlap with what\\n10:04 data engineers usually do what you did\\n10:05 as a data scientist yes there's a lot of\\n10:07 overlap and\\n10:09 so there as the data scientists usually\\n10:12 are often you you don't work with\\n10:14 perfectly clean and perfectly delivered\\n10:16 data you will still build up your own\\n10:18 pipelines to make the data accessible\\n10:20 and especially if you move into more\\n10:23 production level\\n10:25 and\\n10:26 i mean the\\n10:27 data size is a very loose title and what\\n10:29 you do under this role can be very\\n10:30 different but there's often a lot of\\n10:33 pipelining work that you do on yourself\\n10:35 and i think\\n10:36 it's a good thing that data scientists\\n10:38 do that and don't just rely on data\\n10:40 engineers to kind of do handhold them\\n10:42 through these steps\\n10:45 and so there's a lot of transferable\\n10:46 skills it also depends great and also\\n10:48 data engineering is a very broad topic\\n10:51 and i never did the more kafka real-time\\n10:53 data engineering kind of stuff i've\\n10:54 carefully navigated myself around that\\n10:57 i've always done more what is now\\n10:58 considered analytics engineering maybe\\n11:01 which is more like the preparing data\\n11:03 for vi and data warehouses and\\n11:06 scheduling batch processing and all\\n11:08 these kind of things\\n11:10 so that was more my realm of data\\n11:12 engineering\\n11:13 and there's there's a this whole other\\n11:15 universe of data engineering that i've\\n11:16 never really touched and that i don't\\n11:18 feel i think where you need a better\\n11:20 understanding of distributed system and\\n11:21 things like that which i don't have\\n11:23 and so that is that's often more the\\n11:25 playground for people with a really\\n11:27 strong distributed computer science\\n11:29 background\\n11:31 and that isn't just not my round but in\\n11:33 for another for anything that's more in\\n11:35 the world of what is now analytics\\n11:36 engineering that kind of branch of data\\n11:38 engineering i think data scientists are\\n11:40 very well prepared there's obviously\\n11:42 things we need to learn but it there's a\\n11:44 lot\\n11:45 i've seen of i've often found that\\n11:47 people that come from peers of\\n11:49 engineering don't have a feeling for\\n11:50 data that they struggle more to move\\n11:52 into that space than people that come\\n11:54 that have a data science background and\\n11:56 just need to level up on\\n11:58 software engineering and collaboration\\n12:00 skills\\n12:01 what is this feeling of data in your\\n12:04 opinion what is that\\n12:06 yeah that that means understanding\\n12:08 it's a lot of things about\", 'video_id': '3TTu-hYzxeg', '_id': 622}, {'start': 58500, 'content': \"rn a\\n57:26 new tool\\n57:27 yeah\\n57:28 yeah there is one question uh probably\\n57:31 last one because i see we should be\\n57:32 wrapping up\\n57:33 but this question has seven upwards so i\\n57:35 think i have to ask it so question from\\n57:38 akshay is i want to know real world\\n57:40 end-to-end process of how a data\\n57:42 engineering team design build deploy and\\n57:44 monitor with structured\\n57:47 data in both real and batch i think this\\n57:49 is too much for one minute that we have\\n57:51 left\\n57:52 maybe you can give us okay an overview\\n57:56 i think i think we should have another\\n57:57 session you know dedicated to this piece\\n57:59 right\\n58:00 which which can you know last couple of\\n58:02 hours right\\n58:04 but anyways you know just to summarize\\n58:06 this you know in in the matter of time\\n58:08 is um\\n58:09 so there are different pieces of data\\n58:12 engineering right end to end so\\n58:13 first\\n58:14 if you start with the source systems\\n58:16 where data exists right it could be\\n58:18 relational database flat files cloud s3\\n58:20 all these things and you build one data\\n58:22 pipeline to pull data from source\\n58:24 systems and load into your data\\n58:26 warehouse or data lake that is your\\n58:28 centralized data hub and then you build\\n58:30 one process to expose this data because\\n58:33 this is one first part of it you have\\n58:34 all the retain data warehouse\\n58:36 but how a consumer who is interested in\\n58:38 your data will consume it so there could\\n58:40 be various methods of con consuming the\\n58:43 data in terms of you have let's say\\n58:45 reporting tool or visualization tool\\n58:48 and you have certain apis built on on\\n58:50 top of your data warehouse platforms\\n58:52 which can serve any applications in real\\n58:54 time\\n58:55 you can have some another etl layer for\\n58:58 you know um some other consumers who are\\n59:00 interested in your data so\\n59:02 this this whole end-to-end system can be\\n59:05 in batch mode also which runs daily or\\n59:07 weekly load and second thing is it can\\n59:09 be event based also so the moment data\\n59:12 arrive in your source system you can\\n59:14 have certain events listening to that\\n59:16 source system for example let's say s3\\n59:18 bucket right your file length on s3\\n59:19 bucket\\n59:20 your lambda function get triggered i am\\n59:22 talking in terms of aws terminologies\\n59:25 and that puts your reads data from s3\\n59:27 buckets and load into your data\\n59:29 warehouse so that is more real time\\n59:31 or if you talk about streaming then you\\n59:33 have kafka or any message brokers which\\n59:36 you know can connect to real-time data\\n59:38 with your warehouse right so i would say\\n59:41 just to summarize this focus not only\\n59:44 just bringing data into data warehouse\\n59:45 but a second part which is how you\\n59:48 expose that data if nobody is able to\\n59:51 consumer data consume your data then\\n59:53 your data warehouse is not uh worthy or\\n59:55 useful at all right\\n59:58 yeah thanks a lot um\\n1:00:01 what's the best way to find you if\\n1:00:03 so\", 'video_id': 'FljnbUQ796w', '_id': 2319}, {'start': 42000, 'content': \"of Singapore releases a\\n45:30 lot of public data to like this open\\n45:33 data platforms right and sometimes you\\n45:36 need to edit this data before\\n45:40 publishing um the current data that we\\n45:43 share are data that is collected from\\n45:46 systems of course we Mass things like\\n45:50 um U cut numbers\\n45:55 MH what they actually share like and how\\n45:58 to to find this\\n45:59 information um there are two key\\n46:01 platforms one is data.gov Dog the other\\n46:05 one is called Data Mo so data.gov\\n46:08 Aggregates um information across\\n46:11 different government bodies in Singapore\\n46:13 and it ranges from things like rainfall\\n46:16 to air pollution\\n46:20 figures so there are categories like art\\n46:22 and culture education economy\\n46:24 environment geospatial housing Health\\n46:26 social trans\\n46:27 real time API so I guess I need to go to\\n46:30 transport to see your data sets right\\n46:34 yeah okay so I go to\\n46:37 transport and there is quite a lot of\\n46:40 things yes\\n46:42 like air travel geospatial data of like\\n46:47 Puffs\\n46:49 Network and um let's say somebody also\\n46:54 in January will start the next of data\\n46:57 engineering what kind of projects would\\n46:59 you recommend for them to try using\\n47:02 these data\\n47:04 sets I think one useful data set could\\n47:07 be car parking data because we collect\\n47:11 um car parking figures in I think I\\n47:14 think if I'm not wrong it's real time so\\n47:16 you get Gentry um transactions so I\\n47:20 think transaction data is quite a useful\\n47:22 and large data set for data engineering\\n47:25 projects whereby you can inest the data\\n47:27 in real time store it store it in a data\\n47:30 warehouse data Lake and then process it\\n47:32 later on for\\n47:35 analysis car\\n47:40 parking how do I find it so I just uh\\n47:44 look for car parking I don't think I can\\n47:46 find anything I think car parking is a\\n47:49 dynamic data\\n47:51 set H there there's a real time apis\\n47:55 maybe this is what I yes I'm interested\\n47:57 in okay\\n48:00 yeah and I guess I would be interested\\n48:03 in uh I cannot find maybe you can send\\n48:06 it later this is not something I can\\n48:07 just find right now yeah I can send to\\n48:09 you later another one would be real time\\n48:12 taxi data also another Dynamic data set\\n48:15 because I think the last data\\n48:16 engineering Zoom cam we were using the\\n48:19 the New York Taxi data set keep using it\\n48:22 it is an aggregated data set but I think\\n48:26 would be useful to also look at real\\n48:29 time data set and like go through the\\n48:30 process on on how to to store this\\n48:34 information so I put taxi there in the\\n48:37 search bar and then I see public\\n48:40 transport capacity monthly taxi\\n48:42 population and there's data from January\\n48:45 2005 to December uh this is not uh super\\n48:49 up to date but like it's up to December\\n48:51 2017 so there is quite a lot of data but\\n48:56 I see like there are many data sets with\\n48:59 that are constantly updated right ah you\\n49:02 sent me something yeah I just sent it\", 'video_id': 'VXQIGHUWeL0', '_id': 6845}, {'start': 1500, 'content': \"during the interview and that's\\n1:33 all i have\\n1:37 for the introduction are you ready to\\n1:38 start yeah\\n1:40 okay so let me just\\n1:47 pull my notes\\n1:52 okay we have um today we will talk about\\n1:55 uh the difference between uh\\n1:57 big data engineers and data scientists\\n2:00 and we have special guests today\\n2:02 rexella ruxlana works as a big data\\n2:04 engineer\\n2:05 in uh captify right yeah and\\n2:09 uh yeah so today she will talk about\\n2:13 the role of a data engineer and data\\n2:14 scientist welcome\\n2:17 thank you before we go before we start\\n2:20 with our\\n2:21 main topic let's talk a bit about your\\n2:24 background\\n2:25 can you tell us a bit about your career\\n2:26 journey so far\\n2:28 yeah sure so i have a software\\n2:31 engineering degree\\n2:32 in one of the key universities it's both\\n2:35 bachelor and\\n2:36 master's degree and after that i was\\n2:38 working some time as\\n2:40 a background engineer in java mostly and\\n2:43 just at some point i\\n2:44 learned about data science big data\\n2:46 engineering and\\n2:48 i had some time to make a decision what\\n2:50 exactly i would want to do\\n2:52 and kind of back-end engineering at some\\n2:54 point just got a bit boring for me so\\n2:56 i switched into big data engineering\\n2:59 learned the\\n2:59 scala programming language and that's my\\n3:02 main programming language\\n3:04 now and um for a few years i worked at\\n3:07 a company called sql it's quite famous\\n3:10 in ukraine because it's\\n3:11 quite big company one of the top five\\n3:13 and\\n3:14 it's an outsourcing company which works\\n3:16 with clients and\\n3:18 as well as has some research so i was\\n3:21 working at the\\n3:22 r d department we had some internal\\n3:24 research stuff and\\n3:26 also i worked for some client projects\\n3:28 and\\n3:29 only two years ago i joined captify\\n3:32 which is\\n3:33 a product company they are building a\\n3:35 product in the sphere of\\n3:37 advertising and actually a company is\\n3:40 british it's based in uk\\n3:41 but it has a part of the engineering\\n3:44 team in cave\\n3:44 where i'm based and mostly working on\\n3:48 the product part specifically\\n3:50 in the big data engineering team\\n3:53 yeah i've heard that in advertising\\n3:55 there are there is so much data\\n3:57 that this data engineering big data\\n4:00 engineering becomes really important\\n4:01 because\\n4:02 these companies every day gets get\\n4:04 terabytes of data and they need to\\n4:06 effectively\\n4:07 uh process this data right yeah\\n4:10 and also what kind of makes uh the\\n4:12 solution of creptify unique\\n4:14 is data insights which are obviously\\n4:17 delivered to the help of\\n4:19 big data engineering team by having\\n4:21 different\\n4:22 sources of data and ways to transform\\n4:24 this data and deliver it to the clients\\n4:27 so what do you do at work uh what do you\\n4:29 usually do\\n4:30 as a big data engineer so my main\\n4:33 responsibility is building data\\n4:35 pipelines uh usually it's etl format\\n4:37 extract transform load so kind of\\n4:39 reading the data from some source\\n4:42 building transformations s\", 'video_id': 'yg3d1lFd7Uo', '_id': 7522}, {'start': 12000, 'content': \"ways done more what is now\\n10:58 considered analytics engineering maybe\\n11:01 which is more like the preparing data\\n11:03 for vi and data warehouses and\\n11:06 scheduling batch processing and all\\n11:08 these kind of things\\n11:10 so that was more my realm of data\\n11:12 engineering\\n11:13 and there's there's a this whole other\\n11:15 universe of data engineering that i've\\n11:16 never really touched and that i don't\\n11:18 feel i think where you need a better\\n11:20 understanding of distributed system and\\n11:21 things like that which i don't have\\n11:23 and so that is that's often more the\\n11:25 playground for people with a really\\n11:27 strong distributed computer science\\n11:29 background\\n11:31 and that isn't just not my round but in\\n11:33 for another for anything that's more in\\n11:35 the world of what is now analytics\\n11:36 engineering that kind of branch of data\\n11:38 engineering i think data scientists are\\n11:40 very well prepared there's obviously\\n11:42 things we need to learn but it there's a\\n11:44 lot\\n11:45 i've seen of i've often found that\\n11:47 people that come from peers of\\n11:49 engineering don't have a feeling for\\n11:50 data that they struggle more to move\\n11:52 into that space than people that come\\n11:54 that have a data science background and\\n11:56 just need to level up on\\n11:58 software engineering and collaboration\\n12:00 skills\\n12:01 what is this feeling of data in your\\n12:04 opinion what is that\\n12:06 yeah that that means understanding\\n12:08 it's a lot of things about data so data\\n12:10 as you know i don't have to tell you is\\n12:12 very complex so it has all these how\\n12:14 it's produced all the quality the\\n12:16 statistical aspects of it understanding\\n12:18 what the data actually means how it's\\n12:20 structured how it how it evolves\\n12:23 and for a software engineer and i\\n12:25 remember that from my software\\n12:26 engineering latest often just something\\n12:27 that we don't really worry about just\\n12:29 something we type in and out but we\\n12:30 don't really worry what it is\\n12:32 some json right so some json or xml file\\n12:36 you just get it\\n12:37 you do something with this and then you\\n12:39 spit it out and then something happens\\n12:41 after that right\\n12:42 but the big part of data engineering is\\n12:44 really worrying about the quality of\\n12:45 your data that's probably the biggest\\n12:47 challenge for that data data science\\n12:49 that's something that data scientists\\n12:50 are very familiar with data quality\\n12:52 issues and how to deal with them and\\n12:55 what to do about them and\\n12:57 having these conversations around with\\n12:59 the people that collect the data produce\\n13:00 the data and all these kind of things\\n13:03 [Music]\\n13:04 but he also mentioned that you were\\n13:06 doing more work of what is called today\\n13:08 analytics engineer\\n13:10 rather than\\n13:11 uh you know kafka distributed system\\n13:14 kind of data engineer so do you think\\n13:16 this uh worrying about data quality\\n13:18 applies to all data engineers regardless\\n13:20 \", 'video_id': '3TTu-hYzxeg', '_id': 623}]\n"
     ]
    }
   ],
   "source": [
    "stage3 = await do_research(\n",
    "    stage=3,\n",
    "    stage_instructions=\"finish research\",\n",
    "    previous_stages=[stage1, stage2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0cdb397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"stage\": 3,\n",
      "  \"explored_keywords\": [\n",
      "    {\n",
      "      \"keyword\": \"advanced data engineering skills\",\n",
      "      \"relevant_references\": [\n",
      "        {\n",
      "          \"document_id\": 622,\n",
      "          \"quote\": \"...there's often a lot of pipelining work that you do on yourself.\",\n",
      "          \"timestamp\": \"10:33\",\n",
      "          \"relevance_to_keyword\": \"This snippet highlights the transferable skills and responsibilities associated with data engineering, showcasing the overlap between data science and engineering roles.\",\n",
      "          \"relevance_to_user_intent\": \"It illustrates the complexity and skills needed in data engineering, informing users about career pathways.\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": 7552,\n",
      "          \"quote\": \"I would say that coding skills...is also important...\",\n",
      "          \"timestamp\": \"47:00\",\n",
      "          \"relevance_to_keyword\": \"This indicates that coding is crucial in both data science and engineering, emphasizing the foundational skills necessary for data careers.\",\n",
      "          \"relevance_to_user_intent\": \"It underscores essential skills for advancing one's career in data fields.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"data engineering certifications\",\n",
      "      \"relevant_references\": [\n",
      "        {\n",
      "          \"document_id\": 5734,\n",
      "          \"quote\": \"we might as well get some certifications for those students\",\n",
      "          \"timestamp\": \"32:56\",\n",
      "          \"relevance_to_keyword\": \"This highlights the importance of certifications in validating skills and knowledge in data engineering, especially for emerging professionals.\",\n",
      "          \"relevance_to_user_intent\": \"It provides insights into how certifications can enhance credibility and employability in the data engineering field.\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": 618,\n",
      "          \"quote\": \"...people are looking for soft skills...\",\n",
      "          \"timestamp\": \"18:19\",\n",
      "          \"relevance_to_keyword\": \"This excerpt underlines the balance between technical skills and soft skills required in data engineering, relevant to certification discussions.\",\n",
      "          \"relevance_to_user_intent\": \"It suggests that beyond certifications, interpersonal skills are critical in a team-driven environment.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"mentorship opportunities in data engineering\",\n",
      "      \"relevant_references\": [\n",
      "        {\n",
      "          \"document_id\": 2236,\n",
      "          \"quote\": \"...getting those Mentor roles is typically just through reach outs...\",\n",
      "          \"timestamp\": \"48:30\",\n",
      "          \"relevance_to_keyword\": \"This snippet discusses networking strategies to find mentorship in data engineering, showcasing practical paths for career development.\",\n",
      "          \"relevance_to_user_intent\": \"It empowers users with actionable steps to seek guidance and advance in their careers.\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": 4058,\n",
      "          \"quote\": \"...find somebody in your company in your workplace for this kind of relationships\",\n",
      "          \"timestamp\": \"33:30\",\n",
      "          \"relevance_to_keyword\": \"This emphasizes the importance of finding local mentorship within organizations, enhancing professional growth.\",\n",
      "          \"relevance_to_user_intent\": \"It directs users toward building supportive professional networks.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"real-world applications of data engineering\",\n",
      "      \"relevant_references\": [\n",
      "        {\n",
      "          \"document_id\": 2319,\n",
      "          \"quote\": \"...it's important for doctors...to understand...\",\n",
      "          \"timestamp\": \"37:10\",\n",
      "          \"relevance_to_keyword\": \"This highlights how data engineering impacts real-world decision-making, particularly in healthcare, showing the profession's societal significance.\",\n",
      "          \"relevance_to_user_intent\": \"It illustrates the practical implications of data engineering in a critical field.\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": 6845,\n",
      "          \"quote\": \"...one useful data set could be car parking data...\",\n",
      "          \"timestamp\": \"47:07\",\n",
      "          \"relevance_to_keyword\": \"This provides a concrete example of a practical data engineering project, showcasing a relevant application in urban planning.\",\n",
      "          \"relevance_to_user_intent\": \"It gives beginners project ideas that can bridge theoretical concepts and real-world scenarios.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"transitioning from academic to professional in data engineering\",\n",
      "      \"relevant_references\": [\n",
      "        {\n",
      "          \"document_id\": 1133,\n",
      "          \"quote\": \"...become more comfortable working with your command line...\",\n",
      "          \"timestamp\": \"60:22\",\n",
      "          \"relevance_to_keyword\": \"This emphasizes the adjustment required for individuals transitioning into data engineering roles, particularly those with analytical backgrounds.\",\n",
      "          \"relevance_to_user_intent\": \"It prepares users for the practical changes they will face in the workforce.\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": 4621,\n",
      "          \"quote\": \"...you need to set up the infrastructure for building models...\",\n",
      "          \"timestamp\": \"29:36\",\n",
      "          \"relevance_to_keyword\": \"This highlights the infrastructural knowledge needed for data engineering, a crucial area for transitioning professionals.\",\n",
      "          \"relevance_to_user_intent\": \"It points to necessary skills and knowledge for newcomers aiming to enter the workforce successfully.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"keyword\": \"data engineering interview preparation\",\n",
      "      \"relevant_references\": [\n",
      "        {\n",
      "          \"document_id\": 4299,\n",
      "          \"quote\": \"...what are the expectations of the individual customers that we're trying to work with...\",\n",
      "          \"timestamp\": \"44:43\",\n",
      "          \"relevance_to_keyword\": \"This snippet discusses the importance of understanding specific interview expectations, a key factor in preparation for data engineering roles.\",\n",
      "          \"relevance_to_user_intent\": \"It helps users focus their preparation on what matters most during interviews.\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": 6351,\n",
      "          \"quote\": \"The questions... would practice questions...\",\n",
      "          \"timestamp\": \"43:57\",\n",
      "          \"relevance_to_keyword\": \"This emphasizes the importance of tailored practice and understanding the context for data interviews, which is essential for success.\",\n",
      "          \"relevance_to_user_intent\": \"It guides users on effective preparation strategies for job interviews.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"verifiable_insights\": [\n",
      "    {\n",
      "      \"insight\": \"Advanced coding and software engineering skills are crucial for success in data engineering roles, enabling professionals to build and manage complex data pipelines.\",\n",
      "      \"references\": [\n",
      "        {\n",
      "          \"document_id\": 622,\n",
      "          \"quote\": \"...there's often a lot of pipelining work that you do on yourself.\",\n",
      "          \"timestamp\": \"10:33\",\n",
      "          \"relevance_to_keyword\": \"This snippet highlights the transferable skills and responsibilities in data engineering, showcasing overlaps with data science roles.\",\n",
      "          \"relevance_to_user_intent\": \"It illustrates the complexity and skills needed in data engineering, informing users about career pathways.\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": 7552,\n",
      "          \"quote\": \"I would say that coding skills...is also important...\",\n",
      "          \"timestamp\": \"47:00\",\n",
      "          \"relevance_to_keyword\": \"This indicates that coding is crucial in both data science and engineering, emphasizing foundational skills necessary for data careers.\",\n",
      "          \"relevance_to_user_intent\": \"It underscores essential skills for advancing one's career in data fields.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"insight\": \"Certifications can validate knowledge and build credibility in data engineering, helping professionals stand out in a competitive job market.\",\n",
      "      \"references\": [\n",
      "        {\n",
      "          \"document_id\": 5734,\n",
      "          \"quote\": \"we might as well get some certifications for those students\",\n",
      "          \"timestamp\": \"32:56\",\n",
      "          \"relevance_to_keyword\": \"This highlights the importance of certifications in validating skills and knowledge in data engineering, especially for emerging professionals.\",\n",
      "          \"relevance_to_user_intent\": \"It provides insights into how certifications can enhance credibility and employability in the data engineering field.\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": 618,\n",
      "          \"quote\": \"...people are looking for soft skills...\",\n",
      "          \"timestamp\": \"18:19\",\n",
      "          \"relevance_to_keyword\": \"This excerpt underlines the balance between technical skills and soft skills required in data engineering, relevant to certification discussions.\",\n",
      "          \"relevance_to_user_intent\": \"It suggests that beyond certifications, interpersonal skills are critical in a team-driven environment.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"insight\": \"Networking and mentorship play crucial roles in career development for data engineering professionals, providing guidance and opportunities for growth.\",\n",
      "      \"references\": [\n",
      "        {\n",
      "          \"document_id\": 2236,\n",
      "          \"quote\": \"...getting those Mentor roles is typically just through reach outs...\",\n",
      "          \"timestamp\": \"48:30\",\n",
      "          \"relevance_to_keyword\": \"This snippet discusses networking strategies to find mentorship in data engineering, showcasing practical paths for career development.\",\n",
      "          \"relevance_to_user_intent\": \"It empowers users with actionable steps to seek guidance and advance in their careers.\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": 4058,\n",
      "          \"quote\": \"...find somebody in your company in your workplace for this kind of relationships\",\n",
      "          \"timestamp\": \"33:30\",\n",
      "          \"relevance_to_keyword\": \"This emphasizes the importance of finding local mentorship within organizations, enhancing professional growth.\",\n",
      "          \"relevance_to_user_intent\": \"It directs users toward building supportive professional networks.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"insight\": \"Real-world applications of data engineering significantly impact various sectors, including healthcare and urban planning, highlighting the profession's societal relevance.\",\n",
      "      \"references\": [\n",
      "        {\n",
      "          \"document_id\": 2319,\n",
      "          \"quote\": \"...it's important for doctors...to understand...\",\n",
      "          \"timestamp\": \"37:10\",\n",
      "          \"relevance_to_keyword\": \"This highlights how data engineering impacts real-world decision-making, particularly in healthcare, showing the profession's societal significance.\",\n",
      "          \"relevance_to_user_intent\": \"It illustrates the practical implications of data engineering in a critical field.\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": 6845,\n",
      "          \"quote\": \"...one useful data set could be car parking data...\",\n",
      "          \"timestamp\": \"47:07\",\n",
      "          \"relevance_to_keyword\": \"This provides a concrete example of a practical data engineering project, showcasing a relevant application in urban planning.\",\n",
      "          \"relevance_to_user_intent\": \"It gives beginners project ideas that can bridge theoretical concepts and real-world scenarios.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"insight\": \"Transitioning from academic backgrounds to professional roles in data engineering requires adaptation to industry expectations and practical skills development.\",\n",
      "      \"references\": [\n",
      "        {\n",
      "          \"document_id\": 1133,\n",
      "          \"quote\": \"...become more comfortable working with your command line...\",\n",
      "          \"timestamp\": \"60:22\",\n",
      "          \"relevance_to_keyword\": \"This emphasizes the adjustment required for individuals transitioning into data engineering roles, particularly those with analytical backgrounds.\",\n",
      "          \"relevance_to_user_intent\": \"It prepares users for the practical changes they will face in the workforce.\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": 4621,\n",
      "          \"quote\": \"...you need to set up the infrastructure for building models...\",\n",
      "          \"timestamp\": \"29:36\",\n",
      "          \"relevance_to_keyword\": \"This highlights the infrastructural knowledge needed for data engineering, a crucial area for transitioning professionals.\",\n",
      "          \"relevance_to_user_intent\": \"It points to necessary skills and knowledge for newcomers aiming to enter the workforce successfully.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"insight\": \"Effective preparation for data engineering interviews involves understanding specific company expectations and practicing relevant technical skills tailored to those needs.\",\n",
      "      \"references\": [\n",
      "        {\n",
      "          \"document_id\": 4299,\n",
      "          \"quote\": \"...what are the expectations of the individual customers that we're trying to work with...\",\n",
      "          \"timestamp\": \"44:43\",\n",
      "          \"relevance_to_keyword\": \"This snippet discusses the importance of understanding specific interview expectations, a key factor in preparation for data engineering roles.\",\n",
      "          \"relevance_to_user_intent\": \"It helps users focus their preparation on what matters most during interviews.\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": 6351,\n",
      "          \"quote\": \"The questions... would practice questions...\",\n",
      "          \"timestamp\": \"43:57\",\n",
      "          \"relevance_to_keyword\": \"This emphasizes the importance of tailored practice and understanding the context for data interviews, which is essential for success.\",\n",
      "          \"relevance_to_user_intent\": \"It guides users on effective preparation strategies for job interviews.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"stage_summary\": \"Throughout this deep dive stage on data engineering, we uncovered advanced skills and essential certifications that play a vital role in career readiness. Both mentorship and real-world applications emerged as critical components for success in this evolving field, as they inform both practical skills and career trajectories. Additionally, we highlighted the importance of targeted interview preparation to enhance job prospects. Overall, ensuring a balance between technical and soft skills alongside practical experience can greatly facilitate a successful career in data engineering.\",\n",
      "  \"recommended_next_steps\": \"In the next stage, exploration of the emerging trends in data engineering: tools and technologies, future-facing skills, and the impact of AI on data engineering processes. Additionally, consider exploring more detailed case studies on successful data engineering projects.\",\n",
      "  \"recommended_next_keywords\": [\n",
      "    \"emerging trends in data engineering\",\n",
      "    \"tools and technologies for data engineering\",\n",
      "    \"AI impact on data engineering\",\n",
      "    \"case studies on data engineering success\",\n",
      "    \"data engineering in different industries\",\n",
      "    \"career pathways in data engineering\",\n",
      "    \"soft skills for data engineers\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(stage3.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6cfba9",
   "metadata": {},
   "source": [
    "## Syntensizer/Verifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7afbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer_instructions = \"\"\"\n",
    "You are the SYNTHESIZER agent.\n",
    "\n",
    "ROLE\n",
    "You create a cohesive, factual article by synthesizing verified information from all\n",
    "three research stages (StageReports 1–3).\n",
    "\n",
    "DATA SOURCES\n",
    "- You will receive one or more `ResearchStageReport` objects, each containing\n",
    "  verifiable references with document_ids, timestamps, and quotes.\n",
    "- You have access to the tool `get_document_by_id` to retrieve full source text\n",
    "  for any reference.\n",
    "- You must use this tool to verify every claim that appears in your article.\n",
    "\n",
    "TASKS\n",
    "1. Carefully read all StageReports and extract recurring insights and verified facts.\n",
    "2. Use `get_document_by_id` to check each cited reference and confirm that\n",
    "   the quote or insight is correctly represented.\n",
    "3. Only include claims that are explicitly supported by at least one verified source.\n",
    "4. Synthesize related findings into 5–6 cohesive sections with a logical flow.\n",
    "5. Ensure that the article aligns with the original user intent (as passed from the clarifier).\n",
    "\n",
    "ARTICLE STRUCTURE\n",
    "- Introduction: Summarize what the article will explore and why it matters.\n",
    "- 5-6 body sections, each:\n",
    "  - Centered on one major theme or subtopic.\n",
    "  - Contains 3–4 related claims (each 3–4 sentences long).\n",
    "  - Each claim includes an in-text reference\n",
    "- Conclusion: Summarize the most important insights and actionable takeaways.\n",
    "\n",
    "VERIFICATION RULES\n",
    "- For every claim, retrieve at least one cited source using `get_document_by_id`\n",
    "  and confirm that the text supports the claim.\n",
    "- If a reference cannot be verified or is inconsistent, omit it.\n",
    "- Do not invent or infer facts beyond what’s supported by verified material.\n",
    "\n",
    "STYLE\n",
    "- Maintain factual, neutral, and coherent tone.\n",
    "- Avoid speculation, exaggeration, or unsupported synthesis.\n",
    "- Write in clear prose suitable for an informed but general audience.\n",
    "\n",
    "OUTPUT\n",
    "- A single, well-structured factual article ready for presentation.\n",
    "- All references cited\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e82c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reference(BaseModel):\n",
    "    \"\"\"Citations that directly tie each claim to a verifiable source.\"\"\"\n",
    "    quote: str = Field(..., description=\"A short, verbatim quote (2–4 sentences) from the database snippet.\")\n",
    "    youtube_id: str = Field(..., description=\"Video ID\")\n",
    "    timestamp: str = Field(..., description=\"Timestamp to the exact position in the video where the quote is, 'h:mm:ss' or 'mm:ss' format.\")\n",
    "\n",
    "class Keyword(BaseModel):\n",
    "    \"\"\"Research results for a specific keyword\"\"\"\n",
    "    search_keyword: str = Field(..., description=\"Exact keyword used for search.\")\n",
    "    summary: str = Field(..., description=\"Short summary of the search result.\")\n",
    "    references: List[Reference] = Field(..., description=\"Specific references to help us track the findings of the research.\")\n",
    "    relevance_summary: str = Field(..., description=\"1 sentence for each reference explainig how it supports the keyword's summary — ensure factual consistency.\")\n",
    "    other_ideas: str = Field(..., description=\"Free-form description of related or complimentary ideas to explore in next stages.\")\n",
    "\n",
    "class StageReport(BaseModel):\n",
    "    \"\"\"Summarizes what was found during a single exploration stage.\"\"\"\n",
    "    stage: int = Field(..., description=\"Stage number (1 for initial search, 2 for expansion, 3 for deep dive).\")\n",
    "    keywords: List[Keyword] = Field(..., description=\"Search keywords \")\n",
    "    summary: str = Field(..., description=\"A concise synthesis of insights found in this stage, summarizing themes and discoveries from all queries executed in the stage.\")\n",
    "\n",
    "class Claim(BaseModel):\n",
    "    \"\"\"A factual statement supported by one specific reference.\"\"\"\n",
    "    description: str = Field(..., description=(\n",
    "        \"A short paragraph (3–4 sentences) that paraphrases the meaning of the quote in your own words. \"\n",
    "        \"It must stay faithful to the factual content of the quote — no speculation or extrapolation.\"\n",
    "    ))\n",
    "    relevance_check: str = Field(..., description=(\n",
    "        \"1–2 sentences explaining *why* this quote supports the claim — a brief justification to ensure factual grounding.\"\n",
    "    ))\n",
    "    reference: Reference = Field(..., description=(\n",
    "        \"A direct quote that explicitly supports or demonstrates the statement made in 'description'. \"\n",
    "        \"The claim should be a paraphrase or interpretation of this quote.\"\n",
    "    ))\n",
    "\n",
    "class ArticleSection(BaseModel):\n",
    "    \"\"\"One thematic part of the final article, containing multiple claims.\"\"\"\n",
    "    title: str = Field(..., description=\"A concise section title summarizing the theme.\")\n",
    "    claims: List[Claim] = Field(..., description=\"3–4 claims that explore different aspects of this section's theme.\")\n",
    "\n",
    "class ActionPoint(BaseModel):\n",
    "    \"\"\"Practical takeaways from the research.\"\"\"\n",
    "    point: str = Field(..., description=\"A concrete recommendation, insight, or action derived from the research.\")\n",
    "    relevance_check: str = Field(..., description=\"Explain how the referenced quote supports this action point — must show logical connection, not assumption.\")\n",
    "    reference: Reference = Field(..., description=\"Source supporting this action point.\")\n",
    "\n",
    "class Article(BaseModel):\n",
    "    \"\"\"The final synthesized output — a structured article summarizing all research stages.\"\"\"\n",
    "    title: str = Field(..., description=\"Compelling headline summarizing the topic and main insight (7-10 words).\")\n",
    "    introduction: str = Field(..., description=\"A short overview (3-4 paragraphs) explaining what the research explored and why it matters.\")\n",
    "    sections: List[ArticleSection] = Field(..., description=\"5-8 well-structured sections presenting grouped claims by topic.\")\n",
    "    action_points: List[ActionPoint] = Field(..., description=\"Optional 3-5 key insights or recommendations derived from the findings.\")\n",
    "    conclusion: str = Field(..., description=\"Final synthesis paragraph summarizing the broader takeaways and closing thoughts.\")\n",
    "\n",
    "class ResearchReport(BaseModel):\n",
    "    \"\"\"The complete record of exploration across all stages, culminating in the final article.\"\"\"\n",
    "    stages: List[StageReport] = Field(..., description=\"Exploration stage reports (Stage 1–3) detailing the search process.\")\n",
    "    article: Article = Field(..., description=\"The final article.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae642c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer = Agent(\n",
    "    name='synthesizer',\n",
    "    instructions=synthesizer_instructions,\n",
    "    tools=[tools.get_document_by_id],\n",
    "    model='gpt-4o-mini',\n",
    ")\n",
    "\n",
    "synthesizer_callback = NamedCallback(synthesizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "22e7da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reports = [stage1, stage2, stage3]\n",
    "reports = '\\n'.join([r.model_dump_json() for r in all_reports])\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "initial request:\n",
    "{research_task.model_dump_json()}\n",
    "\n",
    "reports:\n",
    "{reports}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b30bd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALL → get_document_by_id {'_id': 2965} call_eDMJUMmGpCttZsElaWqiDHzz\n",
      "CALL → get_document_by_id {'_id': 7527} call_5SN4lICntMMSohGJWqAfi2d9\n",
      "CALL → get_document_by_id {'_id': 643} call_sijVIK91Plt6PweED2mexCFG\n",
      "CALL → get_document_by_id {'_id': 2283} call_rrSpubjmiMXexGSaQUuvABlG\n",
      "CALL → get_document_by_id {'_id': 618} call_A66AHUz1BJwW8mcBDeu8Lj0K\n",
      "CALL → get_document_by_id {'_id': 6845} call_i03SBAesZXGqM2CJ82ijbvvw\n",
      "CALL → get_document_by_id {'_id': 2284} call_n03zLzriQakwLBFfYOr8dFql\n",
      "CALL → get_document_by_id {'_id': 622} call_CT9XwKxJyuIfVbTMSV54ubuZ\n",
      "CALL → get_document_by_id {'_id': 7552} call_sP1PvZhRitAkOjbHtGad0MuA\n",
      "CALL → get_document_by_id {'_id': 5734} call_IJzdEgtrDXOCcRwjCAIU2QFh\n",
      "CALL → get_document_by_id {'_id': 618} call_UKG3HlRB4YsqMKERjxT2dglh\n",
      "CALL → get_document_by_id {'_id': 2236} call_KzPtke0I8kDR1K4VxExAkZYG\n",
      "CALL → get_document_by_id {'_id': 4058} call_mhncjgdBkydyB3REX73xfYgL\n",
      "CALL → get_document_by_id {'_id': 2319} call_vtzIgnE7sRQuiwfWfWyaVWWz\n",
      "CALL → get_document_by_id {'_id': 6845} call_UwnKYeYRBFi8j9pocgX7tzBx\n",
      "CALL → get_document_by_id {'_id': 1133} call_pEJI4Hj3wgCbm6xye77dLpIu\n",
      "CALL → get_document_by_id {'_id': 4621} call_Ia6e2pR4wdnXoce1dkSqLyBY\n",
      "CALL → get_document_by_id {'_id': 4299} call_o6VVXq3dE7XgIuCDlrPQMRfI\n",
      "CALL → get_document_by_id {'_id': 6351} call_YYLfOkI9z9gdLjGGShsr9DaK\n",
      "RES  ← get_document_by_id call_pEJI4Hj3wgCbm6xye77dLpIu {'start': 39000, 'content': \"y\\n39:32 have a couple of years of experience if\\n39:34 it junior yet then definitely that's\\n39:36 that's the best way to\\n39:38 dive into the cold water\\n39:40 uh you don't have i would say other\\n39:44 let's say hard commitments on different\\n39:46 things so you can really spend a lot of\\n39:49 time\\n39:50 on your work at least for the first\\n39:51 years to just uh ramp up\\n39:54 um and yeah i've seen like\\n39:57 people\\n39:58 growing super super fast in scale up in\\n40:01 in a lot of scale up i think in that\\n40:03 company also there has like two\\n40:05 promotion around per year right\\n40:08 and i've seen some unique talent okay\\n40:10 this is like really unique and that's\\n40:12 happening like something\\n40:14 don't get mad don't get me wrong but\\n40:15 like being promoted two times a year\\n40:18 it's just because there we are\\n40:19 delivering so much\\n40:21 um again everybody is different\\n40:23 everybody has a live context which is\\n40:26 different but the point is you have the\\n40:27 opportunity right in a classic company\\n40:29 that that would never happen that would\\n40:31 never happen because you won't have the\\n40:32 opportunity it's not about the promotion\\n40:35 around it's also about having the\\n40:36 projects right to basically show off\\n40:39 right and i think in one year you know\\n40:42 in a certain scale up when you see their\\n40:44 products you know before and after the\\n40:46 year a lot of things could happen right\\n40:48 so yeah why not\\n40:51 yeah another question we have i am\\n40:53 leading a data team in a hyper growth\\n40:55 scaling up company in lion fronts how do\\n40:58 you guys source big data engineers i\\n41:00 guess these questions how where do we\\n41:02 find talent how do we find data\\n41:04 engineers\\n41:06 we don't find them there is not enough\\n41:08 of them\\n41:09 [Laughter]\\n41:11 so you will not not answer this question\\n41:13 no no no no no\\n41:17 no no i think um\\n41:19 there is something\\n41:21 that definitely helped and that the\\n41:23 scaleup need to work\\n41:25 on uh easily to start to work on is the\\n41:28 engineering culture\\n41:30 so a good example of establish tech\\n41:32 company like airbnb\\n41:35 for example a lot of engineers know them\\n41:39 of course because of the service but\\n41:41 they know them on the engineering parts\\n41:42 because they have so much operations\\n41:44 project they have an insane blog right\\n41:47 they speak at conference\\n41:49 uh so so yeah you know them because of\\n41:52 what they do on the engineering side um\\n41:55 and uh i think a scale scale up need to\\n41:58 invest into those things into\\n41:59 contributing back to the community to\\n42:01 show this is our engineering environment\\n42:04 and i feel that's the best way to\\n42:06 attract talents like\\n42:08 engineering in general they're mostly in\\n42:11 uh i mean attracted by injuring problems\\n42:14 so uh if they see there is like you know\\n42:17 brian mike said in that open source\\n42:19 project from that company\\n42:22 um yeah when they are passion they\\n42:24 passionate they they they actua\", 'video_id': 'acJ6sVqKOUk'}\n",
      "RES  ← get_document_by_id call_IJzdEgtrDXOCcRwjCAIU2QFh {'start': 12000, 'content': \" it's not not for\\n12:06 profit allows just a different\\n12:09 more flexibility more\\n12:12 um\\n12:13 more freedom in the curriculum more tips\\n12:16 more stories from my own experience when\\n12:19 somebody needs extra help\\n12:22 um and the summer I was all uh designed\\n12:25 a curriculum together with a couple of\\n12:26 people at AI Guild and\\n12:29 um what fraud fraud detection and\\n12:31 chargeback as well\\n12:34 fancy class it's actually one of the\\n12:37 questions I uh I have about that so in\\n12:42 your LinkedIn\\n12:43 um you have this experience with AI\\n12:45 Guild that you mentioned and the title\\n12:48 that you have for this for this job is\\n12:51 program manager so responsibilities\\n12:53 according to your profile is designing\\n12:55 the fintech data science curriculum\\n12:57 collecting market Standard practices\\n13:00 data sets and exercises per topic and\\n13:03 finding teachers so yeah I was I got\\n13:05 really curious because we also in data\\n13:07 talks Club also do courses\\n13:10 and yeah this is something I I also need\\n13:13 to do often so I really wanted to ask\\n13:16 you more about this uh and uh I I'll\\n13:20 write my employer was the idea that that\\n13:22 Daniel and Chris I don't know it's a\\n13:24 small community we know each other\\n13:27 um yeah it was\\n13:30 I mean first I was I think I was asked\\n13:32 to be a teacher and I I said I had a lot\\n13:34 of ideas about the the program itself\\n13:36 and how one can update a little bit the\\n13:39 curriculum to make it a bit more modern\\n13:42 and that's all I got to work together\\n13:44 with Daniel on this and then um I got\\n13:47 inspired that maybe we should have some\\n13:49 Google certification or Cloud\\n13:51 certifications if we work in bigquery\\n13:53 and do anything data related we might as\\n13:56 well get some certifications for those\\n13:58 students so you know putting my\\n14:00 connections at Google and got them\\n14:02 access to this um there is a learning\\n14:04 platform that if you are a Google\\n14:05 customer you can have access to it\\n14:08 so now on top of everything the students\\n14:11 also get certification so I think that's\\n14:13 pretty unique\\n14:15 um in in that sense\\n14:16 and\\n14:18 you know what what other questions would\\n14:20 you have around yeah the question was uh\\n14:22 yeah you actually didn't answer that yet\\n14:25 um\\n14:25 so you said you be asked you AI Guild\\n14:29 asked you to join them as a teacher but\\n14:31 you were more interested in uh\\n14:35 you did both okay\\n14:38 and I'm I'm really curious um like what\\n14:41 does it mean what does it mean to design\\n14:44 a curriculum what what did you do there\\n14:46 exactly so this I didn't alone it was\\n14:50 also done yeah right credit credit is\\n14:52 due so you plural I guess\\n14:55 happy\\n14:56 um we we first of all we I well here I I\\n15:01 was interviewing Financial techies so\\n15:04 managers of data in fintech companies or\\n15:09 in fintech departments or in fraud\\n15:11 departments what kind of methodologies\\n15:13 they have implemented in their\\n15:16 um in t\", 'video_id': 'saaRRzgHsmE'}\n",
      "RES  ← get_document_by_id call_sijVIK91Plt6PweED2mexCFG {'start': 42000, 'content': \":23 yeah sharing\\n37:24 it mainly just boiled down to sharing my\\n37:27 thoughts and asking when to ask for help\\n37:28 asking when to offer help and all these\\n37:31 kind of small things that i wasn't used\\n37:33 to working mostly by myself before\\n37:36 so really how to work very closely with\\n37:39 people on a day to day level\\n37:40 keeping them in the loop\\n37:43 knowing when to figure out when i need\\n37:44 to get myself into the loop and all\\n37:46 these kind of questions\\n37:49 so you would say that that engineering\\n37:50 is more\\n37:51 of a team sport than data science\\n37:53 exactly exactly and engineering in\\n37:55 general i guess right because usually\\n37:57 you have a lot more engineers than data\\n37:59 scientists\\n38:00 so maybe for a team you\\n38:03 maybe you have one data scientist and\\n38:04 then a bunch of back-end engineers right\\n38:07 exactly exactly and you use it yeah and\\n38:10 you usually have\\n38:12 also more data engineers than data\\n38:13 scientists and so there's a whole\\n38:16 different approach to working together\\n38:19 in your experience\\n38:21 do data engineers usually work like in\\n38:24 one team so maybe there is one platform\\n38:26 or data engineering team or they\\n38:29 are spread across different teams\\n38:32 i've seen both i prefer the model where\\n38:34 they're not where there's not a data\\n38:36 engineering platform team i think unless\\n38:38 you have a really large company where\\n38:40 you where you really need a data\\n38:41 platform infrastructure and you need\\n38:43 people dedicated to that i think in in\\n38:45 the smaller companies i've usually\\n38:46 worked with i\\n38:48 i think it works better if the data\\n38:49 engineers are embedded with the other\\n38:51 either with the other data faults or\\n38:52 also is part of the date of a wider\\n38:55 platform team\\n38:56 but for what i've usually worked with is\\n38:58 just kind of embedded into the more\\n39:00 general data teams\\n39:02 that are consisting of analysts and data\\n39:04 engineers and data scientists and maybe\\n39:07 ml engineers and all sorts of data\\n39:09 specialists\\n39:11 and in this setup you usually see more\\n39:14 engineers than data scientists right\\n39:16 more than just yes usually but\\n39:20 there can also be a lot of\\n39:21 a lot of analysts for example that it's\\n39:23 common that's common to see so it\\n39:26 depends on the setup\\n39:29 okay now there is a question\\n39:31 so do you know if there is a name for\\n39:33 the role for people who are both data\\n39:36 engineers and data scientists\\n39:39 is such a thing does such a thing exist\\n39:42 at all\\n39:43 um\\n39:44 [Music]\\n39:46 i have not encountered it as such but i\\n39:48 think the closest i've seen is really\\n39:50 analytics engineer this this particular\\n39:53 and it\\n39:54 again it depends on what you consider\\n39:56 data scientists being a data engineer\\n39:58 because the overlap might be all sorts\\n39:59 of things it could also be\\n40:01 it could if it goes to the end it could\\n40:04 also be an mlops engineer for example\\n40:06 that could also be an\", 'video_id': '3TTu-hYzxeg'}\n",
      "RES  ← get_document_by_id call_mhncjgdBkydyB3REX73xfYgL {'start': 6000, 'content': \"balancing between you know my\\n6:07 academic work as well as kind of the\\n6:09 startup world and how things worked\\n6:12 there got fascinated with startups\\n6:14 finished my PhD joined another startup\\n6:18 um where I'm currently you know building\\n6:20 the HR Tech solution that you\\n6:23 mentioned um and yeah um this is where\\n6:26 I'm at\\n6:28 today yeah well must be not easy to\\n6:33 simultaneously um start in a startup and\\n6:37 then U doing your PhD\\n6:39 right no yeah it was not easy but uh it\\n6:43 was a lot of fun actually because it was\\n6:45 a nice balance because during the PHD\\n6:48 you know PhD is very intense and you get\\n6:49 to do a lot of work I mean for those who\\n6:52 have been in a similar Journey you get\\n6:54 to do a lot of very intense work and\\n6:55 mostly to some extent\\n6:58 Alone um and I balanced that out with\\n7:01 you know the excitement of working with\\n7:02 a team and training people and you know\\n7:06 um kind of that Community aspect because\\n7:08 everything that we also did in that um\\n7:11 company was very much community-driven\\n7:13 so it was kind of like a balancing act\\n7:16 as long as you're enjoying what you're\\n7:17 doing really you end up managing somehow\\n7:20 I\\n7:21 guess yeah so what did you so you said\\n7:25 that your research was you you had your\\n7:28 first course ai ai last year of your\\n7:31 Bachelor studies you really liked it and\\n7:33 you enrolled in the master program you\\n7:36 also liked it so then you continued\\n7:38 researching it during your PhD and your\\n7:41 research was about transfer learning\\n7:44 in with limited data right can you tell\\n7:48 us a bit more what did you yeah yeah\\n7:50 sure um so I mean that was a very long\\n7:54 time ago but I hope I can remember like\\n7:56 how things came together so during my\\n7:58 masters I mean my adviser was already\\n8:00 working on certain areas and he was\\n8:02 specifically focused on um natural\\n8:05 language processing and context aware\\n8:07 sensing and back then NLP was still not\\n8:10 the hype that it is today um so it was\\n8:13 more of basic uh or more foundational\\n8:15 NLP stuff I would say not basic but more\\n8:18 foundational um I was fascinated with\\n8:20 the context OFW sensing because the\\n8:22 applications that he was working on were\\n8:24 very much um touching people's lives and\\n8:27 for me like context over sensing you\\n8:30 said context aware sensing so something\\n8:33 like context aware sensing yeah yeah\\n8:35 like wearable devices for like um human\\n8:38 activity recognition emotion\\n8:41 recognition um sensing human behavior\\n8:44 and environments stuff like that right\\n8:46 so he was working on a variety of these\\n8:48 things um so I start of started kind of\\n8:51 looking down this direction I didn't end\\n8:53 up you know down that path but along the\\n8:56 way I came across the idea of um\\n8:59 transfer learning and multitask learning\\n9:02 and this concept of um getting models to\\n9:05 learn from each other again you know I\\n9:08 was starting in the field back then so\\n9:09 for me driven by\", 'video_id': 'm45tNY-8gY8'}\n",
      "RES  ← get_document_by_id call_vtzIgnE7sRQuiwfWfWyaVWWz {'start': 58500, 'content': \"rn a\\n57:26 new tool\\n57:27 yeah\\n57:28 yeah there is one question uh probably\\n57:31 last one because i see we should be\\n57:32 wrapping up\\n57:33 but this question has seven upwards so i\\n57:35 think i have to ask it so question from\\n57:38 akshay is i want to know real world\\n57:40 end-to-end process of how a data\\n57:42 engineering team design build deploy and\\n57:44 monitor with structured\\n57:47 data in both real and batch i think this\\n57:49 is too much for one minute that we have\\n57:51 left\\n57:52 maybe you can give us okay an overview\\n57:56 i think i think we should have another\\n57:57 session you know dedicated to this piece\\n57:59 right\\n58:00 which which can you know last couple of\\n58:02 hours right\\n58:04 but anyways you know just to summarize\\n58:06 this you know in in the matter of time\\n58:08 is um\\n58:09 so there are different pieces of data\\n58:12 engineering right end to end so\\n58:13 first\\n58:14 if you start with the source systems\\n58:16 where data exists right it could be\\n58:18 relational database flat files cloud s3\\n58:20 all these things and you build one data\\n58:22 pipeline to pull data from source\\n58:24 systems and load into your data\\n58:26 warehouse or data lake that is your\\n58:28 centralized data hub and then you build\\n58:30 one process to expose this data because\\n58:33 this is one first part of it you have\\n58:34 all the retain data warehouse\\n58:36 but how a consumer who is interested in\\n58:38 your data will consume it so there could\\n58:40 be various methods of con consuming the\\n58:43 data in terms of you have let's say\\n58:45 reporting tool or visualization tool\\n58:48 and you have certain apis built on on\\n58:50 top of your data warehouse platforms\\n58:52 which can serve any applications in real\\n58:54 time\\n58:55 you can have some another etl layer for\\n58:58 you know um some other consumers who are\\n59:00 interested in your data so\\n59:02 this this whole end-to-end system can be\\n59:05 in batch mode also which runs daily or\\n59:07 weekly load and second thing is it can\\n59:09 be event based also so the moment data\\n59:12 arrive in your source system you can\\n59:14 have certain events listening to that\\n59:16 source system for example let's say s3\\n59:18 bucket right your file length on s3\\n59:19 bucket\\n59:20 your lambda function get triggered i am\\n59:22 talking in terms of aws terminologies\\n59:25 and that puts your reads data from s3\\n59:27 buckets and load into your data\\n59:29 warehouse so that is more real time\\n59:31 or if you talk about streaming then you\\n59:33 have kafka or any message brokers which\\n59:36 you know can connect to real-time data\\n59:38 with your warehouse right so i would say\\n59:41 just to summarize this focus not only\\n59:44 just bringing data into data warehouse\\n59:45 but a second part which is how you\\n59:48 expose that data if nobody is able to\\n59:51 consumer data consume your data then\\n59:53 your data warehouse is not uh worthy or\\n59:55 useful at all right\\n59:58 yeah thanks a lot um\\n1:00:01 what's the best way to find you if\\n1:00:03 so\", 'video_id': 'FljnbUQ796w'}\n",
      "RES  ← get_document_by_id call_UKG3HlRB4YsqMKERjxT2dglh {'start': 4500, 'content': \"alized\\n4:14 i didn't really enjoy data science as\\n4:16 much because it was very black box it\\n4:18 fell to me because i never was felt like\\n4:20 i was feeding some model but i didn't\\n4:22 really understand what's going on which\\n4:23 is partially due to the fact that my\\n4:24 mathematics background isn't that strong\\n4:27 so i didn't never really got the theory\\n4:29 behind it\\n4:30 but also i realized i kind of miss more\\n4:32 the engineering parts of it and\\n4:34 that was also the time when data\\n4:36 engineering became more of a thing\\n4:37 because companies realized that they\\n4:38 need not just data scientists but also\\n4:40 people that actually before come before\\n4:42 them and\\n4:43 make data available for data science\\n4:45 because that's at the time was a common\\n4:47 frustration for data scientists to not\\n4:48 have data\\n4:51 great ambitions but no data\\n4:54 and then i went\\n4:56 got an offer at native instruments to be\\n4:58 one of their first data engineers\\n5:01 i did that for a while um i still had\\n5:04 the ambition back then to transition\\n5:05 back into data science but i left native\\n5:07 instruments for unrelated reasons before\\n5:10 that happened\\n5:12 then i got another job at another\\n5:13 company as a bi developer\\n5:18 my title was data scientists but really\\n5:19 what i did was\\n5:21 develop custom\\n5:23 with data visualizations\\n5:26 and i realized eventually that this was\\n5:28 kind of a dead end for me\\n5:30 and so i\\n5:32 i remembered my software engineering\\n5:34 background which i actually enjoyed\\n5:36 except it was a repetitive and then\\n5:38 at the time i was speaking to somebody\\n5:40 at thoughtworks she was the first data\\n5:42 scientist at the thoughtworks in germany\\n5:44 at the time and she told me that\\n5:46 thoughtworks was planning to expand its\\n5:48 data engineering offering and what i'd\\n5:49 be interested in\\n5:52 in becoming the solidworks germany's\\n5:54 first data engineer and help her expand\\n5:56 that offering and i thought it was\\n5:58 really exciting and\\n5:59 especially since southwark is a great\\n6:01 place for really learning good software\\n6:03 engineering practices which as a data\\n6:05 engineer is always frustrated as a data\\n6:07 scientist that always frustrated me that\\n6:09 the quality of the code and the\\n6:11 collaboration wasn't as good as i was i\\n6:13 remembered it from my back in\\n6:14 engineering days\\n6:16 and so i jumped on that and that's when\\n6:17 i finally decided to stay in data\\n6:19 engineering which i had done on and off\\n6:21 before\\n6:23 and then then yeah after that was i went\\n6:26 to where i'm now it was my transfers and\\n6:28 built up data engineering there which\\n6:29 way i'm now heading a team\\n6:32 that's quite a story and thanks for\\n6:33 sharing so uh what i also wanted to ask\\n6:36 you the next question i prepared is that\\n6:38 you were a data scientist and then you\\n6:40 switched to data engineering and i\\n6:41 wanted to ask why i think you partly\\n6:43 answered that so you said that\\n6:47 data science was a bit too black boxy\", 'video_id': '3TTu-hYzxeg'}\n",
      "RES  ← get_document_by_id call_rrSpubjmiMXexGSaQUuvABlG {'start': 4500, 'content': \" i know kafka\\n4:39 spark and things like this right\\n4:41 yeah yeah it's more uh custom solutions\\n4:44 these days right which fits our needs\\n4:46 and moving towards more open source\\n4:50 frameworks right\\n4:52 okay yeah thanks\\n4:54 so let's talk about data engineering\\n4:56 managers so what do they do and why do\\n4:59 we need them\\n5:01 yeah so um\\n5:04 actually the core uh still remains same\\n5:07 as a people manager right so we have to\\n5:09 take care of your team you know you have\\n5:10 to\\n5:11 you know keep looking at you know how\\n5:13 your team is moving your deliverables\\n5:15 etc\\n5:16 but uh another thing which you know adds\\n5:18 up to this role is stakeholder\\n5:20 management right when you're working\\n5:22 with as an individual contributor you're\\n5:24 just\\n5:25 caring about your piece of work here you\\n5:28 have to talk to various stakeholders who\\n5:30 are sponsoring this data platform as\\n5:32 well as\\n5:33 who are consumers right these days the\\n5:36 the number of and variety of consumers\\n5:38 are also growing\\n5:39 they are the stakeholders for us right\\n5:41 so as a data engineering manager you\\n5:43 have to take care of them\\n5:44 their needs right\\n5:46 and uh again uh from the team\\n5:49 your team is also your stakeholder right\\n5:50 so you have to make sure you know their\\n5:53 skill set are getting upgraded\\n5:55 along with the\\n5:57 new tools and technologies coming into\\n5:59 play right\\n6:00 and then\\n6:01 coaching them just deciding their career\\n6:03 path right\\n6:05 and sometimes you know other things like\\n6:08 within a team deciding for some approach\\n6:11 or sometimes conflict resolutions right\\n6:14 and one of the most important tasks for\\n6:16 data hinging manager or any engineering\\n6:18 manager should be prioritizing the task\\n6:21 right you have lot of things coming on\\n6:23 your way right from various stakeholders\\n6:26 so how you\\n6:27 prioritize that that's one of the key\\n6:30 responsibilities as well\\n6:32 so you work on a data platform some\\n6:35 internal data platform right and you\\n6:37 manage the engineers right\\n6:40 and because the the setup we have to\\n6:43 elix is we have engineering managers\\n6:47 and\\n6:48 people who report to the engineering\\n6:50 managers are back-end engineers\\n6:52 front-end engineers and data engineers\\n6:55 right so\\n6:57 we don't have a role that is called data\\n6:58 engineering manager and usually there is\\n7:01 just an engineering manager who manages\\n7:03 the engineers\\n7:05 and i'm wondering why do we have this um\\n7:08 maybe because we work in so-called\\n7:11 feature teams like a team that works on\\n7:13 a specific\\n7:15 part of a product and everyone works on\\n7:17 the same thing while in your case your\\n7:19 team takes care of the other platform so\\n7:21 everyone on your team is a data engineer\\n7:23 right\\n7:24 absolutely yeah\\n7:26 correct yeah\\n7:28 and i guess it's helpful for data\\n7:30 engineers to have a manager who is also\\n7:32 a data engineer or at least who can\\n7:34 relate to the problems they have because\\n7:36 this is how the\", 'video_id': 'FljnbUQ796w'}\n",
      "RES  ← get_document_by_id call_A66AHUz1BJwW8mcBDeu8Lj0K {'start': 4500, 'content': \"alized\\n4:14 i didn't really enjoy data science as\\n4:16 much because it was very black box it\\n4:18 fell to me because i never was felt like\\n4:20 i was feeding some model but i didn't\\n4:22 really understand what's going on which\\n4:23 is partially due to the fact that my\\n4:24 mathematics background isn't that strong\\n4:27 so i didn't never really got the theory\\n4:29 behind it\\n4:30 but also i realized i kind of miss more\\n4:32 the engineering parts of it and\\n4:34 that was also the time when data\\n4:36 engineering became more of a thing\\n4:37 because companies realized that they\\n4:38 need not just data scientists but also\\n4:40 people that actually before come before\\n4:42 them and\\n4:43 make data available for data science\\n4:45 because that's at the time was a common\\n4:47 frustration for data scientists to not\\n4:48 have data\\n4:51 great ambitions but no data\\n4:54 and then i went\\n4:56 got an offer at native instruments to be\\n4:58 one of their first data engineers\\n5:01 i did that for a while um i still had\\n5:04 the ambition back then to transition\\n5:05 back into data science but i left native\\n5:07 instruments for unrelated reasons before\\n5:10 that happened\\n5:12 then i got another job at another\\n5:13 company as a bi developer\\n5:18 my title was data scientists but really\\n5:19 what i did was\\n5:21 develop custom\\n5:23 with data visualizations\\n5:26 and i realized eventually that this was\\n5:28 kind of a dead end for me\\n5:30 and so i\\n5:32 i remembered my software engineering\\n5:34 background which i actually enjoyed\\n5:36 except it was a repetitive and then\\n5:38 at the time i was speaking to somebody\\n5:40 at thoughtworks she was the first data\\n5:42 scientist at the thoughtworks in germany\\n5:44 at the time and she told me that\\n5:46 thoughtworks was planning to expand its\\n5:48 data engineering offering and what i'd\\n5:49 be interested in\\n5:52 in becoming the solidworks germany's\\n5:54 first data engineer and help her expand\\n5:56 that offering and i thought it was\\n5:58 really exciting and\\n5:59 especially since southwark is a great\\n6:01 place for really learning good software\\n6:03 engineering practices which as a data\\n6:05 engineer is always frustrated as a data\\n6:07 scientist that always frustrated me that\\n6:09 the quality of the code and the\\n6:11 collaboration wasn't as good as i was i\\n6:13 remembered it from my back in\\n6:14 engineering days\\n6:16 and so i jumped on that and that's when\\n6:17 i finally decided to stay in data\\n6:19 engineering which i had done on and off\\n6:21 before\\n6:23 and then then yeah after that was i went\\n6:26 to where i'm now it was my transfers and\\n6:28 built up data engineering there which\\n6:29 way i'm now heading a team\\n6:32 that's quite a story and thanks for\\n6:33 sharing so uh what i also wanted to ask\\n6:36 you the next question i prepared is that\\n6:38 you were a data scientist and then you\\n6:40 switched to data engineering and i\\n6:41 wanted to ask why i think you partly\\n6:43 answered that so you said that\\n6:47 data science was a bit too black boxy\", 'video_id': '3TTu-hYzxeg'}\n",
      "RES  ← get_document_by_id call_i03SBAesZXGqM2CJ82ijbvvw {'start': 42000, 'content': \"of Singapore releases a\\n45:30 lot of public data to like this open\\n45:33 data platforms right and sometimes you\\n45:36 need to edit this data before\\n45:40 publishing um the current data that we\\n45:43 share are data that is collected from\\n45:46 systems of course we Mass things like\\n45:50 um U cut numbers\\n45:55 MH what they actually share like and how\\n45:58 to to find this\\n45:59 information um there are two key\\n46:01 platforms one is data.gov Dog the other\\n46:05 one is called Data Mo so data.gov\\n46:08 Aggregates um information across\\n46:11 different government bodies in Singapore\\n46:13 and it ranges from things like rainfall\\n46:16 to air pollution\\n46:20 figures so there are categories like art\\n46:22 and culture education economy\\n46:24 environment geospatial housing Health\\n46:26 social trans\\n46:27 real time API so I guess I need to go to\\n46:30 transport to see your data sets right\\n46:34 yeah okay so I go to\\n46:37 transport and there is quite a lot of\\n46:40 things yes\\n46:42 like air travel geospatial data of like\\n46:47 Puffs\\n46:49 Network and um let's say somebody also\\n46:54 in January will start the next of data\\n46:57 engineering what kind of projects would\\n46:59 you recommend for them to try using\\n47:02 these data\\n47:04 sets I think one useful data set could\\n47:07 be car parking data because we collect\\n47:11 um car parking figures in I think I\\n47:14 think if I'm not wrong it's real time so\\n47:16 you get Gentry um transactions so I\\n47:20 think transaction data is quite a useful\\n47:22 and large data set for data engineering\\n47:25 projects whereby you can inest the data\\n47:27 in real time store it store it in a data\\n47:30 warehouse data Lake and then process it\\n47:32 later on for\\n47:35 analysis car\\n47:40 parking how do I find it so I just uh\\n47:44 look for car parking I don't think I can\\n47:46 find anything I think car parking is a\\n47:49 dynamic data\\n47:51 set H there there's a real time apis\\n47:55 maybe this is what I yes I'm interested\\n47:57 in okay\\n48:00 yeah and I guess I would be interested\\n48:03 in uh I cannot find maybe you can send\\n48:06 it later this is not something I can\\n48:07 just find right now yeah I can send to\\n48:09 you later another one would be real time\\n48:12 taxi data also another Dynamic data set\\n48:15 because I think the last data\\n48:16 engineering Zoom cam we were using the\\n48:19 the New York Taxi data set keep using it\\n48:22 it is an aggregated data set but I think\\n48:26 would be useful to also look at real\\n48:29 time data set and like go through the\\n48:30 process on on how to to store this\\n48:34 information so I put taxi there in the\\n48:37 search bar and then I see public\\n48:40 transport capacity monthly taxi\\n48:42 population and there's data from January\\n48:45 2005 to December uh this is not uh super\\n48:49 up to date but like it's up to December\\n48:51 2017 so there is quite a lot of data but\\n48:56 I see like there are many data sets with\\n48:59 that are constantly updated right ah you\\n49:02 sent me something yeah I just sent it\", 'video_id': 'VXQIGHUWeL0'}\n",
      "RES  ← get_document_by_id call_YYLfOkI9z9gdLjGGShsr9DaK {'start': 6000, 'content': \"'s not like\\n5:29 you just share your stuff once in a\\n5:32 month or once in a week\\n5:33 but you have to do it consistently long\\n5:35 time uh so i will always tell people\\n5:37 that within your presented brand is not\\n5:39 like a one-time goal but more on\\n5:41 it is a consistent uh commitment right\\n5:44 that you need to do\\n5:46 and to share so that you as a person as\\n5:48 an individual your presence\\n5:50 is always on top of other people's mind\\n5:52 so when they have some opportunities\\n5:54 immediately they will think of you and\\n5:57 they will contact you and this is how\\n5:58 you\\n5:59 get more opportunities and we all know\\n6:01 that getting more opportunities\\n6:03 meaning that we can get a better chance\\n6:06 to go to a next level in our career\\n6:09 so it means you need to be like i don't\\n6:11 know if i can say it\\n6:12 like be famous in certain area when they\\n6:16 think okay\\n6:17 who are people in singapore who are good\\n6:19 at teaching data science\\n6:21 they immediately think of you right so\\n6:22 this is a sort of a personal brand right\\n6:24 so being\\n6:26 sort of famous in a certain niche or am\\n6:28 i correct\\n6:30 i maybe i will try to rephrase it\\n6:32 instead of being famous i would say\\n6:34 to be known to know yes to be known as\\n6:37 someone that is established\\n6:39 in their own expertise yes uh\\n6:43 yeah so this is how we define that and\\n6:46 how do we establish this expertise\\n6:49 yeah good questions i think everyone has\\n6:52 their own preference so be it\\n6:53 writing articles or medium uh right or\\n6:56 be\\n6:57 using a podcast if you like uh to\\n7:00 present using your voice or be it a\\n7:02 video if you like a visual kind of\\n7:04 sharing\\n7:04 so everyone has different preference so\\n7:06 to me i prefer\\n7:08 writing and face-to-face sharing\\n7:11 and that's the reason why i become a\\n7:13 data science instructor because i like\\n7:15 to share\\n7:16 face to face online or offline so if you\\n7:18 have noticed i also\\n7:20 share quite a bit of data science\\n7:22 articles on medium\\n7:24 and i think one of the main reasons is\\n7:26 that i love writing like a lot\\n7:28 i love sharing my thoughts on writing i\\n7:30 i i see that you know whenever i write\\n7:33 it really helps me think deeper of what\\n7:35 i understand\\n7:37 certain knowledge that helps me reflect\\n7:41 on a lot of things on myself to deepen\\n7:43 my knowledge\\n7:44 and at the same time i can share with\\n7:46 others to help others\\n7:47 so to me i think that depends on what\\n7:50 channel you\\n7:51 prefer and you can go for it yeah\\n7:54 so for you you mentioned it was medium\\n7:56 right so you started\\n7:58 posting something actively on medium and\\n8:00 this is how people noticed you right\\n8:03 exactly exactly exactly can you tell us\\n8:06 that story like how did it happen for\\n8:08 you\\n8:08 yeah great uh this is interesting back\\n8:11 two years back\\n8:13 when i started my data science journey\\n8:14 because i just wanted to share my\\n8:17 data science journey and back then i\\n8:19 didn't know about this thing called\\n8:21 p\", 'video_id': 'tQRQnz_aHYQ'}\n",
      "RES  ← get_document_by_id call_sP1PvZhRitAkOjbHtGad0MuA {'start': 46500, 'content': \"on it's for us\\n45:30 just a\\n45:31 decision to build this data governance\\n45:33 solution and\\n45:34 better understanding what kind of data\\n45:36 the process and\\n45:37 what kind of data we have inside just\\n45:39 from multiple people having multiple\\n45:41 tables and\\n45:42 no one knows what's in there\\n45:46 i assume that data scientists\\n45:49 also they produce a lot of data so their\\n45:52 models produce data\\n45:53 they also need to document the data\\n45:55 right do they use the same tool for that\\n45:58 yeah they just use the same time\\n46:01 description\\n46:02 or recommendation confluence so you have\\n46:05 the central place\\n46:06 for implementation for your data for\\n46:08 data that\\n46:10 data scientists produce and then it's\\n46:12 just once interface base\\n46:14 okay cool thanks uh we have a question\\n46:18 from ak\\n46:19 shot is\\n46:22 i think\\n46:26 so how much of data engineering should\\n46:27 one ideally know\\n46:29 i think we covered that um\\n46:32 a bit but um yeah so we talked about\\n46:36 that like how much data engineering\\n46:38 skills data scientists need to know\\n46:40 ideally um\\n46:43 but yeah we were more talking about like\\n46:45 if data scientists want to transition\\n46:47 into data engineering\\n46:48 but to be able to successfully do work\\n46:51 as data scientists\\n46:53 what kind of data engineering skills\\n46:55 they should have\\n46:58 i would say that coding skills it's also\\n47:00 important because i know that some\\n47:02 data scientists somewhere on the\\n47:03 mathematical side and they\\n47:05 more interested in building algorithms\\n47:07 than to write code\\n47:08 and it actually influences the quality\\n47:10 of the creation\\n47:12 because they you can either build just\\n47:15 everything for example in one notebook\\n47:17 and it would be hard to deploy it in\\n47:19 some way or they would build the whole\\n47:21 solution this libraries and for example\\n47:24 classes in python\\n47:25 maybe object-oriented programming so it\\n47:28 would be more like software engineering\\n47:30 way to do things\\n47:31 and the databases for sure as well\\n47:34 because they do need to read the data\\n47:36 or write some results there right\\n47:39 okay so basically uh improve your\\n47:41 software engineering skills\\n47:43 yeah yeah i think the trend i see\\n47:47 is now most data scientists in most\\n47:50 companies that\\n47:52 i see there is a requirement of being a\\n47:54 good\\n47:55 developer so maybe they don't need to be\\n47:58 as good as software engineers\\n48:00 but they need to be decent with coding\\n48:06 um yeah there is a comment about uh for\\n48:08 getting started with kubernetes there is\\n48:10 a good resource\\n48:11 called catacoda and\\n48:14 i think i saw it um i know have you seen\\n48:16 it\\n48:17 yeah i tried it once it was in the\\n48:20 beginning it's quite useful you can just\\n48:22 try out\\n48:22 different commands and see what happens\\n48:25 yeah i think\\n48:26 i saw uh one with kubernetes and one\\n48:28 with\\n48:29 i think and it's pretty cool so they\\n48:32 just\\n48:33 set up a local kubernetes for \", 'video_id': 'yg3d1lFd7Uo'}\n",
      "RES  ← get_document_by_id call_UwnKYeYRBFi8j9pocgX7tzBx {'start': 42000, 'content': \"of Singapore releases a\\n45:30 lot of public data to like this open\\n45:33 data platforms right and sometimes you\\n45:36 need to edit this data before\\n45:40 publishing um the current data that we\\n45:43 share are data that is collected from\\n45:46 systems of course we Mass things like\\n45:50 um U cut numbers\\n45:55 MH what they actually share like and how\\n45:58 to to find this\\n45:59 information um there are two key\\n46:01 platforms one is data.gov Dog the other\\n46:05 one is called Data Mo so data.gov\\n46:08 Aggregates um information across\\n46:11 different government bodies in Singapore\\n46:13 and it ranges from things like rainfall\\n46:16 to air pollution\\n46:20 figures so there are categories like art\\n46:22 and culture education economy\\n46:24 environment geospatial housing Health\\n46:26 social trans\\n46:27 real time API so I guess I need to go to\\n46:30 transport to see your data sets right\\n46:34 yeah okay so I go to\\n46:37 transport and there is quite a lot of\\n46:40 things yes\\n46:42 like air travel geospatial data of like\\n46:47 Puffs\\n46:49 Network and um let's say somebody also\\n46:54 in January will start the next of data\\n46:57 engineering what kind of projects would\\n46:59 you recommend for them to try using\\n47:02 these data\\n47:04 sets I think one useful data set could\\n47:07 be car parking data because we collect\\n47:11 um car parking figures in I think I\\n47:14 think if I'm not wrong it's real time so\\n47:16 you get Gentry um transactions so I\\n47:20 think transaction data is quite a useful\\n47:22 and large data set for data engineering\\n47:25 projects whereby you can inest the data\\n47:27 in real time store it store it in a data\\n47:30 warehouse data Lake and then process it\\n47:32 later on for\\n47:35 analysis car\\n47:40 parking how do I find it so I just uh\\n47:44 look for car parking I don't think I can\\n47:46 find anything I think car parking is a\\n47:49 dynamic data\\n47:51 set H there there's a real time apis\\n47:55 maybe this is what I yes I'm interested\\n47:57 in okay\\n48:00 yeah and I guess I would be interested\\n48:03 in uh I cannot find maybe you can send\\n48:06 it later this is not something I can\\n48:07 just find right now yeah I can send to\\n48:09 you later another one would be real time\\n48:12 taxi data also another Dynamic data set\\n48:15 because I think the last data\\n48:16 engineering Zoom cam we were using the\\n48:19 the New York Taxi data set keep using it\\n48:22 it is an aggregated data set but I think\\n48:26 would be useful to also look at real\\n48:29 time data set and like go through the\\n48:30 process on on how to to store this\\n48:34 information so I put taxi there in the\\n48:37 search bar and then I see public\\n48:40 transport capacity monthly taxi\\n48:42 population and there's data from January\\n48:45 2005 to December uh this is not uh super\\n48:49 up to date but like it's up to December\\n48:51 2017 so there is quite a lot of data but\\n48:56 I see like there are many data sets with\\n48:59 that are constantly updated right ah you\\n49:02 sent me something yeah I just sent it\", 'video_id': 'VXQIGHUWeL0'}\n",
      "RES  ← get_document_by_id call_o6VVXq3dE7XgIuCDlrPQMRfI {'start': 46500, 'content': \"all companies\\n43:30 and this is part of the prep\\n43:32 um all companies will have different\\n43:34 expectations and what they're going to\\n43:35 speak to you about so\\n43:37 for me I would never prepare for\\n43:39 specific questions I would practice\\n43:41 questions in case they come up but when\\n43:44 it comes to preparation for technical\\n43:46 interviews you what we need to do is\\n43:50 really under or try to understand the\\n43:52 expectations of the individual customers\\n43:55 that we're trying to work with right or\\n43:57 the individual companies that we're\\n43:58 trying to join so the questions I mean I\\n44:02 could tell you something but they're not\\n44:03 going to be relevant for everyone else\\n44:04 right but what is relevant is\\n44:08 um\\n44:09 setting the expectations or under trying\\n44:11 to understand the expectations of the\\n44:13 clients that you're interviewing with so\\n44:15 again if you had someone on the inside\\n44:17 or a HR Talent person that you're\\n44:19 working with or a recruiter when you get\\n44:21 to a technical interview the first thing\\n44:24 that you should be asking is what are\\n44:25 the expectations of this interview you\\n44:27 should never ever in my opinion go into\\n44:30 an interview and say it's a technical\\n44:33 interview and that's all you know that\\n44:35 is blasphemy here my word\\n44:38 um\\n44:39 every single time you go into any\\n44:41 interview you should really understand\\n44:42 at least from an agenda perspective\\n44:46 the context of what you're going into\\n44:48 and speaking about right because you\\n44:50 need something to base your prep offers\\n44:54 um so yeah number one I'd always do this\\n44:56 before so let's say\\n44:59 and working with you so I am over like I\\n45:03 passed this introduction stage and now\\n45:05 you set\\n45:07 an interview a technical interview with\\n45:10 oh like somebody I don't know senior\\n45:12 data scientist\\n45:14 so what I do do I ask you or do I ask\\n45:16 that person like what are your\\n45:18 expectations in email before the\\n45:20 interview so I know what to expect\\n45:22 yeah this is what you're saying yeah so\\n45:25 let's say you got through the the intro\\n45:28 stage and that went really well look I'm\\n45:30 really Keen to continue\\n45:32 um what's the next stage and what are\\n45:33 the expectations so if we're in that\\n45:35 technical stage I should be able to give\\n45:37 you a very strong or at least some\\n45:40 pointers in terms of what they're going\\n45:41 to be looking for within that technical\\n45:43 stage right and that's the kind of\\n45:45 Baseline for your preparation what we\\n45:47 don't want to do is go really broad\\n45:49 really generic and kind of not really\\n45:51 know what goal we're shooting at and yes\\n45:54 there are some really good sites out\\n45:56 there where you can go and practice like\\n45:57 coding questions and Link code and\\n46:00 hackarack and code forces and stuff like\\n46:02 that but generally I think when we are\\n46:05 prepping for\\n46:06 an organization we want to keep it as\\n46:09 focused towards our \", 'video_id': 'NnZjlMowkWA'}\n",
      "RES  ← get_document_by_id call_Ia6e2pR4wdnXoce1dkSqLyBY {'start': 22500, 'content': \"ll\\n26:24 of them yeah so which means that um\\n26:29 let's say somebody wants to take our\\n26:32 courses they should do some of this work\\n26:34 even before they take courses right yeah\\n26:36 yeah exactly then you have more Focus\\n26:39 from the very beginning and you know\\n26:40 okay I want to focus on data engineering\\n26:42 so I take data\\n26:44 engineering and then uh yeah just after\\n26:48 the course perhaps instead of taking the\\n26:49 other courses focus on developing the\\n26:52 skills in this area focus on doing more\\n26:54 projects in this area exactly and then\\n26:57 get interviews in that area right and\\n27:00 try to understand where you stand what\\n27:02 else is needed required to get a job\\n27:05 hopefully after finishing our course you\\n27:07 get all the skills right yeah yeah but\\n27:10 sometimes some companies might require\\n27:13 something specific right that we don't\\n27:15 cover and then this is where you can\\n27:18 understand that okay yeah and then try\\n27:20 to focus on I know building a project\\n27:23 with this particular skill yeah it's\\n27:25 it's important to not get lost in doing\\n27:28 all the courses I don't know if if\\n27:29 really all of them do all uh all the\\n27:32 courses before starting a new course\\n27:34 just take some time and okay maybe have\\n27:37 a project even if so I finish data\\n27:40 engineering I do a project I do a a\\n27:43 project and I see if I enjoy doing it\\n27:46 okay I I suppose the hypothesis is\\n27:49 something that I would like but okay I\\n27:51 finish data engineering let me practice\\n27:54 let me show that I developed skills in\\n27:57 data\\n27:59 engineering and then think about another\\n28:02 course but going from uh one course to\\n28:06 another\\n28:07 is like I don't know the wor but yeah\\n28:11 it's better to avoid it like especially\\n28:14 like that's circle like you get on the\\n28:16 train of course after course after\\n28:19 course because I feel like I still don't\\n28:20 have enough qualifications but remember\\n28:24 you have also skills you have strs you\\n28:27 have experience\\n28:29 so don't forget about\\n28:32 that and when it comes to having even\\n28:35 more Focus cuz like okay we you\\n28:38 mentioned that when it comes to data\\n28:40 science it's such a broad topic it can\\n28:43 mean anything from analysts to hardcore\\n28:47 deep learning whatever right\\n28:50 um and when you read one job description\\n28:54 for data scientist it can be super\\n28:56 different from another description of\\n28:58 data scientist and the same thing with\\n29:00 data Engineers so you can be a data\\n29:01 engineer that builds a data platform you\\n29:04 can be a data engineer that helps\\n29:06 analyst you can be a data engineer that\\n29:08 works with data scientists right so\\n29:10 there are also\\n29:14 speci and like do if I already know okay\\n29:18 I want to do data science or I want to\\n29:19 do data engineering do I already should\\n29:23 I already have even more focus and think\\n29:26 okay like I want to focus on this\\n29:28 particular type of data science job or\\n29:31 \", 'video_id': 'PchwbIs0tOg'}\n",
      "RES  ← get_document_by_id call_KzPtke0I8kDR1K4VxExAkZYG {'start': 46500, 'content': \"n quickly check like tabue\\n47:00 or um basic SQL stuff and then just get\\n47:04 going on learning on your own self-\\n47:06 learning is crucial but it I feel those\\n47:10 roles still require some effort because\\n47:11 you do need to spend sometime hardcore\\n47:14 learning those Technologies but product\\n47:17 manager I think it's easier to get\\n47:20 through MH yeah and um yeah so we talked\\n47:25 about Eugene and Eugene also lives in\\n47:27 Seattle\\n47:29 yes I didn't realize that you from the\\n47:32 same city and uh yeah but it's a big\\n47:35 city right it's not like you can\\n47:36 randomly St like running to people on\\n47:38 the street yeah I mean uh I'm very close\\n47:42 to the area where all these Amazon\\n47:43 offices are so yeah every day I do look\\n47:48 some I do come across someone familiar\\n47:51 either from my undergrad Masters or just\\n47:53 from LinkedIn yeah very very active\\n47:56 people yeah\\n47:58 so another question can you please\\n48:00 highlight me mentorship networking\\n48:01 opportunities which were\\n48:04 helpful um so is this about um getting\\n48:07 those opportunities for to be a\\n48:10 mentor so I the way I interpret\\n48:13 interpret this question is you had some\\n48:16 mentorship opportunities but then some\\n48:18 of them ended being helpful for you in\\n48:23 some way oh I see uh yeah I think so\\n48:28 getting those Mentor roles is uh\\n48:31 typically just through reach outs um\\n48:34 cold emailing LinkedIn messages um stuff\\n48:38 like that uh and once you build like\\n48:40 certain rappo with these people these\\n48:42 are huge communities then it becomes a\\n48:44 word of mouth so if you have done like\\n48:47 good networking putter good um good name\\n48:50 to your work um then it becomes a word\\n48:54 of mouth and that's how you kind of\\n48:56 excel in these community-driven uh\\n48:58 programs um because cold emailing or\\n49:01 these stuff can get you into it but like\\n49:04 to build you know a good uh trustworthy\\n49:07 uh relationships or networking as we\\n49:09 call it it's mainly through Word of\\n49:11 Mouth in my opinion yeah actually so now\\n49:16 again speaking of the our conversation\\n49:19 the earlier conversation um so I\\n49:22 scrolled up and saw that we talked about\\n49:24 mentorship and the reason I asked you\\n49:26 about that is because I was doing some\\n49:28 mentorship myself back then so I was\\n49:29 interested in your perspective on these\\n49:33 things and\\n49:35 um for me what was helpful is\\n49:40 uh maybe just structuring my knowledge\\n49:43 around things so people come to you with\\n49:45 requests and then you try to help and\\n49:48 then this way when you speak when you\\n49:50 say things out loud it helps to\\n49:53 structure these things in your head and\\n49:54 then it becomes easier to use this\\n49:57 information like in other settings that\\n49:59 was the main kind of highlight for me\\n50:01 and then like when\\n50:03 people one year after that right hey\\n50:06 like thanks because of the interview\\n50:09 because of the session we did together\\n50:11 like now I work at\", 'video_id': 'ekG5zJioyFs'}\n",
      "RES  ← get_document_by_id call_5SN4lICntMMSohGJWqAfi2d9 {'start': 9000, 'content': \"a engineers like uh buy\\n9:28 the book and the way it's supposed to be\\n9:30 a difference in terms of um how you\\n9:32 process the data like big data\\n9:34 engineering requires a bit different\\n9:36 tools like heavy load\\n9:37 optimizations data engineering small\\n9:40 like\\n9:40 software engineering on the back end but\\n9:43 in reality i would say that\\n9:44 a lot of companies name big data\\n9:46 engineers as data engineers and it's\\n9:48 like constantly a bit confusing\\n9:50 because of that so many just drop the\\n9:53 big part and just\\n9:55 go with data engineer and is there any\\n9:58 difference in\\n9:59 tools uh because for example you you say\\n10:02 you mentioned spark impala\\n10:05 things like this and what i see\\n10:09 in data engineers\\n10:12 maybe is a bit different like most of\\n10:14 them use spark as well but i see\\n10:17 more cloud-based things like i don't\\n10:20 know\\n10:21 streams lambda functions and things like\\n10:24 this or it's just\\n10:25 it depends on the company and there's no\\n10:27 really big difference\\n10:29 i would say it depends on the company\\n10:30 because some companies choose multiple\\n10:32 cloud sources\\n10:33 some companies build custom solutions\\n10:35 and because of that\\n10:37 data engineers might be more on the side\\n10:39 of for example parsing data\\n10:40 which is considered to be like more\\n10:42 background thing or\\n10:44 writing written from the database while\\n10:46 more big data scene is working with\\n10:48 uh so-called big data specific data\\n10:51 formats\\n10:51 like uh avro rk and protobuf\\n10:55 probably like backgrounds and js usually\\n10:58 work with json\\n10:59 or maybe a little bit the safe space\\n11:02 okay so at the end usually there is no\\n11:04 much difference\\n11:05 yeah okay and so what kind of i think we\\n11:09 talked about\\n11:10 about tools so we talked about uh\\n11:13 spark cloud\\n11:16 and you mentioned scala as well i think\\n11:18 python is quite popular\\n11:20 yeah what kind of skills if we not if\\n11:23 we're not talking about specific tools\\n11:24 but more skills\\n11:26 or more fundamental skills what kind of\\n11:28 skills they need\\n11:30 to be able to do their job i would say\\n11:33 the most important one is coding skills\\n11:35 um\\n11:36 it's often that senior level engineers\\n11:39 get into big data engineering which is\\n11:40 quite logical because\\n11:42 they already have some experience on the\\n11:44 backend side and then\\n11:45 they learn big data stack and just\\n11:48 understand already how it works behind\\n11:50 the scenes\\n11:51 so definitely a great level of coding\\n11:54 skills\\n11:55 another one is working these databases\\n11:58 like writing queries being able to\\n12:00 optimize them\\n12:00 usually it's a sql databases sometimes\\n12:03 no sql\\n12:04 so kind of being able to switch from one\\n12:07 to another because\\n12:08 in my experience when you join different\\n12:10 companies sometimes you have\\n12:12 totally different stack or even\\n12:13 different projects and you just have to\\n12:15 switch real quick\\n12:17 so those are those would be the m\", 'video_id': 'yg3d1lFd7Uo'}\n",
      "RES  ← get_document_by_id call_eDMJUMmGpCttZsElaWqiDHzz {'start': 21000, 'content': \"re\\n19:31 right and then um then also\\n19:34 learn a bit of machine learning right um\\n19:37 is how\\n19:38 this is this how the learning path uh\\n19:40 like let's say we have a typical\\n19:43 data analyst who knows how to write sql\\n19:46 queries who knows how to create\\n19:47 dashboards\\n19:48 who knows how to do\\n19:52 nice data visualization and they want to\\n19:54 become this type a\\n19:56 data scientist how the learning path for\\n19:58 them will look like\\n20:00 so i can talk about this quite well\\n20:03 because that was exactly my path\\n20:05 i when i started my journey into data\\n20:08 science i could\\n20:10 build like do the sequel very badly did\\n20:13 the\\n20:13 do the excel do the dashboarding\\n20:16 do a little bit of r but i had no idea\\n20:19 what the other skills were\\n20:21 so a lot of my journey was essentially\\n20:23 just trying to figure out what i should\\n20:25 learn\\n20:26 once i had that direction when i started\\n20:30 working with people who were in a data\\n20:31 science role\\n20:32 who had data science experiments or\\n20:34 experience\\n20:36 and they could guide me on what i should\\n20:38 be learning that was when i saw my own\\n20:40 growth\\n20:40 and development really like just pick up\\n20:42 like a hockey stick\\n20:43 so um definitely i felt that\\n20:47 before i had that sort of guidance i was\\n20:49 just kind of fumbling around in the dark\\n20:51 reading a lot of different articles and\\n20:53 kind of being stretched everywhere\\n20:55 so you hear like oh you need to\\n20:57 understand all the theory before you\\n20:58 even start doing any programming and\\n21:00 then someone else would say\\n21:01 no you just go implement the machine\\n21:02 learning things and then you pick up the\\n21:04 theory\\n21:04 so i feel like yeah that's what i would\\n21:08 say is all just\\n21:08 go and try a few things and when you\\n21:11 need to learn the theory you'll know\\n21:12 when you need to learn the theory\\n21:13 because you have no idea what's going on\\n21:14 so\\n21:16 i think that was that was the same\\n21:17 advice given to me also\\n21:19 so um but yeah i would say for anyone\\n21:22 who's currently\\n21:23 in a data analyst role or doing\\n21:26 work which is not even in analytics but\\n21:28 you're managing databases or\\n21:30 you're um i wouldn't say software\\n21:33 developer that comes into the\\n21:34 the other into the type b but for anyone\\n21:37 who's working with data\\n21:38 and they're doing things and visualizing\\n21:40 and whatever\\n21:42 there's definitely a path into data\\n21:43 science you just have to be curious and\\n21:45 keep working on it\\n21:46 and work with good strong mentors who\\n21:49 can give you\\n21:50 that level of guidance to push you in\\n21:51 the right direction\\n21:54 yeah so that's uh so i'm just\\n21:57 trying to like how can we formalize this\\n21:59 being curious right\\n22:00 so you can just uh like let's say you\\n22:03 you are trying to put a learning plan\\n22:05 and then you put\\n22:06 python there you put machine learning\\n22:07 theory there you put uh\\n22:09 some other things and then th\", 'video_id': 'HVQ0DZOQcts'}\n",
      "RES  ← get_document_by_id call_n03zLzriQakwLBFfYOr8dFql {'start': 6000, 'content': \"u know other things like\\n6:08 within a team deciding for some approach\\n6:11 or sometimes conflict resolutions right\\n6:14 and one of the most important tasks for\\n6:16 data hinging manager or any engineering\\n6:18 manager should be prioritizing the task\\n6:21 right you have lot of things coming on\\n6:23 your way right from various stakeholders\\n6:26 so how you\\n6:27 prioritize that that's one of the key\\n6:30 responsibilities as well\\n6:32 so you work on a data platform some\\n6:35 internal data platform right and you\\n6:37 manage the engineers right\\n6:40 and because the the setup we have to\\n6:43 elix is we have engineering managers\\n6:47 and\\n6:48 people who report to the engineering\\n6:50 managers are back-end engineers\\n6:52 front-end engineers and data engineers\\n6:55 right so\\n6:57 we don't have a role that is called data\\n6:58 engineering manager and usually there is\\n7:01 just an engineering manager who manages\\n7:03 the engineers\\n7:05 and i'm wondering why do we have this um\\n7:08 maybe because we work in so-called\\n7:11 feature teams like a team that works on\\n7:13 a specific\\n7:15 part of a product and everyone works on\\n7:17 the same thing while in your case your\\n7:19 team takes care of the other platform so\\n7:21 everyone on your team is a data engineer\\n7:23 right\\n7:24 absolutely yeah\\n7:26 correct yeah\\n7:28 and i guess it's helpful for data\\n7:30 engineers to have a manager who is also\\n7:32 a data engineer or at least who can\\n7:34 relate to the problems they have because\\n7:36 this is how they can\\n7:38 think what is the best way for the\\n7:41 development for coaching right and if we\\n7:44 have just a usual\\n7:46 engineering manager they might not\\n7:48 know in a lot of details about you know\\n7:51 new data tools and so on right that's\\n7:53 where you come into play into picture\\n7:56 and then this is you if you give\\n7:58 suggestions to people you tell them what\\n8:00 is good to learn right\\n8:02 yeah i think you mentioned very valid\\n8:04 point right um this role when i talk to\\n8:07 other engineering managers i realized\\n8:08 that as a data engineering manager you\\n8:11 have to\\n8:12 be in line with some hands-on activities\\n8:15 as well so you should know what your\\n8:16 team is working upon at the code level\\n8:18 sometimes right\\n8:20 so that's that's how i spend my time\\n8:22 like i wear two heads here so 50 of the\\n8:25 time i am working as an individual\\n8:26 contributor as a data engineer in my\\n8:28 team and remaining fifty percent i am uh\\n8:31 managing the team right\\n8:33 so\\n8:33 as you mentioned it uh correctly because\\n8:35 uh sometimes when you when you have\\n8:38 technical brainstorming you know or\\n8:40 maybe defining road maps then your\\n8:42 technical skill sets really comes into\\n8:44 play\\n8:45 so a data engineering manager should\\n8:48 should definitely you know have some\\n8:50 hands on not only just managing people\\n8:54 how do you find time to actually do this\\n8:56 like how large is your team how many\\n8:58 people do you make so currently uh\\n9:00 in i manage eight people s\", 'video_id': 'FljnbUQ796w'}\n",
      "RES  ← get_document_by_id call_CT9XwKxJyuIfVbTMSV54ubuZ {'start': 10500, 'content': \" i've\\n9:37 experienced it in quite a few places\\n9:41 and uh but as a data engineer i guess as\\n9:44 a data scientist you already needed to\\n9:46 do some things that data engineers would\\n9:48 do right so you mentioned that at\\n9:50 soundcloud so you not only did modeling\\n9:54 but also everything that it was before\\n9:55 modeling like building data pipelines\\n9:58 and after modeling i guess deploying the\\n10:00 model so how does it overlap with what\\n10:04 data engineers usually do what you did\\n10:05 as a data scientist yes there's a lot of\\n10:07 overlap and\\n10:09 so there as the data scientists usually\\n10:12 are often you you don't work with\\n10:14 perfectly clean and perfectly delivered\\n10:16 data you will still build up your own\\n10:18 pipelines to make the data accessible\\n10:20 and especially if you move into more\\n10:23 production level\\n10:25 and\\n10:26 i mean the\\n10:27 data size is a very loose title and what\\n10:29 you do under this role can be very\\n10:30 different but there's often a lot of\\n10:33 pipelining work that you do on yourself\\n10:35 and i think\\n10:36 it's a good thing that data scientists\\n10:38 do that and don't just rely on data\\n10:40 engineers to kind of do handhold them\\n10:42 through these steps\\n10:45 and so there's a lot of transferable\\n10:46 skills it also depends great and also\\n10:48 data engineering is a very broad topic\\n10:51 and i never did the more kafka real-time\\n10:53 data engineering kind of stuff i've\\n10:54 carefully navigated myself around that\\n10:57 i've always done more what is now\\n10:58 considered analytics engineering maybe\\n11:01 which is more like the preparing data\\n11:03 for vi and data warehouses and\\n11:06 scheduling batch processing and all\\n11:08 these kind of things\\n11:10 so that was more my realm of data\\n11:12 engineering\\n11:13 and there's there's a this whole other\\n11:15 universe of data engineering that i've\\n11:16 never really touched and that i don't\\n11:18 feel i think where you need a better\\n11:20 understanding of distributed system and\\n11:21 things like that which i don't have\\n11:23 and so that is that's often more the\\n11:25 playground for people with a really\\n11:27 strong distributed computer science\\n11:29 background\\n11:31 and that isn't just not my round but in\\n11:33 for another for anything that's more in\\n11:35 the world of what is now analytics\\n11:36 engineering that kind of branch of data\\n11:38 engineering i think data scientists are\\n11:40 very well prepared there's obviously\\n11:42 things we need to learn but it there's a\\n11:44 lot\\n11:45 i've seen of i've often found that\\n11:47 people that come from peers of\\n11:49 engineering don't have a feeling for\\n11:50 data that they struggle more to move\\n11:52 into that space than people that come\\n11:54 that have a data science background and\\n11:56 just need to level up on\\n11:58 software engineering and collaboration\\n12:00 skills\\n12:01 what is this feeling of data in your\\n12:04 opinion what is that\\n12:06 yeah that that means understanding\\n12:08 it's a lot of things about\", 'video_id': '3TTu-hYzxeg'}\n"
     ]
    }
   ],
   "source": [
    "synthesizer_results = await synthesizer.run(\n",
    "    user_prompt=user_prompt,\n",
    "    output_type=ResearchReport,\n",
    "    event_stream_handler=synthesizer_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57e1852a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentRunResult(output=ResearchReport(stages=[StageReport(stage=1, keywords=[Keyword(search_keyword='data engineering learning path for beginners', summary='The importance of guidance for beginners in data engineering was highlighted.', references=[Reference(quote='so definitely i felt that before I had that sort of guidance I was just kind of fumbling around in the dark reading a lot of different articles...', youtube_id='HVQ0DZOQcts', timestamp='19:40')], relevance_summary='This quote emphasizes how essential clear guidance is for newcomers to learn data engineering effectively.', other_ideas='Exploring structured mentorship options could further enhance the learning experience.'), Keyword(search_keyword='essential skills for data engineers', summary='Experts consider coding skills fundamental for success in data engineering.', references=[Reference(quote='I would say the most important one is coding skills...', youtube_id='yg3d1lFd7Uo', timestamp='11:33')], relevance_summary='This snippet asserts the critical role of coding skills in the data engineering field.', other_ideas='Further investigation into programming languages used in data engineering could be valuable.'), Keyword(search_keyword='best online courses for data engineering', summary='Numerous online courses are available that focus on various skills fundamental to data engineering.', references=[Reference(quote='There are good courses about this...', youtube_id='HVQ0DZOQcts', timestamp='25:04')], relevance_summary='This indicates a range of educational resources that novices can utilize for structured learning.', other_ideas='Comparing specific courses might provide better insights on which to choose.'), Keyword(search_keyword='data engineering tools and technologies', summary='Understanding various tools used in data engineering is necessary for practical applications in the field.', references=[Reference(quote='...you can see them as tools solving different pieces of the puzzle.', youtube_id='yg3d1lFd7Uo', timestamp='38:24')], relevance_summary='This highlights the array of tools and technologies integral to data engineering tasks.', other_ideas='Investigating which tools are most in-demand in the job market might enhance relevance.'), Keyword(search_keyword='step-by-step guide to becoming a data engineer', summary='A successful transition into data engineering entails acquiring a new set of skills amidst shifting data paradigms.', references=[Reference(quote='...you have to acquire a new skill set but when this data paradigm is shifting right...', youtube_id='FljnbUQ796w', timestamp='4:02')], relevance_summary='This insight speaks to how evolving data methodologies necessitate ongoing education.', other_ideas='Exploring specific skills in demand within the industry could further guide newcomers.')], summary='The initial research stage identified essential resources and guidance needed for beginners venturing into data engineering. Key themes included the importance of structured guidance, coding as a fundamental skill, available online courses, tools in data engineering, and the skill sets necessary for effective transition into the field.'), StageReport(stage=2, keywords=[Keyword(search_keyword='data engineering projects for beginners', summary='Practical projects suggested for beginners include utilizing real-time datasets like car parking data.', references=[Reference(quote='...one useful data set could be car parking data because we collect uh car parking figures in real time...', youtube_id='VXQIGHUWeL0', timestamp='47:07'), Reference(quote='...first if you start with the source systems where data exists right it could be relational database flat files cloud s3...', youtube_id='yg3d1lFd7Uo', timestamp='58:12')], relevance_summary='These quotes outline concrete project examples and foundational understanding for beginners in data engineering.', other_ideas='Exploring additional project datasets or beginner-friendly APIs could cater to learners.'), Keyword(search_keyword='advanced data engineering skills', summary='Advanced coding and software engineering skills are necessary for effective data pipeline management.', references=[Reference(quote=\"...there's often a lot of pipelining work that you do on yourself.\", youtube_id='3TTu-hYzxeg', timestamp='10:33'), Reference(quote='I would say that coding skills...is also important...', youtube_id='yg3d1lFd7Uo', timestamp='47:00')], relevance_summary='This insight highlights the readiness required to manage complex data projects effectively.', other_ideas='Exploring specific coding languages preferred in data engineering roles would enhance clarity.'), Keyword(search_keyword='mentorship opportunities in data engineering', summary='Networking is crucial for finding mentorship, enabling career growth and development in data engineering.', references=[Reference(quote='...getting those Mentor roles is typically just through reach outs...', youtube_id='3TTu-hYzxeg', timestamp='48:30'), Reference(quote='...find somebody in your company in your workplace for this kind of relationships', youtube_id='FljnbUQ796w', timestamp='33:30')], relevance_summary='These snippets emphasize actionable steps toward cultivating mentorship in the data engineering field.', other_ideas='Examining organizations or platforms emphasizing mentorship could enhance networking opportunities.'), Keyword(search_keyword='real-world applications of data engineering', summary='Various sectors benefit from data engineering, including healthcare and urban planning.', references=[Reference(quote=\"...it's important for doctors...to understand...\", youtube_id='3TTu-hYzxeg', timestamp='37:10'), Reference(quote='...one useful data set could be car parking data...', youtube_id='VXQIGHUWeL0', timestamp='47:07')], relevance_summary='These quotes showcase the tangible impacts data engineering has across critical fields.', other_ideas='Exploring case studies showcasing successful implementations of data engineering in vital sectors could provide deeper insights.')], summary='The second stage brought to light several beginner-friendly projects while emphasizing the need for advanced skills and networking opportunities. Recognizing real-world applications of data engineering solidified the value and relevance of practical experience for beginners.'), StageReport(stage=3, keywords=[Keyword(search_keyword='data engineering certifications', summary='Certifications can validate skills, enhancing credibility in the competitive data engineering job market.', references=[Reference(quote='we might as well get some certifications for those students', youtube_id='yg3d1lFd7Uo', timestamp='32:56'), Reference(quote='...people are looking for soft skills...', youtube_id='FljnbUQ796w', timestamp='18:19')], relevance_summary='This highlights the importance of certifications in distinguishing emerging data engineers in the job market.', other_ideas='Research on specific certification programs relevant for data engineers might benefit newcomers.'), Keyword(search_keyword='transitioning from academic to professional in data engineering', summary='Adaptation to industry practices and necessary skills is vital for academic professionals entering the data engineering field.', references=[Reference(quote='...become more comfortable working with your command line...', youtube_id='FljnbUQ796w', timestamp='60:22'), Reference(quote='...you need to set up the infrastructure for building models...', youtube_id='yg3d1lFd7Uo', timestamp='29:36')], relevance_summary='These snippets prepare learners for practical challenges faced in the workforce.', other_ideas='Examining common hurdles faced when transitioning could provide further context.'), Keyword(search_keyword='data engineering interview preparation', summary='Focusing preparation on company-specific demands is crucial for successful data engineering interviews.', references=[Reference(quote=\"...what are the expectations of the individual customers that we're trying to work with...\", youtube_id='NnZjlMowkWA', timestamp='44:43'), Reference(quote='The questions... would practice questions...', youtube_id='NnZjlMowkWA', timestamp='43:57')], relevance_summary='These insights stress understanding the nuances of the interview process to optimize preparation efforts.', other_ideas='Developing targeted study materials based on different job descriptions might benefit candidates.')], summary='The third research stage further solidified the importance of professional skills, including certifications and effective preparation for interviews. Recognizing the shift from academic settings to professional environments was also emphasized as a pivotal aspect for upcoming data engineers.')], article=Article(title='A Structured Learning Path for Aspiring Data Engineers', introduction='Data engineering is a critical field that underpins the modern data-driven world. As organizations increasingly rely on data for decision-making, the demand for skilled data engineers has surged. This article seeks to provide a structured learning path for those looking to start a career in data engineering, emphasizing essential skills, tools, and resources.', sections=[ArticleSection(title='The Importance of Guidance for Beginners', claims=[Claim(description=\"For beginners in data engineering, having structured guidance is crucial. As one expert noted, prior to receiving direction, many individuals feel like they are 'fumbling around in the dark,' which can lead to confusion and frustration. This highlights the necessity of finding a clear learning path to navigate the complexities of data engineering (HVQ0DZOQcts).\", relevance_check='This insight emphasizes how critical a structured approach is for effective learning in data engineering.', reference=Reference(quote='so definitely i felt that before I had that sort of guidance I was just kind of fumbling around in the dark reading a lot of different articles...', youtube_id='HVQ0DZOQcts', timestamp='19:40')), Claim(description=\"Structured online courses are plentiful and can significantly aid newcomers in developing essential data engineering skills. It has been noted that 'there are good courses about this', which suggests that a variety of educational resources can assist learners at all levels (HVQ0DZOQcts).\", relevance_check='This confirms the availability of structured educational resources crucial for beginners in data engineering.', reference=Reference(quote='There are good courses about this...', youtube_id='HVQ0DZOQcts', timestamp='25:04')), Claim(description='Online courses focusing on essential skills can streamline the learning experience for data engineering beginners. The growing selection of courses makes it easier for newcomers to gain the foundational knowledge needed without feeling overwhelmed.', relevance_check='This underscores the variety of learning resources available for those interested in data engineering.', reference=Reference(quote='...I felt that before I had that sort of guidance I was just kind of fumbling around in the dark...', youtube_id='HVQ0DZOQcts', timestamp='19:40'))]), ArticleSection(title='Essential Skills for Data Engineers', claims=[Claim(description='Coding skills are emphasized as the most important for success in data engineering. An expert highlights that without strong coding abilities, one may struggle to manage the complexities of data projects (yg3d1lFd7Uo).', relevance_check='This indicates that fundamental programming knowledge is paramount for aspirants in the field.', reference=Reference(quote='...most important one is coding skills...', youtube_id='yg3d1lFd7Uo', timestamp='11:33')), Claim(description='Understanding databases is another crucial skill for data engineers. Proficiency in writing queries and optimizing them for performance across various database types, including SQL and NoSQL, is essential for adapting to different project needs.', relevance_check='This reinforces the idea that database knowledge is fundamental for anyone starting in data engineering.', reference=Reference(quote=\"...writing queries being able to optimize them usually it's a sql databases sometimes no sql...\", youtube_id='yg3d1lFd7Uo', timestamp='11:30'))]), ArticleSection(title='Tools and Technologies in Data Engineering', claims=[Claim(description='An understanding of various tools and technologies used in data engineering is crucial. Data engineers often utilize different tools that serve distinct purposes within data processing workflows, and familiarity with these tools is essential for effective job performance (yg3d1lFd7Uo).', relevance_check='This provides insight into the range of tools that are vital for data engineering tasks.', reference=Reference(quote='...you can see them as tools solving different pieces of the puzzle.', youtube_id='yg3d1lFd7Uo', timestamp='38:24')), Claim(description=\"Familiarity with specific platforms can enhance a data engineer's skill set. Many engineers are now adopting cloud-based solutions and open-source tools which are becoming industry standards in data engineering practices.\", relevance_check='This signals the importance of staying updated with modern tools and technologies that shape the data engineering landscape.', reference=Reference(quote='...tools solving different pieces of the puzzle.', youtube_id='yg3d1lFd7Uo', timestamp='38:24'))]), ArticleSection(title='Practical Projects for Beginners', claims=[Claim(description='Engaging in practical projects using real-time datasets is highly recommended among experts as a way for beginners to application their learning. For instance, working with car parking data collected in real-time is introduced as a relevant project that allows learners to implement their skills (VXQIGHUWeL0).', relevance_check='This illustrates a concrete example of a beginner-friendly data engineering project that facilitates learning and application.', reference=Reference(quote='...one useful data set could be car parking data because we collect uh car parking figures in real time...', youtube_id='VXQIGHUWeL0', timestamp='47:07')), Claim(description='A solid understanding of the entire data pipeline—from source systems to data consumption—is fundamental for aspiring data engineers. Beginners should familiarize themselves with where data originates and how it is processed and utilized later (yg3d1lFd7Uo).', relevance_check='This establishes the need for a comprehensive grasp of the workflow within data engineering.', reference=Reference(quote='...first if you start with the source systems where data exists right it could be relational database flat files cloud s3...', youtube_id='yg3d1lFd7Uo', timestamp='58:12'))]), ArticleSection(title='Networking and Mentorship Opportunities', claims=[Claim(description='Networking is essential for establishing mentorship relationships, which are vital for career development in data engineering. As the process unfolds, leveraging resources like LinkedIn for outreach can help forge valuable connections.', relevance_check='This provides actionable steps for finding mentorship that strengthens professional networks in data engineering.', reference=Reference(quote='...getting those Mentor roles is typically just through reach outs...', youtube_id='3TTu-hYzxeg', timestamp='48:30'))]), ArticleSection(title='Preparing for Data Engineering Interviews', claims=[Claim(description='Understanding what to expect during interviews based on company-specific demands is crucial for success. In preparation, candidates are encouraged to ask about interview expectations to tailor their preparation accordingly (NnZjlMowkWA).', relevance_check='This emphasizes a strategic approach to interview preparation, ensuring candidates align their focus with specific company needs.', reference=Reference(quote=\"...what are the expectations of the individual customers that we're trying to work with...\", youtube_id='NnZjlMowkWA', timestamp='44:43'))])], action_points=[ActionPoint(point='Seek structured guidance through courses or mentorship.', relevance_check='As identified, having direction significantly aids the learning process for data engineering newcomers.', reference=Reference(quote='so definitely i felt that before I had that sort of guidance I was just kind of fumbling around in the dark...', youtube_id='HVQ0DZOQcts', timestamp='19:40')), ActionPoint(point='Prioritize developing core coding and database skills.', relevance_check='Experts agree that mastering coding and database management is fundamental to success in data engineering roles.', reference=Reference(quote='...most important one is coding skills...', youtube_id='yg3d1lFd7Uo', timestamp='11:33')), ActionPoint(point='Engage in practical projects to enhance learning.', relevance_check='Practical experience with real-time data helps bridge the gap between theoretical knowledge and application.', reference=Reference(quote='...one useful data set could be car parking data because we collect uh car parking figures in real time...', youtube_id='VXQIGHUWeL0', timestamp='47:07'))], conclusion=\"Overall, aspiring data engineers should pursue a structured learning path that incorporates technical skills, practical experience, and networking opportunities. Emphasizing coding mastery, active engagement in meaningful projects, and the importance of mentorship can greatly enhance one's readiness to successfully enter the data engineering profession.\")))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthesizer_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aeaf124c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Article(title='A Structured Learning Path for Aspiring Data Engineers', introduction='Data engineering is a critical field that underpins the modern data-driven world. As organizations increasingly rely on data for decision-making, the demand for skilled data engineers has surged. This article seeks to provide a structured learning path for those looking to start a career in data engineering, emphasizing essential skills, tools, and resources.', sections=[ArticleSection(title='The Importance of Guidance for Beginners', claims=[Claim(description=\"For beginners in data engineering, having structured guidance is crucial. As one expert noted, prior to receiving direction, many individuals feel like they are 'fumbling around in the dark,' which can lead to confusion and frustration. This highlights the necessity of finding a clear learning path to navigate the complexities of data engineering (HVQ0DZOQcts).\", relevance_check='This insight emphasizes how critical a structured approach is for effective learning in data engineering.', reference=Reference(quote='so definitely i felt that before I had that sort of guidance I was just kind of fumbling around in the dark reading a lot of different articles...', youtube_id='HVQ0DZOQcts', timestamp='19:40')), Claim(description=\"Structured online courses are plentiful and can significantly aid newcomers in developing essential data engineering skills. It has been noted that 'there are good courses about this', which suggests that a variety of educational resources can assist learners at all levels (HVQ0DZOQcts).\", relevance_check='This confirms the availability of structured educational resources crucial for beginners in data engineering.', reference=Reference(quote='There are good courses about this...', youtube_id='HVQ0DZOQcts', timestamp='25:04')), Claim(description='Online courses focusing on essential skills can streamline the learning experience for data engineering beginners. The growing selection of courses makes it easier for newcomers to gain the foundational knowledge needed without feeling overwhelmed.', relevance_check='This underscores the variety of learning resources available for those interested in data engineering.', reference=Reference(quote='...I felt that before I had that sort of guidance I was just kind of fumbling around in the dark...', youtube_id='HVQ0DZOQcts', timestamp='19:40'))]), ArticleSection(title='Essential Skills for Data Engineers', claims=[Claim(description='Coding skills are emphasized as the most important for success in data engineering. An expert highlights that without strong coding abilities, one may struggle to manage the complexities of data projects (yg3d1lFd7Uo).', relevance_check='This indicates that fundamental programming knowledge is paramount for aspirants in the field.', reference=Reference(quote='...most important one is coding skills...', youtube_id='yg3d1lFd7Uo', timestamp='11:33')), Claim(description='Understanding databases is another crucial skill for data engineers. Proficiency in writing queries and optimizing them for performance across various database types, including SQL and NoSQL, is essential for adapting to different project needs.', relevance_check='This reinforces the idea that database knowledge is fundamental for anyone starting in data engineering.', reference=Reference(quote=\"...writing queries being able to optimize them usually it's a sql databases sometimes no sql...\", youtube_id='yg3d1lFd7Uo', timestamp='11:30'))]), ArticleSection(title='Tools and Technologies in Data Engineering', claims=[Claim(description='An understanding of various tools and technologies used in data engineering is crucial. Data engineers often utilize different tools that serve distinct purposes within data processing workflows, and familiarity with these tools is essential for effective job performance (yg3d1lFd7Uo).', relevance_check='This provides insight into the range of tools that are vital for data engineering tasks.', reference=Reference(quote='...you can see them as tools solving different pieces of the puzzle.', youtube_id='yg3d1lFd7Uo', timestamp='38:24')), Claim(description=\"Familiarity with specific platforms can enhance a data engineer's skill set. Many engineers are now adopting cloud-based solutions and open-source tools which are becoming industry standards in data engineering practices.\", relevance_check='This signals the importance of staying updated with modern tools and technologies that shape the data engineering landscape.', reference=Reference(quote='...tools solving different pieces of the puzzle.', youtube_id='yg3d1lFd7Uo', timestamp='38:24'))]), ArticleSection(title='Practical Projects for Beginners', claims=[Claim(description='Engaging in practical projects using real-time datasets is highly recommended among experts as a way for beginners to application their learning. For instance, working with car parking data collected in real-time is introduced as a relevant project that allows learners to implement their skills (VXQIGHUWeL0).', relevance_check='This illustrates a concrete example of a beginner-friendly data engineering project that facilitates learning and application.', reference=Reference(quote='...one useful data set could be car parking data because we collect uh car parking figures in real time...', youtube_id='VXQIGHUWeL0', timestamp='47:07')), Claim(description='A solid understanding of the entire data pipeline—from source systems to data consumption—is fundamental for aspiring data engineers. Beginners should familiarize themselves with where data originates and how it is processed and utilized later (yg3d1lFd7Uo).', relevance_check='This establishes the need for a comprehensive grasp of the workflow within data engineering.', reference=Reference(quote='...first if you start with the source systems where data exists right it could be relational database flat files cloud s3...', youtube_id='yg3d1lFd7Uo', timestamp='58:12'))]), ArticleSection(title='Networking and Mentorship Opportunities', claims=[Claim(description='Networking is essential for establishing mentorship relationships, which are vital for career development in data engineering. As the process unfolds, leveraging resources like LinkedIn for outreach can help forge valuable connections.', relevance_check='This provides actionable steps for finding mentorship that strengthens professional networks in data engineering.', reference=Reference(quote='...getting those Mentor roles is typically just through reach outs...', youtube_id='3TTu-hYzxeg', timestamp='48:30'))]), ArticleSection(title='Preparing for Data Engineering Interviews', claims=[Claim(description='Understanding what to expect during interviews based on company-specific demands is crucial for success. In preparation, candidates are encouraged to ask about interview expectations to tailor their preparation accordingly (NnZjlMowkWA).', relevance_check='This emphasizes a strategic approach to interview preparation, ensuring candidates align their focus with specific company needs.', reference=Reference(quote=\"...what are the expectations of the individual customers that we're trying to work with...\", youtube_id='NnZjlMowkWA', timestamp='44:43'))])], action_points=[ActionPoint(point='Seek structured guidance through courses or mentorship.', relevance_check='As identified, having direction significantly aids the learning process for data engineering newcomers.', reference=Reference(quote='so definitely i felt that before I had that sort of guidance I was just kind of fumbling around in the dark...', youtube_id='HVQ0DZOQcts', timestamp='19:40')), ActionPoint(point='Prioritize developing core coding and database skills.', relevance_check='Experts agree that mastering coding and database management is fundamental to success in data engineering roles.', reference=Reference(quote='...most important one is coding skills...', youtube_id='yg3d1lFd7Uo', timestamp='11:33')), ActionPoint(point='Engage in practical projects to enhance learning.', relevance_check='Practical experience with real-time data helps bridge the gap between theoretical knowledge and application.', reference=Reference(quote='...one useful data set could be car parking data because we collect uh car parking figures in real time...', youtube_id='VXQIGHUWeL0', timestamp='47:07'))], conclusion=\"Overall, aspiring data engineers should pursue a structured learning path that incorporates technical skills, practical experience, and networking opportunities. Emphasizing coding mastery, active engagement in meaningful projects, and the importance of mentorship can greatly enhance one's readiness to successfully enter the data engineering profession.\")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthesizer_results.output.article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a280930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = synthesizer_results.output.article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "069df759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_link(reference) -> str:\n",
    "    \"\"\"\n",
    "    Converts the timestamp to a YouTube URL with a proper time offset.\n",
    "    Supports both 'h:mm:ss' and 'mm:ss' formats.\n",
    "    \"\"\"\n",
    "    if not reference.timestamp:\n",
    "        return f\"https://www.youtube.com/watch?v={reference.youtube_id}\"\n",
    "\n",
    "    ts = reference.timestamp.strip()\n",
    "    if not ts:\n",
    "        return f\"https://www.youtube.com/watch?v={reference.youtube_id}\"\n",
    "\n",
    "    parts = ts.split(\":\")\n",
    "\n",
    "    try:\n",
    "        parts = [int(p) for p in parts]\n",
    "    except ValueError:\n",
    "        return f\"https://www.youtube.com/watch?v={reference.youtube_id}\"\n",
    "\n",
    "    if len(parts) == 3: # h:mm:ss\n",
    "        hours, minutes, seconds = parts\n",
    "    elif len(parts) == 2: # mm:ss\n",
    "        hours, minutes, seconds = 0, parts[0], parts[1]\n",
    "    elif len(parts) == 1:\n",
    "        hours, minutes, seconds = 0, 0, parts[0]\n",
    "\n",
    "    total_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "    return f\"https://www.youtube.com/watch?v={reference.youtube_id}&t={total_seconds}s\"\n",
    "\n",
    "def diplay_reference(reference: Reference): \n",
    "    return f\"[{reference.quote}]({to_link(reference)})\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7bff34c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: 1\n",
      "  keyword: data engineering learning path for beginners\n",
      "  summary: The importance of guidance for beginners in data engineering was highlighted.\n",
      "  references: ['[so definitely i felt that before I had that sort of guidance I was just kind of fumbling around in the dark reading a lot of different articles...](https://www.youtube.com/watch?v=HVQ0DZOQcts&t=1180s)']\n",
      "  keyword: essential skills for data engineers\n",
      "  summary: Experts consider coding skills fundamental for success in data engineering.\n",
      "  references: ['[I would say the most important one is coding skills...](https://www.youtube.com/watch?v=yg3d1lFd7Uo&t=693s)']\n",
      "  keyword: best online courses for data engineering\n",
      "  summary: Numerous online courses are available that focus on various skills fundamental to data engineering.\n",
      "  references: ['[There are good courses about this...](https://www.youtube.com/watch?v=HVQ0DZOQcts&t=1504s)']\n",
      "  keyword: data engineering tools and technologies\n",
      "  summary: Understanding various tools used in data engineering is necessary for practical applications in the field.\n",
      "  references: ['[...you can see them as tools solving different pieces of the puzzle.](https://www.youtube.com/watch?v=yg3d1lFd7Uo&t=2304s)']\n",
      "  keyword: step-by-step guide to becoming a data engineer\n",
      "  summary: A successful transition into data engineering entails acquiring a new set of skills amidst shifting data paradigms.\n",
      "  references: ['[...you have to acquire a new skill set but when this data paradigm is shifting right...](https://www.youtube.com/watch?v=FljnbUQ796w&t=242s)']\n",
      "The initial research stage identified essential resources and guidance needed for beginners venturing into data engineering. Key themes included the importance of structured guidance, coding as a fundamental skill, available online courses, tools in data engineering, and the skill sets necessary for effective transition into the field.\n",
      "Stage: 2\n",
      "  keyword: data engineering projects for beginners\n",
      "  summary: Practical projects suggested for beginners include utilizing real-time datasets like car parking data.\n",
      "  references: ['[...one useful data set could be car parking data because we collect uh car parking figures in real time...](https://www.youtube.com/watch?v=VXQIGHUWeL0&t=2827s)', '[...first if you start with the source systems where data exists right it could be relational database flat files cloud s3...](https://www.youtube.com/watch?v=yg3d1lFd7Uo&t=3492s)']\n",
      "  keyword: advanced data engineering skills\n",
      "  summary: Advanced coding and software engineering skills are necessary for effective data pipeline management.\n",
      "  references: [\"[...there's often a lot of pipelining work that you do on yourself.](https://www.youtube.com/watch?v=3TTu-hYzxeg&t=633s)\", '[I would say that coding skills...is also important...](https://www.youtube.com/watch?v=yg3d1lFd7Uo&t=2820s)']\n",
      "  keyword: mentorship opportunities in data engineering\n",
      "  summary: Networking is crucial for finding mentorship, enabling career growth and development in data engineering.\n",
      "  references: ['[...getting those Mentor roles is typically just through reach outs...](https://www.youtube.com/watch?v=3TTu-hYzxeg&t=2910s)', '[...find somebody in your company in your workplace for this kind of relationships](https://www.youtube.com/watch?v=FljnbUQ796w&t=2010s)']\n",
      "  keyword: real-world applications of data engineering\n",
      "  summary: Various sectors benefit from data engineering, including healthcare and urban planning.\n",
      "  references: [\"[...it's important for doctors...to understand...](https://www.youtube.com/watch?v=3TTu-hYzxeg&t=2230s)\", '[...one useful data set could be car parking data...](https://www.youtube.com/watch?v=VXQIGHUWeL0&t=2827s)']\n",
      "The second stage brought to light several beginner-friendly projects while emphasizing the need for advanced skills and networking opportunities. Recognizing real-world applications of data engineering solidified the value and relevance of practical experience for beginners.\n",
      "Stage: 3\n",
      "  keyword: data engineering certifications\n",
      "  summary: Certifications can validate skills, enhancing credibility in the competitive data engineering job market.\n",
      "  references: ['[we might as well get some certifications for those students](https://www.youtube.com/watch?v=yg3d1lFd7Uo&t=1976s)', '[...people are looking for soft skills...](https://www.youtube.com/watch?v=FljnbUQ796w&t=1099s)']\n",
      "  keyword: transitioning from academic to professional in data engineering\n",
      "  summary: Adaptation to industry practices and necessary skills is vital for academic professionals entering the data engineering field.\n",
      "  references: ['[...become more comfortable working with your command line...](https://www.youtube.com/watch?v=FljnbUQ796w&t=3622s)', '[...you need to set up the infrastructure for building models...](https://www.youtube.com/watch?v=yg3d1lFd7Uo&t=1776s)']\n",
      "  keyword: data engineering interview preparation\n",
      "  summary: Focusing preparation on company-specific demands is crucial for successful data engineering interviews.\n",
      "  references: [\"[...what are the expectations of the individual customers that we're trying to work with...](https://www.youtube.com/watch?v=NnZjlMowkWA&t=2683s)\", '[The questions... would practice questions...](https://www.youtube.com/watch?v=NnZjlMowkWA&t=2637s)']\n",
      "The third research stage further solidified the importance of professional skills, including certifications and effective preparation for interviews. Recognizing the shift from academic settings to professional environments was also emphasized as a pivotal aspect for upcoming data engineers.\n",
      "# A Structured Learning Path for Aspiring Data Engineers\n",
      "## Introduction\n",
      "Data engineering is a critical field that underpins the modern data-driven world. As organizations increasingly rely on data for decision-making, the demand for skilled data engineers has surged. This article seeks to provide a structured learning path for those looking to start a career in data engineering, emphasizing essential skills, tools, and resources.\n",
      "## The Importance of Guidance for Beginners\n",
      "For beginners in data engineering, having structured guidance is crucial. As one expert noted, prior to receiving direction, many individuals feel like they are 'fumbling around in the dark,' which can lead to confusion and frustration. This highlights the necessity of finding a clear learning path to navigate the complexities of data engineering (HVQ0DZOQcts). ( [so definitely i felt that before I had that sort of guidance I was just kind of fumbling around in the dark reading a lot of different articles...](https://www.youtube.com/watch?v=HVQ0DZOQcts&t=1180s) )\n",
      "Structured online courses are plentiful and can significantly aid newcomers in developing essential data engineering skills. It has been noted that 'there are good courses about this', which suggests that a variety of educational resources can assist learners at all levels (HVQ0DZOQcts). ( [There are good courses about this...](https://www.youtube.com/watch?v=HVQ0DZOQcts&t=1504s) )\n",
      "Online courses focusing on essential skills can streamline the learning experience for data engineering beginners. The growing selection of courses makes it easier for newcomers to gain the foundational knowledge needed without feeling overwhelmed. ( [...I felt that before I had that sort of guidance I was just kind of fumbling around in the dark...](https://www.youtube.com/watch?v=HVQ0DZOQcts&t=1180s) )\n",
      "## Essential Skills for Data Engineers\n",
      "Coding skills are emphasized as the most important for success in data engineering. An expert highlights that without strong coding abilities, one may struggle to manage the complexities of data projects (yg3d1lFd7Uo). ( [...most important one is coding skills...](https://www.youtube.com/watch?v=yg3d1lFd7Uo&t=693s) )\n",
      "Understanding databases is another crucial skill for data engineers. Proficiency in writing queries and optimizing them for performance across various database types, including SQL and NoSQL, is essential for adapting to different project needs. ( [...writing queries being able to optimize them usually it's a sql databases sometimes no sql...](https://www.youtube.com/watch?v=yg3d1lFd7Uo&t=690s) )\n",
      "## Tools and Technologies in Data Engineering\n",
      "An understanding of various tools and technologies used in data engineering is crucial. Data engineers often utilize different tools that serve distinct purposes within data processing workflows, and familiarity with these tools is essential for effective job performance (yg3d1lFd7Uo). ( [...you can see them as tools solving different pieces of the puzzle.](https://www.youtube.com/watch?v=yg3d1lFd7Uo&t=2304s) )\n",
      "Familiarity with specific platforms can enhance a data engineer's skill set. Many engineers are now adopting cloud-based solutions and open-source tools which are becoming industry standards in data engineering practices. ( [...tools solving different pieces of the puzzle.](https://www.youtube.com/watch?v=yg3d1lFd7Uo&t=2304s) )\n",
      "## Practical Projects for Beginners\n",
      "Engaging in practical projects using real-time datasets is highly recommended among experts as a way for beginners to application their learning. For instance, working with car parking data collected in real-time is introduced as a relevant project that allows learners to implement their skills (VXQIGHUWeL0). ( [...one useful data set could be car parking data because we collect uh car parking figures in real time...](https://www.youtube.com/watch?v=VXQIGHUWeL0&t=2827s) )\n",
      "A solid understanding of the entire data pipeline—from source systems to data consumption—is fundamental for aspiring data engineers. Beginners should familiarize themselves with where data originates and how it is processed and utilized later (yg3d1lFd7Uo). ( [...first if you start with the source systems where data exists right it could be relational database flat files cloud s3...](https://www.youtube.com/watch?v=yg3d1lFd7Uo&t=3492s) )\n",
      "## Networking and Mentorship Opportunities\n",
      "Networking is essential for establishing mentorship relationships, which are vital for career development in data engineering. As the process unfolds, leveraging resources like LinkedIn for outreach can help forge valuable connections. ( [...getting those Mentor roles is typically just through reach outs...](https://www.youtube.com/watch?v=3TTu-hYzxeg&t=2910s) )\n",
      "## Preparing for Data Engineering Interviews\n",
      "Understanding what to expect during interviews based on company-specific demands is crucial for success. In preparation, candidates are encouraged to ask about interview expectations to tailor their preparation accordingly (NnZjlMowkWA). ( [...what are the expectations of the individual customers that we're trying to work with...](https://www.youtube.com/watch?v=NnZjlMowkWA&t=2683s) )\n",
      "## Action Points\n",
      "* Seek structured guidance through courses or mentorship. [so definitely i felt that before I had that sort of guidance I was just kind of fumbling around in the dark...](https://www.youtube.com/watch?v=HVQ0DZOQcts&t=1180s)\n",
      "* Prioritize developing core coding and database skills. [...most important one is coding skills...](https://www.youtube.com/watch?v=yg3d1lFd7Uo&t=693s)\n",
      "* Engage in practical projects to enhance learning. [...one useful data set could be car parking data because we collect uh car parking figures in real time...](https://www.youtube.com/watch?v=VXQIGHUWeL0&t=2827s)\n",
      "## Conclusion\n",
      "Overall, aspiring data engineers should pursue a structured learning path that incorporates technical skills, practical experience, and networking opportunities. Emphasizing coding mastery, active engagement in meaningful projects, and the importance of mentorship can greatly enhance one's readiness to successfully enter the data engineering profession.\n"
     ]
    }
   ],
   "source": [
    "report = synthesizer_results.output\n",
    "\n",
    "# Display stage-by-stage findings\n",
    "for stage in report.stages:\n",
    "    print('Stage:', stage.stage)\n",
    "    for kw in stage.keywords:\n",
    "        print('  keyword:', kw.search_keyword)\n",
    "        print('  summary:', kw.summary)\n",
    "        print('  references:', [diplay_reference(r) for r in kw.references])\n",
    "    print(stage.summary)\n",
    "\n",
    "# Display the final article\n",
    "article = report.article\n",
    "print('#', article.title)\n",
    "print('## Introduction')\n",
    "print(article.introduction)\n",
    "\n",
    "for section in article.sections:\n",
    "    print('##', section.title)\n",
    "    for claim in section.claims:\n",
    "        print(claim.description, '(', diplay_reference(claim.reference), ')')\n",
    "\n",
    "print('## Action Points')\n",
    "for action_point in article.action_points:\n",
    "    print('*', action_point.point, diplay_reference(action_point.reference))\n",
    "\n",
    "print('## Conclusion')\n",
    "print(article.conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc7d98",
   "metadata": {},
   "source": [
    "# Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7bf64443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import RunContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "13bbd703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_messages(messages):\n",
    "    contents = []\n",
    "    \n",
    "    for m in messages:\n",
    "        print(m.kind)\n",
    "\n",
    "        for p in m.parts:\n",
    "            print(p.part_kind)\n",
    "            kind = p.part_kind\n",
    "            if kind == 'user-prompt' or kind == 'text':\n",
    "                print(p.content)\n",
    "            if kind == 'tool-call': \n",
    "                print(p.tool_name, p.args)\n",
    "            if kind == 'tool-return':\n",
    "                print(type(p.content), p.content)\n",
    "            print()\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "255048a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator_instructions = \"\"\"\n",
    "first, ask user an initial question via clarifier (clarify_tool_initial)\n",
    "then formulate requiremets for the researcher (clarify_tool_research_task)\n",
    "then execute research via researcher in three stages: 1, 2, 3 (reserch_tool)\n",
    "each research step should be done after the previous one is completed\n",
    "\n",
    "make it timeless: don't add years to queries. for example:\n",
    "\"learning machine learning\" is better than \"learning machine learning in 2023\"\n",
    "\n",
    "when the resarch it ready, output a short summary of the research\n",
    "\"\"\"\n",
    "\n",
    "orchestrator = Agent(\n",
    "    name='orchestrator',\n",
    "    instructions=orchestrator_instructions,\n",
    "    model='gpt-4o-mini',\n",
    ")\n",
    "\n",
    "orchestrator_callback = NamedCallback(orchestrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b5482eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@orchestrator.tool\n",
    "async def clarify_tool_initial(ctx: RunContext, query: str) -> str:\n",
    "    \"\"\"Runs the clarifier once to interpret the user's request.\n",
    "\n",
    "    Args:\n",
    "        query: Raw user question.\n",
    "\n",
    "    Returns:\n",
    "        A short text summary describing the user's intent.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Clarifier (Initial) ===\")\n",
    "    callback = NamedCallback(clarifier)\n",
    "    results = await clarifier.run(user_prompt=query, event_stream_handler=callback)\n",
    "    return results.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "efafef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "@orchestrator.tool\n",
    "async def clarify_tool_research_task(ctx: RunContext, query: str) -> ResearchInstructions:\n",
    "    \"\"\"Runs the clarifier again using both the user query and prior clarifier output\n",
    "    to create a structured ResearchInstructions object.\n",
    "\n",
    "    Args:\n",
    "        query: User's original question.\n",
    "\n",
    "    Returns:\n",
    "        ResearchInstructions with refined request, intent, and search queries.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Clarifier (Research Task) ===\")\n",
    "    prior_outputs = []\n",
    "    for m in ctx.messages:\n",
    "        for p in m.parts:\n",
    "            if p.part_kind == \"tool-return\" and p.tool_name == \"clarify_tool_initial\":\n",
    "                prior_outputs.append(p.content)\n",
    "\n",
    "    prior_text = \"\\n\".join(str(x) for x in prior_outputs)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    User query:\n",
    "    {query}\n",
    "    \n",
    "    Prior clarification:\n",
    "    {prior_text}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    callback = NamedCallback(clarifier)\n",
    "\n",
    "    results = await clarifier.run(\n",
    "        user_prompt=prompt,\n",
    "        event_stream_handler=callback,\n",
    "        output_type=ResearchInstructions\n",
    "    )\n",
    "\n",
    "    return results.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f384a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "@orchestrator.tool\n",
    "async def research_tool(ctx: RunContext, stage: int, stage_instructions: str) -> ResearchStageReport:\n",
    "    \"\"\"Runs one stage of research using prior reports as context.\n",
    "\n",
    "    Args:\n",
    "        stage: Research stage number (1–3).\n",
    "        stage_instructions: Description of what this stage should focus on.\n",
    "\n",
    "    Returns:\n",
    "        ResearchStageReport with insights, references, and next steps.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== RESEARCH stage {stage} ===\")\n",
    "    \n",
    "    prior_reports: List[ResearchStageReport] = []\n",
    "\n",
    "    for m in ctx.messages:\n",
    "        for p in m.parts:\n",
    "            if p.part_kind == \"tool-return\" and p.tool_name == \"research_tool\":\n",
    "                if isinstance(p.content, ResearchStageReport):\n",
    "                    prior_reports.append(p.content)\n",
    "    \n",
    "    result = await do_research(\n",
    "        stage=stage,\n",
    "        stage_instructions=stage_instructions,\n",
    "        previous_stages=prior_reports,\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "43c9413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3fc9341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how do I get started with data engineering?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cc198b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALL → clarify_tool_initial {'query': 'how do I get started with data engineering?'} call_04XrqlBrj5fDygEFmZe4RgEB\n",
      "\n",
      "=== Clarifier (Initial) ===\n",
      "RES  ← clarify_tool_initial call_04XrqlBrj5fDygEFmZe4RgEB To help clarify your request, could you please specify what aspect of getting started with data engineering you are most interested in? For example, are you looking for educational resources, specific skills to learn, job opportunities, or practical projects to undertake?\n"
     ]
    }
   ],
   "source": [
    "orchestrator_results = await orchestrator.run(\n",
    "    user_prompt=question,\n",
    "    message_history=message_history,\n",
    "    event_stream_handler=orchestrator_callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "79ce52ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request\n",
      "user-prompt\n",
      "how do I get started with data engineering?\n",
      "\n",
      "\n",
      "response\n",
      "tool-call\n",
      "clarify_tool_initial {\"query\":\"how do I get started with data engineering?\"}\n",
      "\n",
      "\n",
      "request\n",
      "tool-return\n",
      "<class 'str'> To help clarify your request, could you please specify what aspect of getting started with data engineering you are most interested in? For example, are you looking for educational resources, specific skills to learn, job opportunities, or practical projects to undertake?\n",
      "\n",
      "\n",
      "response\n",
      "text\n",
      "What aspect of getting started with data engineering are you most interested in? For example, are you looking for educational resources, specific skills to learn, job opportunities, or practical projects to undertake?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = orchestrator_results.new_messages()\n",
    "message_history.extend(messages)\n",
    "print_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b71540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b7374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALL → clarify_tool_initial {'query': 'How do I learn about data science'} call_OFnvlmWvHMpgzI86BPLhGiAB\n",
      "\n",
      "=== Clarifier (Initial) ===\n",
      "RES  ← clarify_tool_initial call_OFnvlmWvHMpgzI86BPLhGiAB To refine your request, could you please clarify what specific aspects of data science you're interested in? For example, are you looking for resources (courses, books), learning paths, practical projects, or something else?\n",
      "request\n",
      "user-prompt\n",
      "How do I learn about data science\n",
      "\n",
      "\n",
      "response\n",
      "tool-call\n",
      "clarify_tool_initial {\"query\":\"How do I learn about data science\"}\n",
      "\n",
      "\n",
      "request\n",
      "tool-return\n",
      "<class 'str'> To refine your request, could you please clarify what specific aspects of data science you're interested in? For example, are you looking for resources (courses, books), learning paths, practical projects, or something else?\n",
      "\n",
      "\n",
      "response\n",
      "text\n",
      "What specific aspects of data science are you interested in? For example, are you looking for resources (courses, books), learning paths, practical projects, or something else?\n",
      "\n",
      "\n",
      "CALL → clarify_tool_research_task {'query': 'How do I learn about data science with a focus on practical projects'} call_dGDqoyWasfUXnadx2Wu6n3st\n",
      "\n",
      "=== Clarifier (Research Task) ===\n",
      "RES  ← clarify_tool_research_task call_dGDqoyWasfUXnadx2Wu6n3st initial_request='How do I learn about data science with a focus on practical projects' refined_request='I want to learn about data science focusing on practical projects and the resources needed for that.' user_intent='The user wants to learn data science through hands-on projects and needs information about relevant resources and learning paths.' queries=['best data science courses with practical projects', 'data science project ideas for beginners', 'top resources for hands-on data science learning', 'data science bootcamps focusing on practical experience', 'how to apply data science skills in real-world projects'] instructions='Explore resources including courses, tutorials, and project ideas that emphasize practical applications of data science.'\n",
      "CALL → research_tool {'stage': 1, 'stage_instructions': 'Explore resources including courses, tutorials, and project ideas that emphasize practical applications of data science.'} call_8VJVerxhMdhJcAoN6YXrnaSm\n",
      "\n",
      "=== RESEARCH stage 1 ===\n",
      "CALL → search {'query': 'practical applications of data science courses tutorials project ideas'} call_lk3mineB1eJDLurllCO3NDOw\n",
      "RES  ← search call_lk3mineB1eJDLurllCO3NDOw [{'start': 3000, 'content': \"2:49 conferences mostly in and around\\n2:51 Amsterdam with by data\\n2:54 so what did you do as a data science\\n2:56 indicator you said you your\\n2:59 responsibilities included creating\\n3:01 courses yes that's good yeah yeah so at\\n3:05 the code 80 Driven Academy we teach a\\n3:07 lot of courses on every thing data\\n3:09 science so some are very generic like an\\n3:11 introduction to python for data analysts\\n3:14 or an introduction to data science for\\n3:17 instance but we also create a lot of\\n3:20 courses very specifically targeted\\n3:21 towards a specific audience so for\\n3:23 instance I created a deep learning with\\n3:25 NLP course or a an unsupervised learning\\n3:28 course and those are more detailed or\\n3:30 more specific topics and then gave me an\\n3:32 opportunity to really dive into that\\n3:34 topic and create good exercises and\\n3:36 assignments and material on that that\\n3:38 was really fun yeah I think I spoke with\\n3:41 folks from your company from go data\\n3:43 driven at the restaurant by data by Con\\n3:46 in Berlin and as far as I remember\\n3:49 you're doing education and consultancy\\n3:52 right that's yeah\\n3:54 so I was mostly a data science educator\\n3:57 for about two years but I strongly\\n4:00 believe that you can't be a good teacher\\n4:02 if you don't also have hands-on\\n4:03 experience so I I like to really when I\\n4:06 do courses or when I teach courses\\n4:08 really tell a lot of anecdotes about my\\n4:11 experiences and in my work because it\\n4:14 speaks more to the imagination of why\\n4:15 we're doing this than just talking about\\n4:17 the concepts so while I really enjoyed\\n4:20 it I do feel like after two years mostly\\n4:22 focusing on the educational side I I\\n4:25 need some hands-on experience and also I\\n4:27 was really missing this decoding bit so\\n4:29 that's uh so so the ideal situation for\\n4:32 me is to do both trainings and education\\n4:34 and also work as a data scientist and\\n4:37 combine that in some way do you still\\n4:40 teach\\n4:42 uh occasionally some courses but I'm\\n4:44 more focused on my lead data science\\n4:46 role at the moment\\n4:47 what do you do as a lead data scientist\\n4:51 um I'm with a company where\\n4:53 um I'm mostly focused on building a\\n4:55 community of practice there they just\\n4:57 went through a transition in their the\\n4:59 way that they organize their teams and I\\n5:01 want to make sure that all the data\\n5:03 scientists still communicate clearly\\n5:05 with each other get to exchange\\n5:06 knowledge but also increase the maturity\\n5:09 level of the data science products that\\n5:10 we produce so make sure that we are not\\n5:13 just everyone doing something on their\\n5:15 own time behind their own laptop but\\n5:17 bringing them together make sure that we\\n5:18 actually get to mature well-functioning\\n5:21 monitored data science products\\n5:24 yeah this is such an interesting topic\\n5:25 but I'm afraid or I want to ask more\\n5:29 about that intent if we run out of\\n5:31 questions uh yeah because the the main\\n5:33 topic for today is actually data center\\n5\", 'video_id': 't3HDdVWQzNM', '_id': 6132}, {'start': 1500, 'content': \"k we'll talk about data\\n1:28 Centric Ai and we have a special guest\\n1:30 today Marisha Marisha works as a lead\\n1:32 data scientist at go data driven she has\\n1:35 a strong interest in education and\\n1:37 teaching both as a part of your current\\n1:39 role at code data driven and also as a\\n1:42 co-organizer of Pi date Amsterdam and Pi\\n1:44 data Global welcome\\n1:46 yeah nice thank you for having me\\n1:49 the questions for today's interview were\\n1:51 prepared by Johanna buyer thanks Johanna\\n1:53 for your help so before we go into our\\n1:56 main topic of data Centric a let's start\\n1:59 with your background\\n2:00 can you tell us about your career\\n2:01 Journey so far\\n2:03 yeah sure\\n2:04 um so I started by studying artificial\\n2:07 intelligence at the University of\\n2:09 Amsterdam I did both a bachelor and a\\n2:11 master in artificial intelligence and my\\n2:13 early career was focused on specifically\\n2:15 applying deep learning on medical\\n2:17 imaging particularly early stage lung\\n2:20 cancer detection in 3D CT scans\\n2:23 and within that domain my focus was on\\n2:25 geometric deep learning on the medical\\n2:27 domain which was also the topic of my\\n2:29 master thesis supervised by maxwelling\\n2:31 but after that I transitioned into the\\n2:34 role of data science educator I go data\\n2:36 driven which meant that I taught and\\n2:39 created courses on basically all things\\n2:41 data science and now I work as a lead\\n2:44 data scientist at code 80 driven and in\\n2:47 addition to that I organized meetups and\\n2:49 conferences mostly in and around\\n2:51 Amsterdam with by data\\n2:54 so what did you do as a data science\\n2:56 indicator you said you your\\n2:59 responsibilities included creating\\n3:01 courses yes that's good yeah yeah so at\\n3:05 the code 80 Driven Academy we teach a\\n3:07 lot of courses on every thing data\\n3:09 science so some are very generic like an\\n3:11 introduction to python for data analysts\\n3:14 or an introduction to data science for\\n3:17 instance but we also create a lot of\\n3:20 courses very specifically targeted\\n3:21 towards a specific audience so for\\n3:23 instance I created a deep learning with\\n3:25 NLP course or a an unsupervised learning\\n3:28 course and those are more detailed or\\n3:30 more specific topics and then gave me an\\n3:32 opportunity to really dive into that\\n3:34 topic and create good exercises and\\n3:36 assignments and material on that that\\n3:38 was really fun yeah I think I spoke with\\n3:41 folks from your company from go data\\n3:43 driven at the restaurant by data by Con\\n3:46 in Berlin and as far as I remember\\n3:49 you're doing education and consultancy\\n3:52 right that's yeah\\n3:54 so I was mostly a data science educator\\n3:57 for about two years but I strongly\\n4:00 believe that you can't be a good teacher\\n4:02 if you don't also have hands-on\\n4:03 experience so I I like to really when I\\n4:06 do courses or when I teach courses\\n4:08 really tell a lot of anecdotes about my\\n4:11 experiences and in my work because it\\n4:14 speaks more to the imagination of why\\n4:1\", 'video_id': 't3HDdVWQzNM', '_id': 6131}, {'start': 52500, 'content': \"etimes my bash keeps the history\\n52:13 sometimes i can just go up and see what\\n52:15 the comments but this is very unreliable\\n52:18 so often when i close my terminal all\\n52:21 the comments that i put are gone i don't\\n52:23 know why it happens but i do not rely on\\n52:25 that i put i would create like a\\n52:27 readme.md file or i would open a google\\n52:30 document or notion recently i have been\\n52:33 using notion for that and i would just\\n52:35 copy paste like from the terminal the\\n52:38 commands there\\n52:40 sometimes i would take screenshots with\\n52:42 errors and then would post there\\n52:45 and then yeah i shared a couple of\\n52:47 tutorials like that so i had these\\n52:49 documents and then i put them together\\n52:51 as docs like tutorials public tutorials\\n52:53 and shared\\n52:55 um\\n52:56 yeah i have a couple of git github repos\\n52:59 like that so maybe you can check them\\n53:03 uh one more question from the slack\\n53:05 community and then we go on to the slido\\n53:07 um so dmitrios who's a fellow organizer\\n53:10 of super communities i think he\\n53:11 organizes mvl ops community he asks\\n53:14 where do you get your community related\\n53:16 ideas from yeah i know where demetrius\\n53:20 is coming from\\n53:21 with this\\n53:24 so\\n53:25 yeah\\n53:26 i did get a few ideas let's say\\n53:29 i got inspired from the stuff demetrius\\n53:33 is doing what was doing at the envelopes\\n53:35 community so for example the podcast the\\n53:37 format we have right now\\n53:39 of doing it live with the live audience\\n53:42 so today i think this is the first time\\n53:44 when it didn't really work well because\\n53:46 of the internet problems so the first\\n53:48 time in more than a year so i think that\\n53:53 yeah i hope it doesn't repeat on friday\\n53:55 when we have another one but yeah\\n53:57 so this idea i\\n54:00 borrowed from the matrix then there are\\n54:03 some ideas\\n54:04 like for example from java ranch which\\n54:06 is a java community so they invited book\\n54:09 authors to ask them questions i also\\n54:11 brought this idea so i got a lot of\\n54:12 inspiration from other communities\\n54:15 um\\n54:16 and perhaps also added\\n54:18 a personal twist to these ideas\\n54:21 for example the minis and the open\\n54:23 source spotlight\\n54:24 yeah exactly exactly yeah but mostly it\\n54:26 comes from uh\\n54:29 some from other communities like malop's\\n54:31 community\\n54:33 and\\n54:34 from people from the community members\\n54:37 sometimes people would reach out to me\\n54:38 saying hey i have this awesome idea do\\n54:41 you want to try it and then usually yes\\n54:44 let's try it and then there are very few\\n54:47 a few initiatives like that that\\n54:48 unfortunately didn't work out well so\\n54:50 for example about networking sessions\\n54:53 but somebody reached out to me saying\\n54:55 hey it would be nice to just\\n54:57 hang out in zoom and then we started\\n54:59 with right that it didn't work out\\n55:02 but yeah this is how these things happen\\n55:06 right i think we have the last question\\n55:08 for this podcast which is from slid\", 'video_id': 'IxTyq96juVE', '_id': 3409}, {'start': 22500, 'content': \"ll\\n26:24 of them yeah so which means that um\\n26:29 let's say somebody wants to take our\\n26:32 courses they should do some of this work\\n26:34 even before they take courses right yeah\\n26:36 yeah exactly then you have more Focus\\n26:39 from the very beginning and you know\\n26:40 okay I want to focus on data engineering\\n26:42 so I take data\\n26:44 engineering and then uh yeah just after\\n26:48 the course perhaps instead of taking the\\n26:49 other courses focus on developing the\\n26:52 skills in this area focus on doing more\\n26:54 projects in this area exactly and then\\n26:57 get interviews in that area right and\\n27:00 try to understand where you stand what\\n27:02 else is needed required to get a job\\n27:05 hopefully after finishing our course you\\n27:07 get all the skills right yeah yeah but\\n27:10 sometimes some companies might require\\n27:13 something specific right that we don't\\n27:15 cover and then this is where you can\\n27:18 understand that okay yeah and then try\\n27:20 to focus on I know building a project\\n27:23 with this particular skill yeah it's\\n27:25 it's important to not get lost in doing\\n27:28 all the courses I don't know if if\\n27:29 really all of them do all uh all the\\n27:32 courses before starting a new course\\n27:34 just take some time and okay maybe have\\n27:37 a project even if so I finish data\\n27:40 engineering I do a project I do a a\\n27:43 project and I see if I enjoy doing it\\n27:46 okay I I suppose the hypothesis is\\n27:49 something that I would like but okay I\\n27:51 finish data engineering let me practice\\n27:54 let me show that I developed skills in\\n27:57 data\\n27:59 engineering and then think about another\\n28:02 course but going from uh one course to\\n28:06 another\\n28:07 is like I don't know the wor but yeah\\n28:11 it's better to avoid it like especially\\n28:14 like that's circle like you get on the\\n28:16 train of course after course after\\n28:19 course because I feel like I still don't\\n28:20 have enough qualifications but remember\\n28:24 you have also skills you have strs you\\n28:27 have experience\\n28:29 so don't forget about\\n28:32 that and when it comes to having even\\n28:35 more Focus cuz like okay we you\\n28:38 mentioned that when it comes to data\\n28:40 science it's such a broad topic it can\\n28:43 mean anything from analysts to hardcore\\n28:47 deep learning whatever right\\n28:50 um and when you read one job description\\n28:54 for data scientist it can be super\\n28:56 different from another description of\\n28:58 data scientist and the same thing with\\n29:00 data Engineers so you can be a data\\n29:01 engineer that builds a data platform you\\n29:04 can be a data engineer that helps\\n29:06 analyst you can be a data engineer that\\n29:08 works with data scientists right so\\n29:10 there are also\\n29:14 speci and like do if I already know okay\\n29:18 I want to do data science or I want to\\n29:19 do data engineering do I already should\\n29:23 I already have even more focus and think\\n29:26 okay like I want to focus on this\\n29:28 particular type of data science job or\\n29:31 \", 'video_id': 'PchwbIs0tOg', '_id': 4621}, {'start': 15000, 'content': \"have not me personally but\\n17:58 like the problem\\n18:00 that let me take a step back so in our\\n18:03 community we have courses right so right\\n18:05 now we have three courses free different\\n18:06 courses so ml engineering course data\\n18:09 engineering course and mops course while\\n18:11 the first and the last one are kind of\\n18:13 similar the data engineering course is\\n18:16 quite different so it's a different kind\\n18:17 of job right so then people take all\\n18:20 these courses so they take the\\n18:21 engineering the data engineering course\\n18:23 the ml engineering course and they say\\n18:25 okay I like all the courses M all of\\n18:29 them right what's the third so ml\\n18:31 engineering data engineering and the\\n18:33 third mops mops okay okay so and then\\n18:37 the students come and say like we took\\n18:39 the courses and we like all of them and\\n18:42 I want to do all of this stuff right and\\n18:44 this is a lot right so you cannot be you\\n18:46 cannot like you can but like it's\\n18:48 difficult to be a jack of all trades\\n18:50 right especially if you're only starting\\n18:51 your career and you you need to figure\\n18:53 out what exactly from these\\n18:57 directions where exactly do I want to go\\n19:00 and what sometimes happens\\n19:03 is the students just apply to everything\\n19:06 right so they apply to data engineering\\n19:07 position mlops position ml engineering\\n19:10 positions like all of them right yeah\\n19:14 like I am not sure if it's a good thing\\n19:17 or a bad thing maybe you can tell us but\\n19:20 I think one of the consequences of that\\n19:22 that you kind of lose focus right yeah\\n19:25 exactly so how in this situation when\\n19:28 there are so many options and because um\\n19:31 like if I try to focus then it means\\n19:34 that I\\n19:36 am kind of how to say losing\\n19:40 opportunities like I have this fear of\\n19:42 missing out that if I don't apply to\\n19:44 data engineering positions then like\\n19:46 there's a very big chunk of potential\\n19:49 jobs that I will not get because I don't\\n19:52 apply to them right so if I only apply\\n19:54 to ml engineering positions so how in\\n19:57 this case can I actually understand\\n19:59 which one is better and what is better\\n20:01 for me okay yeah the first thing so\\n20:07 taking the courses all the courses to\\n20:09 explore is good because one doesn't have\\n20:12 experience in the field so exploring\\n20:15 different um uh\\n20:18 specializations is uh a good way to\\n20:21 start but what I would suggest to do\\n20:25 before before starting to do courses\\n20:27 okay now we are we I will talk about\\n20:30 those who already do the course but\\n20:32 before doing the courses and start doing\\n20:35 like applying for jobs take some times\\n20:38 and reflect on your profile what do you\\n20:42 have as uh as skills what do you have as\\n20:47 strengths and what do you have as uh\\n20:50 qualifications of course qualifications\\n20:53 strengths skills and then what do you\\n20:55 have as experience so taking into\\n20:59 consideration all of these in addition\\n21:01 to\", 'video_id': 'PchwbIs0tOg', '_id': 4616}]\n",
      "RES  ← research_tool call_8VJVerxhMdhJcAoN6YXrnaSm stage=1 explored_keywords=[ResearchKeyword(keyword='practical applications of data science', relevant_references=[Reference(document_id=6132, quote='at the code 80 Driven Academy we teach a lot of courses on everything data science', timestamp='3:09', relevance_to_keyword='This quote provides a context for learning practical data science through structured courses.', relevance_to_user_intent='The mention of the academy indicates opportunities for applying data science practically via courses offered.'), Reference(document_id=6131, quote='I created a deep learning with NLP course or an unsupervised learning course and those are more detailed or more specific topics', timestamp='3:25', relevance_to_keyword='Courses that are specifically designed for certain data science skills show direct pathways to practical applications.', relevance_to_user_intent=\"This aligns with the user's interest in detailed, practical applications in data science.\"), Reference(document_id=4621, quote='just take some time and okay maybe have a project even if so I finish data engineering I do a project', timestamp='28:02', relevance_to_keyword='Encouragement to engage in project work highlights the importance of actual coding and real-world applications.', relevance_to_user_intent=\"This reflects the user's interest in undertaking projects as a form of practical application of their data science skills.\")])] verifiable_insights=[VerifiableInsight(insight='The Code 80 Driven Academy offers a variety of data science courses including specific tracks in deep learning and unsupervised learning, focusing on practical applications and tailored learning paths.', references=[Reference(document_id=6132, quote='at the code 80 Driven Academy we teach a lot of courses on everything data science', timestamp='3:09', relevance_to_keyword='This quote provides a context for learning practical data science through structured courses.', relevance_to_user_intent='The mention of the academy indicates opportunities for applying data science practically via courses offered.')]), VerifiableInsight(insight='Hands-on experience and projects are emphasized as essential for effectively applying skills learned in courses, reinforcing the application of theoretical knowledge in practical scenarios.', references=[Reference(document_id=4621, quote='just take some time and okay maybe have a project even if so I finish data engineering I do a project', timestamp='28:02', relevance_to_keyword='Encouragement to engage in project work highlights the importance of actual coding and real-world applications.', relevance_to_user_intent=\"This reflects the user's interest in undertaking projects as a form of practical application of their data science skills.\")])] stage_summary='Initial findings highlight the availability of practical data science courses at Code 80 Driven Academy, emphasizing specialized tracks that allow learners to delve deeply into topics like deep learning and unsupervised learning. The insights stress the importance of pairing coursework with hands-on projects, which can enhance the applicability of theoretical knowledge in real-world settings.' recommended_next_steps='Explore specific courses or projects mentioned in the findings to pursue practical applications of data science. Additionally, consider looking into how to integrate personal projects with learning to solidify understanding.' recommended_next_keywords=['specific data science courses', 'project-based learning in data science', 'real-world applications of data science', 'hands-on data science projects', 'data science bootcamps', 'mentorship in data science', 'data engineering project ideas']\n",
      "CALL → research_tool {'stage': 2, 'stage_instructions': 'Find data science project ideas for beginners that can be used as practical applications.'} call_wHvReKbl0C8TKQPAWmym01Sd\n",
      "\n",
      "=== RESEARCH stage 2 ===\n",
      "CALL → search {'query': 'data science beginner project ideas'} call_KKr4znoX8Hw9t0xiX6BDkbeX\n",
      "CALL → search {'query': 'beginner friendly data science projects'} call_JnXEA87WZzolAINa24U2Tkcc\n",
      "CALL → search {'query': 'real-world data science applications beginner'} call_dWeFUeJMbPk3yGl3c3qhNW6U\n",
      "CALL → search {'query': 'hands-on data science projects for beginners'} call_EhsUQCkFdek7Hrvm5eVv8XsV\n",
      "CALL → search {'query': 'data science project examples for beginners'} call_GOai5ljTbA8zzNPnQwFZtAJO\n",
      "RES  ← search call_KKr4znoX8Hw9t0xiX6BDkbeX [{'start': 27000, 'content': \" like a I don't\\n26:46 know an\\n26:48 imposter yeah I think that's a good\\n26:50 question like I was very comfortable in\\n26:52 the topics that I was working on but\\n26:54 there were definitely like people who\\n26:56 were more beginners than me\\n26:58 and I think they did a great job because\\n27:00 what they what they did sometimes is\\n27:02 like oh I don't really understand it\\n27:04 what do you think about it and do you\\n27:06 have a paper I could read or do you have\\n27:08 a book that I would recommend so even if\\n27:11 they were not experts in those topics\\n27:13 they just put in the work to research\\n27:15 about it and since there was always\\n27:16 somebody who knew more about the topic\\n27:19 at hand it was really like easy to guide\\n27:21 each other to see like what to do and\\n27:24 like what was right and what was wrong\\n27:26 and because there was also like people\\n27:28 reviewing the blue requests you could\\n27:29 catch um a lot of like maybe mistakes or\\n27:32 things that weren't so clear so in the\\n27:35 end I think maybe not all topics are\\n27:38 beginner friendly but definitely they\\n27:41 even in in complex projects I think\\n27:44 there's always ATT test this more\\n27:45 beginner friendly MH and also like let's\\n27:49 say you know the topic uh you you know\\n27:51 computer vision CU you did some projects\\n27:54 in computer vision you're not a beginner\\n27:57 and maybe some things they seem obvious\\n28:00 to you and then you don't much time\\n28:04 explaining them but when somebody is\\n28:06 like uh has a fresh perspective on\\n28:08 things they don't necessarily have your\\n28:10 experience they look at the your content\\n28:14 and say okay like I don't understand how\\n28:16 did you jump from this point to this\\n28:17 point yeah honestly that's something\\n28:20 that I really like about teaching\\n28:22 because like when you do something on a\\n28:23 daily basis you kind of forget that that\\n28:26 has no meaning for people in real life\\n28:29 whatsoever and then like people like ask\\n28:32 you this question and you're like oh I\\n28:34 see so like that's not common knowledge\\n28:37 and then you have to like Circle back\\n28:38 and try to explain it with like more\\n28:40 care and also in a way this just more\\n28:42 understandable too like machine learning\\n28:46 is one of those fields that there are so\\n28:48 many words that mean the same thing and\\n28:51 there are so many complicated ways to\\n28:52 say things that sometimes are not that\\n28:55 complicated so that's I think is really\\n28:58 important especially if you are starting\\n29:00 in the field MH and um so let's say I\\n29:04 want to look to find a project like you\\n29:07 did to take part in an open source\\n29:09 project it could be developing a course\\n29:12 or maybe contributing to something I\\n29:16 don't know to do some open source\\n29:18 project uh some other open source\\n29:20 project where would you suggest to look\\n29:22 for these projects in which places like\\n29:25 could it be just random communities uh\\n29:27 or there are specific places wher\", 'video_id': 'GifY8Zn-pnU', '_id': 2670}, {'start': 21000, 'content': \"at this stage\\n21:03 you think like do I even need machine\\n21:06 learing here or it's more like\\n21:07 analytical project absolutely uh okay so\\n21:12 as soon as we uh take off the Inception\\n21:14 phase this is where the data science and\\n21:17 the data scientists and analyst come\\n21:18 together and we brainstorm about the\\n21:21 solution so we discuss about the how and\\n21:24 at this point we understand whether this\\n21:25 is a a data science project that would\\n21:28 involve um that would involve machine\\n21:31 learning or a data analytics whether\\n21:33 it's uh it's a hybrid between that the\\n21:36 two different uh sub teams uh in the\\n21:38 data science and\\n21:40 analytics um to be honest we do have um\\n21:44 some let's say idea when the business\\n21:47 stakeholders discuss about the problem\\n21:50 and we may have already decided that\\n21:52 this point that this is a data science\\n21:53 project or data analytics but at the\\n21:55 assumtion we're absolutely certain that\\n21:57 you you know what this is 100% the data\\n22:00 science um project for instance it's\\n22:03 just a confirmation that we had when\\n22:06 when we\\n22:07 started and depending whether it is a\\n22:10 data science project or it is not I\\n22:12 guess the next step would be different\\n22:14 right absolutely\\n22:16 yeah it's data science project then you\\n22:20 say okay like I'm a data scientist I\\n22:22 cannot help you then somebody else takes\\n22:24 this over right um not really I'm the\\n22:28 accountable for both data science and\\n22:30 analytics project the only difference is\\n22:33 that if it's a it's an analytics project\\n22:36 the technical lead that will work that\\n22:38 will work on the project is going to be\\n22:41 um a data analyst instead of a data\\n22:43 scientist uh I still hold the\\n22:45 accountability of making sure that the\\n22:47 product is is delivered end to\\n22:49 end so what's the next step or is it\\n22:52 different different\\n22:54 projects uh not really uh as soon as you\\n22:57 have have an idea uh and you have\\n22:59 defined the how of um of solving the uh\\n23:03 the problem statement um this is where\\n23:05 we move into the uh research and\\n23:08 development phase this is the Hardcore\\n23:11 um modeling steps um in data science\\n23:15 where we follow all the different agile\\n23:17 methodologies uh spring planning\\n23:19 standups retrospective all The Usual\\n23:21 Suspects are usually uh there where we\\n23:24 start tackling all the different uh\\n23:26 stories that we have defined in a in a\\n23:29 cound board for instance um and we\\n23:32 Define Sprints this is the goal for\\n23:35 Sprint one Sprint to and uh yeah this is\\n23:38 where we start build building uh\\n23:40 whatever that that solution might uh\\n23:42 look like uh we also make sure that the\\n23:44 stakeholders are closely uh working with\\n23:47 us because you have to make sure that um\\n23:51 it's a it's a common problem that we're\\n23:54 trying to tackle and you want to make\\n23:55 sure that the business stakeholders are\\n23:57 part of the team and they're not \", 'video_id': '1pExOVuCF8Q', '_id': 428}, {'start': 19500, 'content': \"4 what the data is is not actually there\\n19:36 which means that this is a noo and when\\n19:38 when that happens although it doesn't\\n19:40 happen frequently this is a fail F\\n19:42 scenario and then we say you know what\\n19:44 we cannot proceed that let's take the\\n19:45 second in\\n19:47 line but this happens later right so at\\n19:50 the business understanding step\\n19:51 absolutely you come with this definition\\n19:53 of done uh document for a project which\\n19:55 is like two three pages long right and\\n19:57 then I guess you proceed to The Next\\n19:59 Step which is you mentioned checking\\n20:02 data in\\n20:04 exactly so so as everybody has signed\\n20:07 off this uh document uh the business\\n20:10 stakeholders uh data scientist which is\\n20:12 uh me in that case data Engineers uh\\n20:14 every single person involved then we\\n20:16 proceed to the next phase which is this\\n20:18 is where the data\\n20:20 signy um invol starts to to kick in yes\\n20:25 Inception you can think of it as the\\n20:28 edav exploratory data analysis where we\\n20:31 try to ensure that we have everything\\n20:32 that we need uh that includes uh access\\n20:35 to the data if the data is already\\n20:37 present any um gdpr concerns that we\\n20:40 might encounter\\n20:43 um explore the data sources as in\\n20:46 different distributions and this kind of\\n20:48 um concern that we might have uh so yeah\\n20:51 that's Prett much\\n20:53 it is this uh like at which stage do you\\n20:57 actually so you said this is when data\\n21:00 science kicks in is this at this stage\\n21:03 you think like do I even need machine\\n21:06 learing here or it's more like\\n21:07 analytical project absolutely uh okay so\\n21:12 as soon as we uh take off the Inception\\n21:14 phase this is where the data science and\\n21:17 the data scientists and analyst come\\n21:18 together and we brainstorm about the\\n21:21 solution so we discuss about the how and\\n21:24 at this point we understand whether this\\n21:25 is a a data science project that would\\n21:28 involve um that would involve machine\\n21:31 learning or a data analytics whether\\n21:33 it's uh it's a hybrid between that the\\n21:36 two different uh sub teams uh in the\\n21:38 data science and\\n21:40 analytics um to be honest we do have um\\n21:44 some let's say idea when the business\\n21:47 stakeholders discuss about the problem\\n21:50 and we may have already decided that\\n21:52 this point that this is a data science\\n21:53 project or data analytics but at the\\n21:55 assumtion we're absolutely certain that\\n21:57 you you know what this is 100% the data\\n22:00 science um project for instance it's\\n22:03 just a confirmation that we had when\\n22:06 when we\\n22:07 started and depending whether it is a\\n22:10 data science project or it is not I\\n22:12 guess the next step would be different\\n22:14 right absolutely\\n22:16 yeah it's data science project then you\\n22:20 say okay like I'm a data scientist I\\n22:22 cannot help you then somebody else takes\\n22:24 this over right um not really I'm the\\n22:28 accountable for both data science and\\n22:30 \", 'video_id': '1pExOVuCF8Q', '_id': 427}, {'start': 57000, 'content': \"w\\n48:24 like a little bit about data engineering\\n48:26 maybe they'll ask you like otp versus\\n48:28 olap um maybe they'll just ask you have\\n48:31 you built any data pipelines and you\\n48:32 know tell me about some of the tools\\n48:33 you've used in data engineering things\\n48:35 like that you don't need to know every\\n48:36 one of them uh but just like if you've\\n48:39 you know they want to know that you've\\n48:40 spent some time with this uh and then\\n48:42 the second interview is probably going\\n48:43 to be a sql question\\n48:45 so you can expect that so you know i'd\\n48:48 say\\n48:49 if you can do some of the medium\\n48:51 uh lee code problems\\n48:53 then okay you should feel pretty good\\n48:55 and you don't have to get them 100\\n48:57 right but if you don't feel blown away\\n48:59 by like the medium uh sequel questions\\n49:01 they're probably pretty good and then at\\n49:03 that point go in an interview you know\\n49:06 like like just like it's fine like there\\n49:08 will be more interviews that show up so\\n49:10 i'd say like go on the interview and\\n49:11 that will help you\\n49:12 a little bit see\\n49:14 you know you can self-assess afterwards\\n49:16 you can see where you are one thing i\\n49:18 would say\\n49:20 one caveat to that and one thing to be\\n49:22 careful of is sometimes i'll see\\n49:24 students go on an interview they're like\\n49:27 bs something kind of out of left field\\n49:29 and of course they vomit uh and they'll\\n49:31 be like i gotta learn that thing like i\\n49:32 learned everything about that thing and\\n49:33 you come back to them two months later\\n49:35 they're still just like learning\\n49:36 everything about that thing and so like\\n49:38 you want to stay on your learning path\\n49:40 of okay i'm building like a data\\n49:42 pipeline i'm improving my sql skills i'm\\n49:44 going through some like python lead code\\n49:46 problems right because those will also\\n49:49 be asked\\n49:52 okay so there are still a couple of\\n49:53 questions i want to ask so yeah\\n49:57 and the question uh i want to ask most\\n49:59 if somebody wants to start teaching\\n50:01 software engineering or data engineer or\\n50:03 data science\\n50:04 any topic\\n50:05 what would you suggest to them so let's\\n50:07 say i am a data engineer already i do\\n50:10 not have experience in teaching\\n50:12 what should i do\\n50:14 okay so\\n50:16 i mean the first thing is okay so think\\n50:19 of a topic i guess that is probably like\\n50:22 beginner level you know meaning meaning\\n50:24 that one is something like a beginner\\n50:26 can accomplish\\n50:28 and\\n50:28 two\\n50:29 would be interesting to a beginner like\\n50:32 actually fi like and that itself will be\\n50:33 a process like it took me multiple tries\\n50:36 uh to get there\\n50:37 and then i'd say explain it to someone\\n50:39 like explain just like\\n50:41 explain it to someone at the level that\\n50:42 you want your audience to be just one\\n50:44 person and walk them through it uh and\\n50:47 teach them it and then see if they know\\n50:49 it and then also kind of maybe hear\\n50:51 their feedback o\", 'video_id': 'dFo10l8B6Go', '_id': 2057}, {'start': 43500, 'content': \"t\\n41:11 you know their background is like i have\\n41:12 a master's in marine biology\\n41:14 or you know something that's kind of\\n41:15 like maybe tech adjacent\\n41:17 i also know people that like gosh i mean\\n41:20 i work with a guy who um\\n41:22 not at not at iterative but um at uh\\n41:25 what's it called\\n41:26 um at michigan he has like a history phd\\n41:30 and he taught himself you know software\\n41:32 development and data science\\n41:34 skills and now he's one of the\\n41:35 instructors um so\\n41:37 i i think there is a lot of room\\n41:41 for people who are coming in from a\\n41:43 non-technical background and in fact\\n41:45 when it can be an asset in a way\\n41:48 that you really do get the experience of\\n41:51 being a beginner\\n41:52 and you can learn like what was it like\\n41:54 like when i was a beginner at this\\n41:55 what parts of this were really confusing\\n41:58 for me and then\\n41:59 you take note of that and then you know\\n42:01 that you know you take that with you\\n42:03 um and that i think for me like all the\\n42:06 times i didn't know is actually the most\\n42:08 informative for this job\\n42:11 so basically like if somebody who is not\\n42:14 super technical who doesn't work as a\\n42:16 software engineer right now\\n42:18 one way of of getting this position of\\n42:21 becoming a developer advocate would be\\n42:23 learning in public right so you just\\n42:26 learn something put it to\\n42:30 put it online uh write an article about\\n42:33 this\\n42:34 and this is how you do this right so you\\n42:36 start communicating about your learning\\n42:38 process\\n42:39 then people notice you and then maybe\\n42:42 your tweet goes viral and then you\\n42:43 mention that\\n42:44 you know by the way i'm looking for a\\n42:46 job and this is\\n42:48 this is a good recipe of uh getting a\\n42:50 job in\\n42:51 in in as a developer as a kid\\n42:55 yeah it's definitely what i recommend to\\n42:57 people is start\\n42:58 blogging you know in a platform that\\n43:00 you'd like medium is a good one there's\\n43:02 towards data science you know is a\\n43:04 really good\\n43:05 place for you know there's a lot of\\n43:07 beginner ones there\\n43:08 um yeah post on twitter\\n43:12 if you're in the r community i really\\n43:14 recommend like our bloggers you can also\\n43:16 go like you know language specific sites\\n43:18 and aggregators\\n43:19 um but just start just start making\\n43:22 things\\n43:25 yeah it makes sense but usually you talk\\n43:28 to\\n43:29 to other developer advocates the rails\\n43:31 what kind of backgrounds\\n43:33 do they have what kind of background did\\n43:35 they have before becoming\\n43:36 the rail is there some pattern that you\\n43:38 saw like\\n43:40 are they usually uh you know like were\\n43:44 they in the past software engineers or\\n43:46 it's really there is no pattern in my\\n43:49 experience they tend to be\\n43:51 and this is not all by far\\n43:54 but i noticed that there's a lot of\\n43:55 people that are kind of\\n43:57 creative like working on a lot of\\n43:59 different things like learning things\\n44:01 um there's kind of a i don\", 'video_id': 'jv5W4jXk4P4', '_id': 3579}]\n",
      "RES  ← search call_JnXEA87WZzolAINa24U2Tkcc [{'start': 27000, 'content': \" like a I don't\\n26:46 know an\\n26:48 imposter yeah I think that's a good\\n26:50 question like I was very comfortable in\\n26:52 the topics that I was working on but\\n26:54 there were definitely like people who\\n26:56 were more beginners than me\\n26:58 and I think they did a great job because\\n27:00 what they what they did sometimes is\\n27:02 like oh I don't really understand it\\n27:04 what do you think about it and do you\\n27:06 have a paper I could read or do you have\\n27:08 a book that I would recommend so even if\\n27:11 they were not experts in those topics\\n27:13 they just put in the work to research\\n27:15 about it and since there was always\\n27:16 somebody who knew more about the topic\\n27:19 at hand it was really like easy to guide\\n27:21 each other to see like what to do and\\n27:24 like what was right and what was wrong\\n27:26 and because there was also like people\\n27:28 reviewing the blue requests you could\\n27:29 catch um a lot of like maybe mistakes or\\n27:32 things that weren't so clear so in the\\n27:35 end I think maybe not all topics are\\n27:38 beginner friendly but definitely they\\n27:41 even in in complex projects I think\\n27:44 there's always ATT test this more\\n27:45 beginner friendly MH and also like let's\\n27:49 say you know the topic uh you you know\\n27:51 computer vision CU you did some projects\\n27:54 in computer vision you're not a beginner\\n27:57 and maybe some things they seem obvious\\n28:00 to you and then you don't much time\\n28:04 explaining them but when somebody is\\n28:06 like uh has a fresh perspective on\\n28:08 things they don't necessarily have your\\n28:10 experience they look at the your content\\n28:14 and say okay like I don't understand how\\n28:16 did you jump from this point to this\\n28:17 point yeah honestly that's something\\n28:20 that I really like about teaching\\n28:22 because like when you do something on a\\n28:23 daily basis you kind of forget that that\\n28:26 has no meaning for people in real life\\n28:29 whatsoever and then like people like ask\\n28:32 you this question and you're like oh I\\n28:34 see so like that's not common knowledge\\n28:37 and then you have to like Circle back\\n28:38 and try to explain it with like more\\n28:40 care and also in a way this just more\\n28:42 understandable too like machine learning\\n28:46 is one of those fields that there are so\\n28:48 many words that mean the same thing and\\n28:51 there are so many complicated ways to\\n28:52 say things that sometimes are not that\\n28:55 complicated so that's I think is really\\n28:58 important especially if you are starting\\n29:00 in the field MH and um so let's say I\\n29:04 want to look to find a project like you\\n29:07 did to take part in an open source\\n29:09 project it could be developing a course\\n29:12 or maybe contributing to something I\\n29:16 don't know to do some open source\\n29:18 project uh some other open source\\n29:20 project where would you suggest to look\\n29:22 for these projects in which places like\\n29:25 could it be just random communities uh\\n29:27 or there are specific places wher\", 'video_id': 'GifY8Zn-pnU', '_id': 2670}, {'start': 25500, 'content': \"he modules or yeah I work mostly\\n25:20 on the first module which is like what\\n25:22 is computer vision what is image\\n25:25 processing um how the computers even see\\n25:28 Imes and like what are the classical\\n25:30 techniques that happened and then after\\n25:34 that I sort of became a reviewer for the\\n25:38 course so I review quite a lot of the\\n25:40 other units mostly because the way that\\n25:43 the course was structured like once\\n25:45 everybody was done everybody made the PO\\n25:47 request and then it became like okay we\\n25:49 have 30 PO requests to review like who\\n25:51 is\\n25:52 available and then I also contributed to\\n25:54 like some parts of like introduction to\\n25:57 what is transfer learning\\n25:59 and so forth but it was really based on\\n26:02 by the time I joined quite a a lot of\\n26:04 the fancy topics were taken and the\\n26:06 introductory topics were quite were\\n26:09 quite free so I was like okay I can take\\n26:11 the introductory top like I can work\\n26:14 with\\n26:15 this and it was and how how much\\n26:18 computer vision experience did you have\\n26:19 back then when I was working in in\\n26:22 Academia like my last internship in my\\n26:25 master's degree in the beginning of my\\n26:27 academic work were both in computer\\n26:30 vision so I was quite quite familiar\\n26:33 with\\n26:34 him I'm also curious um like in order to\\n26:37 teach something or in order to take part\\n26:39 in a community course like that how much\\n26:41 how deep your knowledge should\\n26:43 be so that you don't feel like a I don't\\n26:46 know an\\n26:48 imposter yeah I think that's a good\\n26:50 question like I was very comfortable in\\n26:52 the topics that I was working on but\\n26:54 there were definitely like people who\\n26:56 were more beginners than me\\n26:58 and I think they did a great job because\\n27:00 what they what they did sometimes is\\n27:02 like oh I don't really understand it\\n27:04 what do you think about it and do you\\n27:06 have a paper I could read or do you have\\n27:08 a book that I would recommend so even if\\n27:11 they were not experts in those topics\\n27:13 they just put in the work to research\\n27:15 about it and since there was always\\n27:16 somebody who knew more about the topic\\n27:19 at hand it was really like easy to guide\\n27:21 each other to see like what to do and\\n27:24 like what was right and what was wrong\\n27:26 and because there was also like people\\n27:28 reviewing the blue requests you could\\n27:29 catch um a lot of like maybe mistakes or\\n27:32 things that weren't so clear so in the\\n27:35 end I think maybe not all topics are\\n27:38 beginner friendly but definitely they\\n27:41 even in in complex projects I think\\n27:44 there's always ATT test this more\\n27:45 beginner friendly MH and also like let's\\n27:49 say you know the topic uh you you know\\n27:51 computer vision CU you did some projects\\n27:54 in computer vision you're not a beginner\\n27:57 and maybe some things they seem obvious\\n28:00 to you and then you don't much time\\n28:04 explaining them but when somebody is\\n28:06 like u\", 'video_id': 'GifY8Zn-pnU', '_id': 2669}, {'start': 37500, 'content': \" reach out to\\n39:14 people and just have fun with with the\\n39:17 content that you put there.\\n39:20 >> I'm just checking my stock overflow. I\\n39:22 have actually 2,4400\\n39:24 reputation points.\\n39:26 >> Oh, that's good. That's\\n39:29 >> sometimes you just ask a question and\\n39:30 then you come there like five years ago\\n39:33 and you see, okay.\\n39:34 >> Yeah. But it wasn't beginner friendly.\\n39:36 if you didn't if you didn't know how to\\n39:39 pose a question, a good question, people\\n39:42 would come after you. So, it wasn't that\\n39:45 beginner friendly, right?\\n39:47 >> I don't remember having this problem,\\n39:49 but I've been um an active participant\\n39:53 of different forums since uh I had\\n39:56 access to the internet.\\n39:57 >> Okay.\\n39:57 >> So, I guess I kind of knew the culture.\\n40:01 >> So, maybe it wasn't like too,\\n40:04 how to say alien to me.\\n40:06 Okay, so back to our topic. So you\\n40:10 shared the progress um your progress uh\\n40:15 you were taking MLM camp and you were\\n40:17 sharing your progress but one of the\\n40:19 things you did you did it not from the\\n40:21 position hey I'm student this is what\\n40:24 was covered today but you were\\n40:26 rephrasing this to be an expert okay\\n40:28 this is a c curve this is used to\\n40:33 see how good your classifiers are so you\\n40:35 were sharing what you learned but more\\n40:38 like from an expert point of you you\\n40:40 just rephrased um\\n40:42 like reframed your mind I guess right\\n40:46 you framed reframed this in your mind so\\n40:49 this helped you post cuz also at the end\\n40:51 you wanted to attract these recruiters\\n40:53 you wanted to attract more followers uh\\n40:56 and that helped in order to do this\\n40:58 because also I guess since you were\\n41:00 working on platforms like Upwork you\\n41:03 wanted to eventually also get more\\n41:04 clients there right?\\n41:07 >> Yeah. Yeah. So actually in a world once\\n41:09 you like when when I built my like\\n41:12 reputation there it was easy to to to\\n41:16 get customers and outside of work was\\n41:18 really hard to actually get customers\\n41:21 but you know after the p after the\\n41:24 pandemic like I saw world was losing a\\n41:27 lot of you know the their their clients\\n41:29 and I wasn't getting a lot of of you\\n41:33 know of jobs to actually work on. So I\\n41:36 saw like I need to shift to a different\\n41:40 place. So I try your course I you know I\\n41:44 didn't even have a linking account\\n41:47 before that you know before posting\\n41:49 before before the the MLS camp but but\\n41:53 yeah because X was you know I I wanted\\n41:56 to post in somewhere else and I know\\n41:58 that LinkedIn was also a good place to\\n42:00 find work. I I I opened my account and\\n42:04 started to post in there and and and\\n42:07 yeah, I I was trying to reach a market\\n42:11 because one fun thing about posting\\n42:13 things online is that your audience grow\\n42:15 with you. So if you're starting to share\\n42:17 things as a beginner right now\\n42:21 eventually those audience will become\\n42:23 also senior engineers \", 'video_id': '5km62e4nDaw', '_id': 723}, {'start': 21000, 'content': \" yeah there's actually a lot more I I\\n22:31 think I can talk for hours about what\\n22:33 you can do but we have a lot of other\\n22:35 questions right yeah yeah I am yeah that\\n22:39 text is massive like and I'm still I'm\\n22:41 always surprised like how you do all of\\n22:43 these things because we also have like\\n22:44 the webinars and the podcast like right\\n22:46 like if people think they are\\n22:47 interesting if people think they are\\n22:49 interesting they can also like probably\\n22:51 reach out to fris we're always looking\\n22:53 for new guests but I think in general um\\n22:56 the one thing that how people can\\n22:58 benefit is um which dat club like uses\\n23:01 quite a bit is this learning in public\\n23:03 so always um if you learn something\\n23:06 tweet it or talk about it and we will\\n23:08 probably also like you know promote it\\n23:11 um I think that's also big part of the\\n23:14 zoom cams um yes to make it thanks for\\n23:17 mentioning this yeah yeah yeah um cool\\n23:21 um so then we move on um what are the\\n23:25 main lessons learned from your\\n23:27 experience in building the DTC online\\n23:31 community yeah so that was also I was\\n23:34 lucky to see to be able to see this\\n23:36 question before the interview because\\n23:38 it's like a very difficult question to\\n23:40 answer to be\\n23:41 honest um so yeah and I did a bit of\\n23:45 brainstorming and I came up with um a\\n23:48 few\\n23:49 things so I remember at the beginning\\n23:52 the goal was quite ambitious so the goal\\n23:54 was to create a community for all data\\n23:57 people which includes like data analysts\\n24:00 uh data Engineers data scientists I\\n24:03 don't know data product managers ml\\n24:05 Engineers like everyone who deals with\\n24:09 data but with time I realized that it's\\n24:12 too broad it's not possible to be that\\n24:15 broad um and there are already\\n24:17 communities for example like there's\\n24:19 Community called locally optimistic who\\n24:22 focuses more like on uh data product\\n24:24 manager and data analyst and then there\\n24:27 is a mlop Community yeah who focuses\\n24:29 more on\\n24:31 mvelopes um so we also kind needed to\\n24:34 focus on something so for data talks\\n24:36 Club it was more like um beginner\\n24:40 friendly Hands-On learning for a lot of\\n24:43 our content um so focus is more like on\\n24:46 people who start their career or\\n24:48 continue rather than who are advanced in\\n24:50 their career and with a lot of focus on\\n24:52 Hands-On stuff and with focus on\\n24:55 engineering aspects of data like uh ml\\n24:59 engineering data engineering mlops so\\n25:01 these are engineering heavy things where\\n25:04 you need to code a lot and our podcast\\n25:07 uh is still kind of well it's not so\\n25:10 super technical uh but still we talk\\n25:13 about like careers and things like that\\n25:15 who also that also appeal more to like\\n25:19 maybe beginner and intermediate level of\\n25:22 audience rather than like professionals\\n25:24 yeah so I guess uh with time we\\n25:28 actually found some Focus yeah uh but\\n25:31 still yeah s\", 'video_id': 'nCqwZT9zA0M', '_id': 4162}, {'start': 36000, 'content': \"don't take I\\n37:49 don't take things personally and I try\\n37:51 to learn from interactions. So sometimes\\n37:55 that little post can help you to\\n37:58 actually reach out to more people and\\n38:01 those debates also help you. So\\n38:04 >> right cuz like when you make a mistake\\n38:07 and everyone is like okay there's a\\n38:09 mistake I have to correct him right so\\n38:11 they go and leave a comment\\n38:13 >> and what happens when people leave\\n38:15 comments this post gets promoted to the\\n38:18 top of your feed right because everyone\\n38:20 is commenting on it so then this way you\\n38:22 get more exposure. interesting.\\n38:24 >> And that's how Stack Overflow.\\n38:26 >> And then it's not really incorrect what\\n38:28 you said. It was more like um inviting\\n38:32 for a debate.\\n38:34 >> Yeah.\\n38:35 >> Okay.\\n38:36 >> Yeah. And and it was like stock overflow\\n38:38 like I don't know if you post some\\n38:41 sometimes in stock overflow but it was\\n38:43 intense. If you if you say something\\n38:45 that that people or you know if what's\\n38:48 already posted people was throughout you\\n38:51 like they they will point that out\\n38:53 really hard you know I I have couple of\\n38:55 of question that I put on Insta overflow\\n38:58 that had minus three minus four so like\\n39:01 that was intense and people point out\\n39:03 hey this was already like this doesn't\\n39:05 meet the guidelines and so yeah but you\\n39:08 know like it's it's it's part it's part\\n39:10 of the deal sometimes you need to\\n39:12 oversimplify things to reach out to\\n39:14 people and just have fun with with the\\n39:17 content that you put there.\\n39:20 >> I'm just checking my stock overflow. I\\n39:22 have actually 2,4400\\n39:24 reputation points.\\n39:26 >> Oh, that's good. That's\\n39:29 >> sometimes you just ask a question and\\n39:30 then you come there like five years ago\\n39:33 and you see, okay.\\n39:34 >> Yeah. But it wasn't beginner friendly.\\n39:36 if you didn't if you didn't know how to\\n39:39 pose a question, a good question, people\\n39:42 would come after you. So, it wasn't that\\n39:45 beginner friendly, right?\\n39:47 >> I don't remember having this problem,\\n39:49 but I've been um an active participant\\n39:53 of different forums since uh I had\\n39:56 access to the internet.\\n39:57 >> Okay.\\n39:57 >> So, I guess I kind of knew the culture.\\n40:01 >> So, maybe it wasn't like too,\\n40:04 how to say alien to me.\\n40:06 Okay, so back to our topic. So you\\n40:10 shared the progress um your progress uh\\n40:15 you were taking MLM camp and you were\\n40:17 sharing your progress but one of the\\n40:19 things you did you did it not from the\\n40:21 position hey I'm student this is what\\n40:24 was covered today but you were\\n40:26 rephrasing this to be an expert okay\\n40:28 this is a c curve this is used to\\n40:33 see how good your classifiers are so you\\n40:35 were sharing what you learned but more\\n40:38 like from an expert point of you you\\n40:40 just rephrased um\\n40:42 like reframed your mind I guess right\\n40:46 you framed reframed this in your mind so\\n40:49 t\", 'video_id': '5km62e4nDaw', '_id': 722}]\n",
      "RES  ← search call_dWeFUeJMbPk3yGl3c3qhNW6U [{'start': 66000, 'content': \"58:34 that you understand\\n58:36 how data behaves you understand what\\n58:38 kind of problems that can be in the data\\n58:42 you know how to deal with these problems\\n58:44 and you know how to build a model and\\n58:48 you know what to do\\n58:49 when something goes wrong in this model\\n58:51 so you know if it's overfitting you are\\n58:53 able to understand oh hey it is\\n58:55 overfitting and then you can come up\\n58:56 with some options you don't even have to\\n58:58 apply to apply them honestly if you have\\n59:00 a notebook where you do some analysis on\\n59:02 the titanic uh data set and then you're\\n59:05 like oh here i tried this but then it\\n59:07 overfit here are some things i think i\\n59:08 can do to fix them and yeah if you have\\n59:10 time you know you can go further because\\n59:12 as you know like sometimes data data\\n59:14 science projects are like endless there\\n59:15 are so many things you can try and so\\n59:17 many things you can do kind of like a\\n59:18 future work you know it can be like if i\\n59:20 had more time i would do this and that\\n59:22 so that's why i don't think the\\n59:24 project itself really matters\\n59:26 especially for beginner data scientists\\n59:29 it's just showing\\n59:31 that you can do critical thinking and\\n59:33 you know the tools that are available\\n59:35 and you know when to use them\\n59:37 i would still not like use titanic or\\n59:39 whatever because i think they're kind of\\n59:41 boring but\\n59:44 i would try to find data sets that are\\n59:47 from real life so actually collected in\\n59:49 real life one that i really like to use\\n59:52 that i also use in my course is uh new\\n59:55 york city open data it's from new york\\n59:56 city open data and it is like\\n59:59 the\\n1:00:00 taxi rides the the informational data on\\n1:00:03 that is collected on taxi rides and it\\n1:00:06 is extremely dirty there are so many\\n1:00:08 things that is wrong with that data but\\n1:00:09 i mean\\n1:00:10 you know it's like real life obviously\\n1:00:12 so that happens\\n1:00:13 so i would really suggest that you find\\n1:00:15 a source like that by the way new york\\n1:00:17 city open data has a lot of different\\n1:00:19 types of data so like definitely go\\n1:00:20 check it out\\n1:00:22 you have reddit for example in reddit\\n1:00:24 datasets subreddit i think has a lot of\\n1:00:26 different types of data sets that people\\n1:00:28 are posting just kind of find try to\\n1:00:30 find one that at least resembles real\\n1:00:33 life data a little bit of course real\\n1:00:35 life data is not really made publicly\\n1:00:37 available most of the time uh and as far\\n1:00:39 as i know the ones on kaggle are like\\n1:00:41 quite well prepared and clean and\\n1:00:43 everything so\\n1:00:45 yeah i think if you just get a piece of\\n1:00:48 data that at least resembles real life\\n1:00:50 and then you do your best on top of it\\n1:00:53 that that is you know enough of a\\n1:00:55 project you don't really have to build\\n1:00:56 anything mind-blowing or interesting if\\n1:00:58 you cannot come up with an idea\\n1:01:00 yeah and speak\", 'video_id': 'oUycqtMoYr8', '_id': 4518}, {'start': 27000, 'content': \" like a I don't\\n26:46 know an\\n26:48 imposter yeah I think that's a good\\n26:50 question like I was very comfortable in\\n26:52 the topics that I was working on but\\n26:54 there were definitely like people who\\n26:56 were more beginners than me\\n26:58 and I think they did a great job because\\n27:00 what they what they did sometimes is\\n27:02 like oh I don't really understand it\\n27:04 what do you think about it and do you\\n27:06 have a paper I could read or do you have\\n27:08 a book that I would recommend so even if\\n27:11 they were not experts in those topics\\n27:13 they just put in the work to research\\n27:15 about it and since there was always\\n27:16 somebody who knew more about the topic\\n27:19 at hand it was really like easy to guide\\n27:21 each other to see like what to do and\\n27:24 like what was right and what was wrong\\n27:26 and because there was also like people\\n27:28 reviewing the blue requests you could\\n27:29 catch um a lot of like maybe mistakes or\\n27:32 things that weren't so clear so in the\\n27:35 end I think maybe not all topics are\\n27:38 beginner friendly but definitely they\\n27:41 even in in complex projects I think\\n27:44 there's always ATT test this more\\n27:45 beginner friendly MH and also like let's\\n27:49 say you know the topic uh you you know\\n27:51 computer vision CU you did some projects\\n27:54 in computer vision you're not a beginner\\n27:57 and maybe some things they seem obvious\\n28:00 to you and then you don't much time\\n28:04 explaining them but when somebody is\\n28:06 like uh has a fresh perspective on\\n28:08 things they don't necessarily have your\\n28:10 experience they look at the your content\\n28:14 and say okay like I don't understand how\\n28:16 did you jump from this point to this\\n28:17 point yeah honestly that's something\\n28:20 that I really like about teaching\\n28:22 because like when you do something on a\\n28:23 daily basis you kind of forget that that\\n28:26 has no meaning for people in real life\\n28:29 whatsoever and then like people like ask\\n28:32 you this question and you're like oh I\\n28:34 see so like that's not common knowledge\\n28:37 and then you have to like Circle back\\n28:38 and try to explain it with like more\\n28:40 care and also in a way this just more\\n28:42 understandable too like machine learning\\n28:46 is one of those fields that there are so\\n28:48 many words that mean the same thing and\\n28:51 there are so many complicated ways to\\n28:52 say things that sometimes are not that\\n28:55 complicated so that's I think is really\\n28:58 important especially if you are starting\\n29:00 in the field MH and um so let's say I\\n29:04 want to look to find a project like you\\n29:07 did to take part in an open source\\n29:09 project it could be developing a course\\n29:12 or maybe contributing to something I\\n29:16 don't know to do some open source\\n29:18 project uh some other open source\\n29:20 project where would you suggest to look\\n29:22 for these projects in which places like\\n29:25 could it be just random communities uh\\n29:27 or there are specific places wher\", 'video_id': 'GifY8Zn-pnU', '_id': 2670}, {'start': 37500, 'content': \" reach out to\\n39:14 people and just have fun with with the\\n39:17 content that you put there.\\n39:20 >> I'm just checking my stock overflow. I\\n39:22 have actually 2,4400\\n39:24 reputation points.\\n39:26 >> Oh, that's good. That's\\n39:29 >> sometimes you just ask a question and\\n39:30 then you come there like five years ago\\n39:33 and you see, okay.\\n39:34 >> Yeah. But it wasn't beginner friendly.\\n39:36 if you didn't if you didn't know how to\\n39:39 pose a question, a good question, people\\n39:42 would come after you. So, it wasn't that\\n39:45 beginner friendly, right?\\n39:47 >> I don't remember having this problem,\\n39:49 but I've been um an active participant\\n39:53 of different forums since uh I had\\n39:56 access to the internet.\\n39:57 >> Okay.\\n39:57 >> So, I guess I kind of knew the culture.\\n40:01 >> So, maybe it wasn't like too,\\n40:04 how to say alien to me.\\n40:06 Okay, so back to our topic. So you\\n40:10 shared the progress um your progress uh\\n40:15 you were taking MLM camp and you were\\n40:17 sharing your progress but one of the\\n40:19 things you did you did it not from the\\n40:21 position hey I'm student this is what\\n40:24 was covered today but you were\\n40:26 rephrasing this to be an expert okay\\n40:28 this is a c curve this is used to\\n40:33 see how good your classifiers are so you\\n40:35 were sharing what you learned but more\\n40:38 like from an expert point of you you\\n40:40 just rephrased um\\n40:42 like reframed your mind I guess right\\n40:46 you framed reframed this in your mind so\\n40:49 this helped you post cuz also at the end\\n40:51 you wanted to attract these recruiters\\n40:53 you wanted to attract more followers uh\\n40:56 and that helped in order to do this\\n40:58 because also I guess since you were\\n41:00 working on platforms like Upwork you\\n41:03 wanted to eventually also get more\\n41:04 clients there right?\\n41:07 >> Yeah. Yeah. So actually in a world once\\n41:09 you like when when I built my like\\n41:12 reputation there it was easy to to to\\n41:16 get customers and outside of work was\\n41:18 really hard to actually get customers\\n41:21 but you know after the p after the\\n41:24 pandemic like I saw world was losing a\\n41:27 lot of you know the their their clients\\n41:29 and I wasn't getting a lot of of you\\n41:33 know of jobs to actually work on. So I\\n41:36 saw like I need to shift to a different\\n41:40 place. So I try your course I you know I\\n41:44 didn't even have a linking account\\n41:47 before that you know before posting\\n41:49 before before the the MLS camp but but\\n41:53 yeah because X was you know I I wanted\\n41:56 to post in somewhere else and I know\\n41:58 that LinkedIn was also a good place to\\n42:00 find work. I I I opened my account and\\n42:04 started to post in there and and and\\n42:07 yeah, I I was trying to reach a market\\n42:11 because one fun thing about posting\\n42:13 things online is that your audience grow\\n42:15 with you. So if you're starting to share\\n42:17 things as a beginner right now\\n42:21 eventually those audience will become\\n42:23 also senior engineers \", 'video_id': '5km62e4nDaw', '_id': 723}, {'start': 57000, 'content': \"w\\n48:24 like a little bit about data engineering\\n48:26 maybe they'll ask you like otp versus\\n48:28 olap um maybe they'll just ask you have\\n48:31 you built any data pipelines and you\\n48:32 know tell me about some of the tools\\n48:33 you've used in data engineering things\\n48:35 like that you don't need to know every\\n48:36 one of them uh but just like if you've\\n48:39 you know they want to know that you've\\n48:40 spent some time with this uh and then\\n48:42 the second interview is probably going\\n48:43 to be a sql question\\n48:45 so you can expect that so you know i'd\\n48:48 say\\n48:49 if you can do some of the medium\\n48:51 uh lee code problems\\n48:53 then okay you should feel pretty good\\n48:55 and you don't have to get them 100\\n48:57 right but if you don't feel blown away\\n48:59 by like the medium uh sequel questions\\n49:01 they're probably pretty good and then at\\n49:03 that point go in an interview you know\\n49:06 like like just like it's fine like there\\n49:08 will be more interviews that show up so\\n49:10 i'd say like go on the interview and\\n49:11 that will help you\\n49:12 a little bit see\\n49:14 you know you can self-assess afterwards\\n49:16 you can see where you are one thing i\\n49:18 would say\\n49:20 one caveat to that and one thing to be\\n49:22 careful of is sometimes i'll see\\n49:24 students go on an interview they're like\\n49:27 bs something kind of out of left field\\n49:29 and of course they vomit uh and they'll\\n49:31 be like i gotta learn that thing like i\\n49:32 learned everything about that thing and\\n49:33 you come back to them two months later\\n49:35 they're still just like learning\\n49:36 everything about that thing and so like\\n49:38 you want to stay on your learning path\\n49:40 of okay i'm building like a data\\n49:42 pipeline i'm improving my sql skills i'm\\n49:44 going through some like python lead code\\n49:46 problems right because those will also\\n49:49 be asked\\n49:52 okay so there are still a couple of\\n49:53 questions i want to ask so yeah\\n49:57 and the question uh i want to ask most\\n49:59 if somebody wants to start teaching\\n50:01 software engineering or data engineer or\\n50:03 data science\\n50:04 any topic\\n50:05 what would you suggest to them so let's\\n50:07 say i am a data engineer already i do\\n50:10 not have experience in teaching\\n50:12 what should i do\\n50:14 okay so\\n50:16 i mean the first thing is okay so think\\n50:19 of a topic i guess that is probably like\\n50:22 beginner level you know meaning meaning\\n50:24 that one is something like a beginner\\n50:26 can accomplish\\n50:28 and\\n50:28 two\\n50:29 would be interesting to a beginner like\\n50:32 actually fi like and that itself will be\\n50:33 a process like it took me multiple tries\\n50:36 uh to get there\\n50:37 and then i'd say explain it to someone\\n50:39 like explain just like\\n50:41 explain it to someone at the level that\\n50:42 you want your audience to be just one\\n50:44 person and walk them through it uh and\\n50:47 teach them it and then see if they know\\n50:49 it and then also kind of maybe hear\\n50:51 their feedback o\", 'video_id': 'dFo10l8B6Go', '_id': 2057}, {'start': 58500, 'content': \"rn a\\n57:26 new tool\\n57:27 yeah\\n57:28 yeah there is one question uh probably\\n57:31 last one because i see we should be\\n57:32 wrapping up\\n57:33 but this question has seven upwards so i\\n57:35 think i have to ask it so question from\\n57:38 akshay is i want to know real world\\n57:40 end-to-end process of how a data\\n57:42 engineering team design build deploy and\\n57:44 monitor with structured\\n57:47 data in both real and batch i think this\\n57:49 is too much for one minute that we have\\n57:51 left\\n57:52 maybe you can give us okay an overview\\n57:56 i think i think we should have another\\n57:57 session you know dedicated to this piece\\n57:59 right\\n58:00 which which can you know last couple of\\n58:02 hours right\\n58:04 but anyways you know just to summarize\\n58:06 this you know in in the matter of time\\n58:08 is um\\n58:09 so there are different pieces of data\\n58:12 engineering right end to end so\\n58:13 first\\n58:14 if you start with the source systems\\n58:16 where data exists right it could be\\n58:18 relational database flat files cloud s3\\n58:20 all these things and you build one data\\n58:22 pipeline to pull data from source\\n58:24 systems and load into your data\\n58:26 warehouse or data lake that is your\\n58:28 centralized data hub and then you build\\n58:30 one process to expose this data because\\n58:33 this is one first part of it you have\\n58:34 all the retain data warehouse\\n58:36 but how a consumer who is interested in\\n58:38 your data will consume it so there could\\n58:40 be various methods of con consuming the\\n58:43 data in terms of you have let's say\\n58:45 reporting tool or visualization tool\\n58:48 and you have certain apis built on on\\n58:50 top of your data warehouse platforms\\n58:52 which can serve any applications in real\\n58:54 time\\n58:55 you can have some another etl layer for\\n58:58 you know um some other consumers who are\\n59:00 interested in your data so\\n59:02 this this whole end-to-end system can be\\n59:05 in batch mode also which runs daily or\\n59:07 weekly load and second thing is it can\\n59:09 be event based also so the moment data\\n59:12 arrive in your source system you can\\n59:14 have certain events listening to that\\n59:16 source system for example let's say s3\\n59:18 bucket right your file length on s3\\n59:19 bucket\\n59:20 your lambda function get triggered i am\\n59:22 talking in terms of aws terminologies\\n59:25 and that puts your reads data from s3\\n59:27 buckets and load into your data\\n59:29 warehouse so that is more real time\\n59:31 or if you talk about streaming then you\\n59:33 have kafka or any message brokers which\\n59:36 you know can connect to real-time data\\n59:38 with your warehouse right so i would say\\n59:41 just to summarize this focus not only\\n59:44 just bringing data into data warehouse\\n59:45 but a second part which is how you\\n59:48 expose that data if nobody is able to\\n59:51 consumer data consume your data then\\n59:53 your data warehouse is not uh worthy or\\n59:55 useful at all right\\n59:58 yeah thanks a lot um\\n1:00:01 what's the best way to find you if\\n1:00:03 so\", 'video_id': 'FljnbUQ796w', '_id': 2319}]\n",
      "RES  ← search call_GOai5ljTbA8zzNPnQwFZtAJO [{'start': 21000, 'content': \"at this stage\\n21:03 you think like do I even need machine\\n21:06 learing here or it's more like\\n21:07 analytical project absolutely uh okay so\\n21:12 as soon as we uh take off the Inception\\n21:14 phase this is where the data science and\\n21:17 the data scientists and analyst come\\n21:18 together and we brainstorm about the\\n21:21 solution so we discuss about the how and\\n21:24 at this point we understand whether this\\n21:25 is a a data science project that would\\n21:28 involve um that would involve machine\\n21:31 learning or a data analytics whether\\n21:33 it's uh it's a hybrid between that the\\n21:36 two different uh sub teams uh in the\\n21:38 data science and\\n21:40 analytics um to be honest we do have um\\n21:44 some let's say idea when the business\\n21:47 stakeholders discuss about the problem\\n21:50 and we may have already decided that\\n21:52 this point that this is a data science\\n21:53 project or data analytics but at the\\n21:55 assumtion we're absolutely certain that\\n21:57 you you know what this is 100% the data\\n22:00 science um project for instance it's\\n22:03 just a confirmation that we had when\\n22:06 when we\\n22:07 started and depending whether it is a\\n22:10 data science project or it is not I\\n22:12 guess the next step would be different\\n22:14 right absolutely\\n22:16 yeah it's data science project then you\\n22:20 say okay like I'm a data scientist I\\n22:22 cannot help you then somebody else takes\\n22:24 this over right um not really I'm the\\n22:28 accountable for both data science and\\n22:30 analytics project the only difference is\\n22:33 that if it's a it's an analytics project\\n22:36 the technical lead that will work that\\n22:38 will work on the project is going to be\\n22:41 um a data analyst instead of a data\\n22:43 scientist uh I still hold the\\n22:45 accountability of making sure that the\\n22:47 product is is delivered end to\\n22:49 end so what's the next step or is it\\n22:52 different different\\n22:54 projects uh not really uh as soon as you\\n22:57 have have an idea uh and you have\\n22:59 defined the how of um of solving the uh\\n23:03 the problem statement um this is where\\n23:05 we move into the uh research and\\n23:08 development phase this is the Hardcore\\n23:11 um modeling steps um in data science\\n23:15 where we follow all the different agile\\n23:17 methodologies uh spring planning\\n23:19 standups retrospective all The Usual\\n23:21 Suspects are usually uh there where we\\n23:24 start tackling all the different uh\\n23:26 stories that we have defined in a in a\\n23:29 cound board for instance um and we\\n23:32 Define Sprints this is the goal for\\n23:35 Sprint one Sprint to and uh yeah this is\\n23:38 where we start build building uh\\n23:40 whatever that that solution might uh\\n23:42 look like uh we also make sure that the\\n23:44 stakeholders are closely uh working with\\n23:47 us because you have to make sure that um\\n23:51 it's a it's a common problem that we're\\n23:54 trying to tackle and you want to make\\n23:55 sure that the business stakeholders are\\n23:57 part of the team and they're not \", 'video_id': '1pExOVuCF8Q', '_id': 428}, {'start': 19500, 'content': \"4 what the data is is not actually there\\n19:36 which means that this is a noo and when\\n19:38 when that happens although it doesn't\\n19:40 happen frequently this is a fail F\\n19:42 scenario and then we say you know what\\n19:44 we cannot proceed that let's take the\\n19:45 second in\\n19:47 line but this happens later right so at\\n19:50 the business understanding step\\n19:51 absolutely you come with this definition\\n19:53 of done uh document for a project which\\n19:55 is like two three pages long right and\\n19:57 then I guess you proceed to The Next\\n19:59 Step which is you mentioned checking\\n20:02 data in\\n20:04 exactly so so as everybody has signed\\n20:07 off this uh document uh the business\\n20:10 stakeholders uh data scientist which is\\n20:12 uh me in that case data Engineers uh\\n20:14 every single person involved then we\\n20:16 proceed to the next phase which is this\\n20:18 is where the data\\n20:20 signy um invol starts to to kick in yes\\n20:25 Inception you can think of it as the\\n20:28 edav exploratory data analysis where we\\n20:31 try to ensure that we have everything\\n20:32 that we need uh that includes uh access\\n20:35 to the data if the data is already\\n20:37 present any um gdpr concerns that we\\n20:40 might encounter\\n20:43 um explore the data sources as in\\n20:46 different distributions and this kind of\\n20:48 um concern that we might have uh so yeah\\n20:51 that's Prett much\\n20:53 it is this uh like at which stage do you\\n20:57 actually so you said this is when data\\n21:00 science kicks in is this at this stage\\n21:03 you think like do I even need machine\\n21:06 learing here or it's more like\\n21:07 analytical project absolutely uh okay so\\n21:12 as soon as we uh take off the Inception\\n21:14 phase this is where the data science and\\n21:17 the data scientists and analyst come\\n21:18 together and we brainstorm about the\\n21:21 solution so we discuss about the how and\\n21:24 at this point we understand whether this\\n21:25 is a a data science project that would\\n21:28 involve um that would involve machine\\n21:31 learning or a data analytics whether\\n21:33 it's uh it's a hybrid between that the\\n21:36 two different uh sub teams uh in the\\n21:38 data science and\\n21:40 analytics um to be honest we do have um\\n21:44 some let's say idea when the business\\n21:47 stakeholders discuss about the problem\\n21:50 and we may have already decided that\\n21:52 this point that this is a data science\\n21:53 project or data analytics but at the\\n21:55 assumtion we're absolutely certain that\\n21:57 you you know what this is 100% the data\\n22:00 science um project for instance it's\\n22:03 just a confirmation that we had when\\n22:06 when we\\n22:07 started and depending whether it is a\\n22:10 data science project or it is not I\\n22:12 guess the next step would be different\\n22:14 right absolutely\\n22:16 yeah it's data science project then you\\n22:20 say okay like I'm a data scientist I\\n22:22 cannot help you then somebody else takes\\n22:24 this over right um not really I'm the\\n22:28 accountable for both data science and\\n22:30 \", 'video_id': '1pExOVuCF8Q', '_id': 427}, {'start': 4500, 'content': \"4:51 this is uh demand forecasting and\\n4:54 recommendation so inventory optimization\\n4:58 that's quite interesting yeah thanks for\\n5:00 sharing so uh i've been following you on\\n5:03 linkedin for quite a while and uh i\\n5:06 think you post regularly like every like\\n5:08 maybe every week every two weeks\\n5:11 i see posts from you then some time ago\\n5:14 i think maybe it was six months ago like\\n5:16 it wasn't super recent uh\\n5:19 i think it goes uh like a few months ago\\n5:22 yeah so you shared the link and\\n5:25 you shared the sort of post and the post\\n5:28 started with\\n5:29 do you need\\n5:30 a data science manager or a data science\\n5:33 expert can you tell us more about this\\n5:35 post\\n5:37 yeah uh i remember this post very well\\n5:40 and this post was about differences\\n5:42 between data science manager and data\\n5:45 science expert\\n5:46 and these two positions are often\\n5:49 confused even in data science world and\\n5:52 often uh people forgot many aspects of\\n5:56 managerial tasks\\n5:58 so\\n5:59 i often got\\n6:01 job offers from various head hunters on\\n6:04 nicotine\\n6:05 and job titles were data science manager\\n6:08 or data science team leader\\n6:10 but when i analyzed requirements i could\\n6:14 see that 80 percent of them were very\\n6:17 technical for example python programming\\n6:20 machine learning solutions deployment\\n6:22 kubernetes docker\\n6:24 advanced libraries such as tensorflow\\n6:27 python etc\\n6:29 and only 20\\n6:31 of the requirements had anything to do\\n6:34 with soft skills typical for managers\\n6:37 such as team management stakeholders\\n6:40 expectation\\n6:42 management communication building\\n6:44 relations and strategy for the company\\n6:47 so very often people confuse a data\\n6:50 science manager with data science expert\\n6:52 and i know\\n6:53 data science is a young field and people\\n6:56 don't know what requirements for this\\n6:58 position should be\\n7:00 and don't know what kind of person they\\n7:03 need in their companies\\n7:05 so i want to spread awareness and save\\n7:07 time in the process of building a data\\n7:10 science team in organization\\n7:13 who do you think creates such job\\n7:16 listings is it uh\\n7:17 like is it coming from management who\\n7:19 might not necessarily yet know what they\\n7:21 actually need from a manager or like who\\n7:24 usually creates this post do you have\\n7:26 any um\\n7:28 i think that\\n7:30 usually is created by some guys from i.t\\n7:33 and because it's head of id head of bi\\n7:36 or\\n7:37 somebody like\\n7:39 this\\n7:40 and he or she\\n7:41 uh doesn't know exactly how data science\\n7:44 works what is\\n7:46 more important in which position on\\n7:49 which position\\n7:50 um or sometimes hr\\n7:54 did some some job offers yeah and they\\n7:57 don't have enough knowledge about these\\n8:00 positions and because data science okay\\n8:03 technical\\n8:04 requirements uh team management okay\\n8:07 team management one point or maybe two\\n8:09 points\\n8:11 what do you think should actually be the\\n8:12 balance like somebody is looking for a\\n8:14 manager should it be\\n8:17\", 'video_id': 'hFmIgaN-F8Y', '_id': 2873}, {'start': 7500, 'content': \"much longer so\\n7:13 they told me oh you should do data\\n7:14 science and\\n7:17 back then i had no idea i had no idea\\n7:18 what data science was so i had googled\\n7:20 data science and kind of fell\\n7:24 i wouldn't say i fell in love with it\\n7:25 straight away because i didn't know what\\n7:26 it was\\n7:27 and i actually started using kaggle\\n7:30 trying to do different things i did\\n7:32 almost every mistake that\\n7:34 every new data scientist would would\\n7:36 have would have made\\n7:37 on their career and their journey and\\n7:40 then i managed to\\n7:42 actually apply applied for a few data\\n7:43 science roles even though i didn't have\\n7:45 any experience\\n7:46 got rejected for all of them and then i\\n7:49 eventually\\n7:50 made it into a role with the bank so one\\n7:54 of australia's largest banks within the\\n7:55 digital\\n7:56 area so i was doing more along the same\\n8:00 lines of what i was doing before but in\\n8:02 a different space\\n8:02 so think of all the campaign targeting\\n8:05 and\\n8:06 looking at the different click funnels\\n8:08 and different things like that on their\\n8:09 website\\n8:10 so same thing but this time with python\\n8:12 right well this time\\n8:14 i i tried using python but it was not\\n8:16 very good\\n8:17 so sql again mostly sql okay\\n8:21 but the the thing that helped me bridge\\n8:23 into the data science world was\\n8:25 we actually had an opportunity to apply\\n8:27 data science to some of the problems\\n8:28 within that digital space\\n8:30 so one of my first few projects i\\n8:33 actually got to work hand in hand with\\n8:34 the data science team\\n8:36 and after that project i got absorbed\\n8:38 into the data science team so that was\\n8:39 around\\n8:40 when i became a data scientist by title\\n8:42 only\\n8:44 which year was it oh it must have been\\n8:49 2016 i think\\n8:51 2016. sounds about right it's still\\n8:54 around that time when companies had no\\n8:56 clue what data science is right\\n8:57 i think so i think it things haven't\\n9:00 really changed much in\\n9:01 yes exactly\\n9:05 um but yeah after i so i moved into the\\n9:08 data science team i started working on\\n9:10 more traditional machine learning\\n9:11 projects so\\n9:12 think of all like the customer\\n9:15 propensity modeling\\n9:16 um looking at time series forecasting\\n9:20 we actually did a lot of experimentation\\n9:22 as well so\\n9:24 things about it was more it was still\\n9:26 within the campaign and the marketing\\n9:28 space but it was much more rigorous in\\n9:30 terms of how you would actually run the\\n9:31 experiments and how you\\n9:33 examine the results with all the\\n9:35 statistical testing and\\n9:36 everything up front as well so the\\n9:38 target control groups\\n9:39 but with more rigor so i spent a lot of\\n9:42 time doing that\\n9:43 and then towards the end of my three\\n9:46 years\\n9:46 in the data science team at the bank i\\n9:48 started working more on data assets\\n9:50 so it was more of a exploratory data\\n9:54 role\\n9:55 but i would also be implementing the\\n9:57 final\\n9:58 data products that we were using across\\n10:00 the differ\", 'video_id': 'HVQ0DZOQcts', '_id': 2956}, {'start': 72000, 'content': \"t things\\n1:04:46 like that\\n1:04:47 that's applying everywhere the flip side\\n1:04:50 of that is\\n1:04:51 if you don't apply anywhere and you\\n1:04:54 literally just\\n1:04:55 only go through referral so\\n1:04:59 a lot of the it's difficult both ways\\n1:05:02 for people who are breaking into the\\n1:05:04 industry um there's just so much\\n1:05:06 competition\\n1:05:07 and the area is just so hot so the\\n1:05:10 those are the two different ways that\\n1:05:11 you can apply for these roles\\n1:05:13 but no one really talks about how you\\n1:05:15 get to the stage where you can start\\n1:05:17 applying or even getting referrals\\n1:05:19 so the most important thing for anyone\\n1:05:21 trying to break into data science would\\n1:05:22 be to\\n1:05:23 you essentially need a project portfolio\\n1:05:26 um\\n1:05:28 there's there's no other way essentially\\n1:05:30 not in this competition\\n1:05:32 not in this competitive environment um\\n1:05:35 it's either\\n1:05:36 if you're lucky lucky enough and your\\n1:05:38 company just happens to have an opening\\n1:05:40 for a data scientist\\n1:05:41 and you're in an adjacent team that you\\n1:05:43 can just kind of they give a chance to\\n1:05:45 you\\n1:05:45 to to jump into that data science team\\n1:05:47 like i did\\n1:05:49 you could be lucky very very rare\\n1:05:52 um most of the time people who are\\n1:05:55 coming into\\n1:05:56 data science they'll the data science\\n1:05:58 roles they want people with experience\\n1:06:00 otherwise they would they would just\\n1:06:02 hire someone else with experience\\n1:06:04 so the way to combat your lack of\\n1:06:06 experience is to demonstrate what you\\n1:06:08 can do\\n1:06:09 and one of the only ways that you can\\n1:06:11 demonstrate what you can do in a\\n1:06:12 quantifiable way\\n1:06:14 is to have a project that's public\\n1:06:17 that you can share with the recruiters\\n1:06:19 with people who might be in the hiring\\n1:06:21 management team or if you maybe you know\\n1:06:25 someone in the company who knows\\n1:06:26 other people so this is where your\\n1:06:28 network really comes in\\n1:06:30 but if you don't have a portfolio to\\n1:06:32 show someone\\n1:06:33 um it doesn't matter if you who you know\\n1:06:36 because they can't\\n1:06:37 they can't vouch for you essentially so\\n1:06:40 i would definitely say project portfolio\\n1:06:42 it with as best\\n1:06:44 programming standards as possible um try\\n1:06:47 to avoid\\n1:06:47 a lot of the common pitfalls that we see\\n1:06:50 a lot in\\n1:06:51 beginner projects um i can talk about\\n1:06:54 them a lot more but we'll\\n1:06:55 probably be here for a little bit i can\\n1:06:56 imagine what you talk about like this\\n1:06:59 jupiter notebook without comments where\\n1:07:00 you need to execute something in some\\n1:07:02 particular order\\n1:07:03 just dumped where without any yeah\\n1:07:05 comments without reading\\n1:07:07 out requirements.txt file things like\\n1:07:10 that right\\n1:07:11 yeah maybe we can do a future session\\n1:07:13 where it's like we'll just point out\\n1:07:14 like\\n1:07:15 common mistakes made by beginners\", 'video_id': 'HVQ0DZOQcts', '_id': 2999}]\n",
      "RES  ← search call_EhsUQCkFdek7Hrvm5eVv8XsV [{'start': 3000, 'content': \"2:49 conferences mostly in and around\\n2:51 Amsterdam with by data\\n2:54 so what did you do as a data science\\n2:56 indicator you said you your\\n2:59 responsibilities included creating\\n3:01 courses yes that's good yeah yeah so at\\n3:05 the code 80 Driven Academy we teach a\\n3:07 lot of courses on every thing data\\n3:09 science so some are very generic like an\\n3:11 introduction to python for data analysts\\n3:14 or an introduction to data science for\\n3:17 instance but we also create a lot of\\n3:20 courses very specifically targeted\\n3:21 towards a specific audience so for\\n3:23 instance I created a deep learning with\\n3:25 NLP course or a an unsupervised learning\\n3:28 course and those are more detailed or\\n3:30 more specific topics and then gave me an\\n3:32 opportunity to really dive into that\\n3:34 topic and create good exercises and\\n3:36 assignments and material on that that\\n3:38 was really fun yeah I think I spoke with\\n3:41 folks from your company from go data\\n3:43 driven at the restaurant by data by Con\\n3:46 in Berlin and as far as I remember\\n3:49 you're doing education and consultancy\\n3:52 right that's yeah\\n3:54 so I was mostly a data science educator\\n3:57 for about two years but I strongly\\n4:00 believe that you can't be a good teacher\\n4:02 if you don't also have hands-on\\n4:03 experience so I I like to really when I\\n4:06 do courses or when I teach courses\\n4:08 really tell a lot of anecdotes about my\\n4:11 experiences and in my work because it\\n4:14 speaks more to the imagination of why\\n4:15 we're doing this than just talking about\\n4:17 the concepts so while I really enjoyed\\n4:20 it I do feel like after two years mostly\\n4:22 focusing on the educational side I I\\n4:25 need some hands-on experience and also I\\n4:27 was really missing this decoding bit so\\n4:29 that's uh so so the ideal situation for\\n4:32 me is to do both trainings and education\\n4:34 and also work as a data scientist and\\n4:37 combine that in some way do you still\\n4:40 teach\\n4:42 uh occasionally some courses but I'm\\n4:44 more focused on my lead data science\\n4:46 role at the moment\\n4:47 what do you do as a lead data scientist\\n4:51 um I'm with a company where\\n4:53 um I'm mostly focused on building a\\n4:55 community of practice there they just\\n4:57 went through a transition in their the\\n4:59 way that they organize their teams and I\\n5:01 want to make sure that all the data\\n5:03 scientists still communicate clearly\\n5:05 with each other get to exchange\\n5:06 knowledge but also increase the maturity\\n5:09 level of the data science products that\\n5:10 we produce so make sure that we are not\\n5:13 just everyone doing something on their\\n5:15 own time behind their own laptop but\\n5:17 bringing them together make sure that we\\n5:18 actually get to mature well-functioning\\n5:21 monitored data science products\\n5:24 yeah this is such an interesting topic\\n5:25 but I'm afraid or I want to ask more\\n5:29 about that intent if we run out of\\n5:31 questions uh yeah because the the main\\n5:33 topic for today is actually data center\\n5\", 'video_id': 't3HDdVWQzNM', '_id': 6132}, {'start': 7500, 'content': \"much longer so\\n7:13 they told me oh you should do data\\n7:14 science and\\n7:17 back then i had no idea i had no idea\\n7:18 what data science was so i had googled\\n7:20 data science and kind of fell\\n7:24 i wouldn't say i fell in love with it\\n7:25 straight away because i didn't know what\\n7:26 it was\\n7:27 and i actually started using kaggle\\n7:30 trying to do different things i did\\n7:32 almost every mistake that\\n7:34 every new data scientist would would\\n7:36 have would have made\\n7:37 on their career and their journey and\\n7:40 then i managed to\\n7:42 actually apply applied for a few data\\n7:43 science roles even though i didn't have\\n7:45 any experience\\n7:46 got rejected for all of them and then i\\n7:49 eventually\\n7:50 made it into a role with the bank so one\\n7:54 of australia's largest banks within the\\n7:55 digital\\n7:56 area so i was doing more along the same\\n8:00 lines of what i was doing before but in\\n8:02 a different space\\n8:02 so think of all the campaign targeting\\n8:05 and\\n8:06 looking at the different click funnels\\n8:08 and different things like that on their\\n8:09 website\\n8:10 so same thing but this time with python\\n8:12 right well this time\\n8:14 i i tried using python but it was not\\n8:16 very good\\n8:17 so sql again mostly sql okay\\n8:21 but the the thing that helped me bridge\\n8:23 into the data science world was\\n8:25 we actually had an opportunity to apply\\n8:27 data science to some of the problems\\n8:28 within that digital space\\n8:30 so one of my first few projects i\\n8:33 actually got to work hand in hand with\\n8:34 the data science team\\n8:36 and after that project i got absorbed\\n8:38 into the data science team so that was\\n8:39 around\\n8:40 when i became a data scientist by title\\n8:42 only\\n8:44 which year was it oh it must have been\\n8:49 2016 i think\\n8:51 2016. sounds about right it's still\\n8:54 around that time when companies had no\\n8:56 clue what data science is right\\n8:57 i think so i think it things haven't\\n9:00 really changed much in\\n9:01 yes exactly\\n9:05 um but yeah after i so i moved into the\\n9:08 data science team i started working on\\n9:10 more traditional machine learning\\n9:11 projects so\\n9:12 think of all like the customer\\n9:15 propensity modeling\\n9:16 um looking at time series forecasting\\n9:20 we actually did a lot of experimentation\\n9:22 as well so\\n9:24 things about it was more it was still\\n9:26 within the campaign and the marketing\\n9:28 space but it was much more rigorous in\\n9:30 terms of how you would actually run the\\n9:31 experiments and how you\\n9:33 examine the results with all the\\n9:35 statistical testing and\\n9:36 everything up front as well so the\\n9:38 target control groups\\n9:39 but with more rigor so i spent a lot of\\n9:42 time doing that\\n9:43 and then towards the end of my three\\n9:46 years\\n9:46 in the data science team at the bank i\\n9:48 started working more on data assets\\n9:50 so it was more of a exploratory data\\n9:54 role\\n9:55 but i would also be implementing the\\n9:57 final\\n9:58 data products that we were using across\\n10:00 the differ\", 'video_id': 'HVQ0DZOQcts', '_id': 2956}, {'start': 57000, 'content': \" yeah we have a question and i'm\\n52:22 interested about\\n52:23 uh your take if\\n52:26 um what is in your in your opinion the\\n52:29 difference between\\n52:32 machine learning and data science well\\n52:34 that's uh\\n52:36 that is a hard question to to answer\\n52:39 because i don't think there is consensus\\n52:41 on the on the industry i do see\\n52:44 personally and this is just my personal\\n52:46 opinion\\n52:47 i do see machine learning as a more\\n52:51 hands-on practical side of the equation\\n52:54 and i see data science\\n52:57 as a more theoretical field\\n53:00 that is just me a lot of people will\\n53:02 definitely disagree\\n53:04 a lot of companies use these titles\\n53:06 interchangeably so like you're a data\\n53:08 scientist and what you're doing is\\n53:10 very hands-on and you're a machine\\n53:12 learning person or what you do is very\\n53:14 theoretical but i do i do sort of like\\n53:16 separate those two in my head like that\\n53:18 way that machine learning is more\\n53:20 hands-on\\n53:21 more let's build something let's put it\\n53:23 out there uh\\n53:24 data science is more science right it's\\n53:27 more\\n53:28 theories more let's create things that\\n53:31 don't exist\\n53:32 right now so that's the way i look at it\\n53:34 interesting so the way i look at this\\n53:36 is a bit different so it's from a\\n53:38 different angle\\n53:39 so the way i think about this so you\\n53:42 have data science and machine learning\\n53:44 is one of the tools\\n53:45 there but there are other tools so\\n53:48 like for example if you are solving a\\n53:51 problem with data science you don't\\n53:53 always need to go\\n53:54 and take machine learning and use it as\\n53:56 a tool maybe there is a simpler\\n53:58 approach that you can use maybe you can\\n54:00 just use i like that one yeah\\n54:02 i definitely like that way so you look\\n54:04 at machine learning as a subset of\\n54:07 data not a subset it's like uh\\n54:12 you know you are a carpenter and you\\n54:15 have different tools\\n54:16 right so one thing you have i don't know\\n54:19 what kind of tools carpenters have\\n54:21 um hammers\\n54:25 and then maybe a tool set with hum like\\n54:27 different hammers\\n54:28 this would be machine learning right and\\n54:30 then there is a different\\n54:31 set of uh tools that would be maybe\\n54:34 something else\\n54:35 i like it i like it yeah but so data\\n54:37 scientists a data scientist to you will\\n54:40 be somebody that's capable of using\\n54:42 machine learning but it's also capable\\n54:44 of doing\\n54:44 other stuff yeah or using other\\n54:47 different tool sets\\n54:48 than not only machine learning yeah i\\n54:50 like that i haven't seen other people\\n54:53 um actively saying this so i'm not sure\\n54:56 like\\n54:56 if there is consensus\\n54:59 i like to be honest i've seen yeah i've\\n55:01 seen these concepts\\n55:03 used all over the place for two\\n55:04 different things yeah\\n55:06 so i'm not sure there is consensus\\n55:09 okay so we have a question from\\n55:12 ali i am an application developer\\n55:15 uh manager uh so\\n55:19 there is a lot of obligations s\", 'video_id': 'xVYOdRrN7hw', '_id': 7435}, {'start': 4500, 'content': \"4:51 this is uh demand forecasting and\\n4:54 recommendation so inventory optimization\\n4:58 that's quite interesting yeah thanks for\\n5:00 sharing so uh i've been following you on\\n5:03 linkedin for quite a while and uh i\\n5:06 think you post regularly like every like\\n5:08 maybe every week every two weeks\\n5:11 i see posts from you then some time ago\\n5:14 i think maybe it was six months ago like\\n5:16 it wasn't super recent uh\\n5:19 i think it goes uh like a few months ago\\n5:22 yeah so you shared the link and\\n5:25 you shared the sort of post and the post\\n5:28 started with\\n5:29 do you need\\n5:30 a data science manager or a data science\\n5:33 expert can you tell us more about this\\n5:35 post\\n5:37 yeah uh i remember this post very well\\n5:40 and this post was about differences\\n5:42 between data science manager and data\\n5:45 science expert\\n5:46 and these two positions are often\\n5:49 confused even in data science world and\\n5:52 often uh people forgot many aspects of\\n5:56 managerial tasks\\n5:58 so\\n5:59 i often got\\n6:01 job offers from various head hunters on\\n6:04 nicotine\\n6:05 and job titles were data science manager\\n6:08 or data science team leader\\n6:10 but when i analyzed requirements i could\\n6:14 see that 80 percent of them were very\\n6:17 technical for example python programming\\n6:20 machine learning solutions deployment\\n6:22 kubernetes docker\\n6:24 advanced libraries such as tensorflow\\n6:27 python etc\\n6:29 and only 20\\n6:31 of the requirements had anything to do\\n6:34 with soft skills typical for managers\\n6:37 such as team management stakeholders\\n6:40 expectation\\n6:42 management communication building\\n6:44 relations and strategy for the company\\n6:47 so very often people confuse a data\\n6:50 science manager with data science expert\\n6:52 and i know\\n6:53 data science is a young field and people\\n6:56 don't know what requirements for this\\n6:58 position should be\\n7:00 and don't know what kind of person they\\n7:03 need in their companies\\n7:05 so i want to spread awareness and save\\n7:07 time in the process of building a data\\n7:10 science team in organization\\n7:13 who do you think creates such job\\n7:16 listings is it uh\\n7:17 like is it coming from management who\\n7:19 might not necessarily yet know what they\\n7:21 actually need from a manager or like who\\n7:24 usually creates this post do you have\\n7:26 any um\\n7:28 i think that\\n7:30 usually is created by some guys from i.t\\n7:33 and because it's head of id head of bi\\n7:36 or\\n7:37 somebody like\\n7:39 this\\n7:40 and he or she\\n7:41 uh doesn't know exactly how data science\\n7:44 works what is\\n7:46 more important in which position on\\n7:49 which position\\n7:50 um or sometimes hr\\n7:54 did some some job offers yeah and they\\n7:57 don't have enough knowledge about these\\n8:00 positions and because data science okay\\n8:03 technical\\n8:04 requirements uh team management okay\\n8:07 team management one point or maybe two\\n8:09 points\\n8:11 what do you think should actually be the\\n8:12 balance like somebody is looking for a\\n8:14 manager should it be\\n8:17\", 'video_id': 'hFmIgaN-F8Y', '_id': 2873}, {'start': 7500, 'content': \"among other\\n7:54 things the the tools like how to make\\n7:55 research\\n7:57 reproducible right or yeah so i'm going\\n8:00 to be\\n8:01 you know some of it is going to be\\n8:02 teaching statistics some is going to be\\n8:04 supervising\\n8:05 um you know students as they you know\\n8:08 are trying to do\\n8:09 end-to-end data science projects so a\\n8:11 lot of these people you know in an\\n8:12 applied data science program a lot of\\n8:14 them\\n8:14 want to go on to be data scientists and\\n8:16 not academic researchers\\n8:18 um so i'm i'm gonna do you know\\n8:22 i think maybe pursuing tools for\\n8:24 academic researchers is maybe a research\\n8:26 area that i like\\n8:28 and then my day-to-day teaching will\\n8:30 probably be very applied\\n8:31 you know how do we get junior data\\n8:34 scientists data scientists that are just\\n8:35 about to go to the workforce in a few\\n8:37 months\\n8:38 um you know at a pretty high level you\\n8:42 know of awareness of the issues the\\n8:44 knowledge of the tools in the space\\n8:46 you know able to make some educated\\n8:49 choices\\n8:50 about how to manage their data science\\n8:52 projects\\n8:54 yeah that's something that universities\\n8:56 from what i see\\n8:57 are missing right now this end-to-end uh\\n9:00 overview of of data science projects so\\n9:03 this is\\n9:04 uh this is really great this is\\n9:05 something that\\n9:07 yeah i'm so excited to do it but it's\\n9:09 like making a data science curriculum\\n9:12 it's like a lot of the work is still to\\n9:13 be done like we have to lay out what is\\n9:15 a data science curriculum and what\\n9:17 has to be there um and i suspect a lot\\n9:20 of universities are going to be doing\\n9:22 this in the next couple of years\\n9:24 um because of it's like you said i mean\\n9:27 and like it was in my experience most of\\n9:29 data science i just learned it\\n9:31 by googling things when i talk to you on\\n9:34 twitter and ask you about this\\n9:36 so when i reached out to you saying hey\\n9:39 like i want to talk to somebody about\\n9:41 this role of developer advocacy\\n9:43 and you said you replied to me that\\n9:47 this is such an interesting job and that\\n9:49 you had no idea\\n9:51 that this job existed until you you got\\n9:54 it so can you tell us this story a bit\\n9:56 in more details how did it happen yeah\\n10:00 um so i i really enjoyed you know\\n10:02 throughout my phd\\n10:04 when i wanted to get to work on data\\n10:06 science i would often just make myself\\n10:08 like weekend projects\\n10:10 um and so for one of them i had taken\\n10:13 style gan which is a big beautiful gan\\n10:16 that was released by nvidia with all the\\n10:18 code and the trained model too\\n10:20 um and i i trained it on\\n10:23 a bunch of frames from videos of myself\\n10:26 and different outfits i had in my closet\\n10:29 um and then i i made you know after it\\n10:31 was trained i\\n10:32 just moved around you know the latent\\n10:34 space and i patched it together and i\\n10:36 made a video that was just like you know\\n10:37 morphing on my face\\n10:39 with different accessories around it and\\n10:42 i po\", 'video_id': 'jv5W4jXk4P4', '_id': 3555}]\n",
      "RES  ← research_tool call_wHvReKbl0C8TKQPAWmym01Sd stage=2 explored_keywords=[ResearchKeyword(keyword='data science beginner project ideas', relevant_references=[Reference(document_id=2670, quote='If you want to look to find a project like you did to take part in an open source project it could be developing a course or maybe contributing to something.', timestamp='26:54', relevance_to_keyword='This quote emphasizes the importance of open source projects as valuable opportunities for beginners to apply their skills in real-world scenarios.', relevance_to_user_intent='This aligns with beginners seeking real-world project ideas to develop their data science skills.'), Reference(document_id=428, quote='As soon as we take off the Inception phase this is where the data science and the data scientists and analyst come together and we brainstorm about the solution.', timestamp='21:17', relevance_to_keyword='Highlights how brainstorming and collaboration can lead to innovative project ideas in data science.', relevance_to_user_intent='This indicates that projects derived from team collaboration can enhance learning experiences for beginners.'), Reference(document_id=4518, quote='As far as I know, the ones on Kaggle are like quite well prepared and clean, and everything, so I think if you just get a piece of data that at least resembles real life and then you do your best on top of it that is, you know enough of a project.', timestamp='1:00:50', relevance_to_keyword='Suggests using real-life data, like that from New York City Open Data, for building beginner-level projects irrespective of complexity.', relevance_to_user_intent='Encourages beginners to engage with real-world datasets to gain practical experience.')])] verifiable_insights=[VerifiableInsight(insight='Engaging in open source projects and collaboration is highly encouraged for beginners looking to gain hands-on experience in data science.', references=[Reference(document_id=2670, quote='If you want to look to find a project like you did to take part in an open source project it could be developing a course or maybe contributing to something.', timestamp='26:54', relevance_to_keyword='This quote emphasizes the importance of open source projects as valuable opportunities for beginners to apply their skills in real-world scenarios.', relevance_to_user_intent='This aligns with beginners seeking real-world project ideas to develop their data science skills.')]), VerifiableInsight(insight='Using real-world datasets, such as those from New York City Open Data or Kaggle, is crucial for beginners to develop practical data science projects.', references=[Reference(document_id=4518, quote='As far as I know, the ones on Kaggle are like quite well prepared and clean, and everything, so I think if you just get a piece of data that at least resembles real life and then you do your best on top of it that is, you know enough of a project.', timestamp='1:00:50', relevance_to_keyword='Suggests using real-life data, like that from New York City Open Data, for building beginner-level projects irrespective of complexity.', relevance_to_user_intent='Encourages beginners to engage with real-world datasets to gain practical experience.')])] stage_summary='Findings from this stage underscore the importance of practical applications through open-source projects and real-world datasets. Engaging in collaborative projects can enhance the learning experience for data science beginners, while working with datasets from sources like New York City Open Data or Kaggle can provide meaningful, hands-on experiences.' recommended_next_steps='To further enrich this exploration, investigate specific beginner-friendly datasets or project ideas that leverage these insights. Consider community forums or platforms specifically designed for sharing beginner data science projects.' recommended_next_keywords=['beginner data science project datasets', 'real-life data science projects', 'open source data science contributions', 'beginner-friendly data science tools', 'impactful data science projects', 'data analysis using real datasets', 'collaboration in data science projects']\n",
      "CALL → research_tool {'stage': 3, 'stage_instructions': 'Find data science bootcamps that focus on practical experience and offer project-based learning.'} call_8jEIH3ZrD0c5HZ2IDcDlpkhd\n",
      "\n",
      "=== RESEARCH stage 3 ===\n",
      "CALL → search {'query': 'data science bootcamps practical experience project-based learning'} call_jMJ1f1QB51iFoRraOnlcDXqf\n",
      "CALL → search {'query': 'project-based learning in data science bootcamps'} call_eiqYtbfqURYQTfBbGoH7nnww\n",
      "CALL → search {'query': 'hands-on data science training programs'} call_ESasnuDXIN65DGaapVyGbYyv\n",
      "RES  ← search call_ESasnuDXIN65DGaapVyGbYyv [{'start': 9000, 'content': \"s in in europe and that\\n9:16 you know that that's fine but twice in\\n9:18 my career i've been able to essentially\\n9:20 do a startup within academia at georgia\\n9:23 tech as i mentioned i founded the school\\n9:25 of computational science and engineering\\n9:27 and here at the new jersey institute of\\n9:29 technology last year i founded the\\n9:32 department of data science so i've now\\n9:35 done startups twice within academia and\\n9:37 what it requires\\n9:39 the first thing that you need are people\\n9:41 and you need people who are really\\n9:43 thinking about new directions i'd like\\n9:46 to think about\\n9:47 innovation within academia is really\\n9:50 finding interesting work at the\\n9:52 interface between traditional\\n9:54 departments and especially in computer\\n9:56 and data science we find so many new\\n9:58 areas that are just outside of a single\\n10:01 discipline for instance my own research\\n10:04 in in massive scale analytics requires\\n10:07 expertise in data science in high\\n10:10 performance computing in systems in\\n10:13 algorithms and also in application areas\\n10:16 and so we have to weave together many\\n10:18 areas of knowledge to be able to produce\\n10:22 students who are able to really be\\n10:24 impactful as they graduate and they go\\n10:26 on in their careers\\n10:28 so um very briefly what what does it\\n10:30 take to create these these schools and\\n10:32 departments it takes people and also new\\n10:35 academic programs so we spend quite some\\n10:38 time thinking about what is a new\\n10:40 program look like for instance in data\\n10:42 science this past fall we launched one\\n10:45 of the earliest bachelor's degree\\n10:47 programs in data science at the new\\n10:49 jersey institute of technology\\n10:52 we've had a master's program since 2017\\n10:55 and we're at the cusp of launching a new\\n10:58 phd program in data science so i think\\n11:00 it's quite\\n11:01 quite fascinating to be able to think\\n11:04 about what does it take to train\\n11:06 students to have degree programs in\\n11:09 these emerging areas like data science\\n11:11 and i hope other universities will also\\n11:14 repeat the model that we've created for\\n11:17 this training and preparation of\\n11:19 students for data science\\n11:22 yeah so when now i realized that so when\\n11:24 i was asking this question i was more\\n11:26 thinking about research labs rather than\\n11:28 schools but then actually schools the\\n11:30 main reason for school to exist is to\\n11:34 teach people right so these people then\\n11:36 graduate and then are qualified for\\n11:40 the job right and this is okay\\n11:42 yeah and\\n11:44 you\\n11:44 to start the school\\n11:46 you need to see like okay there is this\\n11:48 university but they and then there is\\n11:51 this area right and\\n11:53 for this area there is no school for\\n11:55 this university right and then you\\n11:57 and then what happens that so you\\n11:58 identified this gap do you just approach\\n12:00 the university and say hey\\n12:02 like how about we just start a data\\n12:04 science department or you first start\\n12:06 wor\", 'video_id': 'vZLlpsUlchQ', '_id': 6946}, {'start': 25500, 'content': \"nces and we\\n24:14 see at five kilometers 10 kilometers 15\\n24:16 kilometers how many people are what\\n24:18 percentage of people have access now\\n24:21 this is uh descriptive basically you\\n24:24 have just know the asset scenario but\\n24:27 then we try to do some more analysis to\\n24:30 see why it is so is it just the road\\n24:32 network is it new hospitals are required\\n24:35 but then the last step is the\\n24:38 prescriptive part where we are actually\\n24:40 using a mathematical model to say where\\n24:42 do you place new Hospitals now that is\\n24:45 the decision making point\\n24:47 because uh knowing all the previous\\n24:49 steps is necessary to make that decision\\n24:51 but that model the optimization model is\\n24:54 what will give you the decision making\\n24:56 capability saying that put a hospital in\\n24:59 this County or a sub-county to give\\n25:01 access to X person more population and\\n25:05 this is going to cost you so much if you\\n25:07 had five more you go from 50 to 100 just\\n25:10 example of course but giving that power\\n25:13 is what we try to incorporate into all\\n25:16 our training programs so how you can\\n25:19 actually go from descriptive and\\n25:22 diagnostic to this optimization model\\n25:24 and how you can use mathematics or\\n25:27 others to actually come up with that\\n25:29 decision making capability uh I think\\n25:32 that summarizes the core of all our\\n25:34 training programs\\n25:35 so from what I understood\\n25:38 um like\\n25:39 of course like you have multiple you\\n25:41 have multiple training programs uh and\\n25:44 they each of them have a different\\n25:47 target audience\\n25:49 right but the ones\\n25:52 um in these universities MIT and\\n25:54 University of Amsterdam who is the main\\n25:57 target audience is it people who I don't\\n26:01 know who study management or is it\\n26:03 people who study data science and\\n26:05 analytics Academy more technical other\\n26:07 less technical\\n26:10 um that's a good question they are\\n26:12 technical uh so we have for example uh\\n26:15 MBA in Big Data uh program that's an MBA\\n26:18 program but they have a big data uh\\n26:20 component so they do learn uh some of\\n26:22 this we also have a business analytics\\n26:25 course uh both here and uh at MIT the\\n26:28 Sloan School of Management so uh these\\n26:30 are the kind of students who take up\\n26:32 these courses but we are also uh have\\n26:35 been brainstorming it's not done yet\\n26:37 it's on seeing if um Healthcare or\\n26:40 education or these kind of programs can\\n26:43 also have such components but uh yeah\\n26:46 that's uh just an idea at this point uh\\n26:49 but uh like you asked in universities\\n26:51 most of our courses are targeting\\n26:53 students who are learning business\\n26:55 analytics or\\n26:57 um me in Big Data so all links are both\\n26:59 management as well as technical yeah so\\n27:02 they already know analytics and you just\\n27:04 show them the application of analytics\\n27:07 from\\n27:08 well for non-profits right foreign\\n27:19 [Music]\\n27:20 is that already no analytics you just\\n27:23 thro\", 'video_id': 'b6x5zZ3C6sQ', '_id': 1375}, {'start': 10500, 'content': \"look like for instance in data\\n10:42 science this past fall we launched one\\n10:45 of the earliest bachelor's degree\\n10:47 programs in data science at the new\\n10:49 jersey institute of technology\\n10:52 we've had a master's program since 2017\\n10:55 and we're at the cusp of launching a new\\n10:58 phd program in data science so i think\\n11:00 it's quite\\n11:01 quite fascinating to be able to think\\n11:04 about what does it take to train\\n11:06 students to have degree programs in\\n11:09 these emerging areas like data science\\n11:11 and i hope other universities will also\\n11:14 repeat the model that we've created for\\n11:17 this training and preparation of\\n11:19 students for data science\\n11:22 yeah so when now i realized that so when\\n11:24 i was asking this question i was more\\n11:26 thinking about research labs rather than\\n11:28 schools but then actually schools the\\n11:30 main reason for school to exist is to\\n11:34 teach people right so these people then\\n11:36 graduate and then are qualified for\\n11:40 the job right and this is okay\\n11:42 yeah and\\n11:44 you\\n11:44 to start the school\\n11:46 you need to see like okay there is this\\n11:48 university but they and then there is\\n11:51 this area right and\\n11:53 for this area there is no school for\\n11:55 this university right and then you\\n11:57 and then what happens that so you\\n11:58 identified this gap do you just approach\\n12:00 the university and say hey\\n12:02 like how about we just start a data\\n12:04 science department or you first start\\n12:06 working there and then you say like okay\\n12:09 like but these students are really great\\n12:11 let's start the department there or like\\n12:13 how does it feel so it really what i've\\n12:15 done is really looked at where is the\\n12:17 need and we see there's such a demand\\n12:20 right now for students educated in data\\n12:23 science and that need is really the the\\n12:26 main driver because we don't want to\\n12:28 just create programs that students won't\\n12:32 be able to find jobs in we want students\\n12:35 to be productive as they graduate and\\n12:37 data science is a growing area so first\\n12:40 is identifying the need and we look also\\n12:43 at the regions it doesn't make sense for\\n12:46 instance for every university to launch\\n12:49 every degree program\\n12:51 and have it\\n12:53 the same as every other university out\\n12:54 there so we really have to look at what\\n12:57 are the needs of the region here at new\\n12:59 jersey institute of technology over a\\n13:01 third of our students are the first time\\n13:04 anyone in their family is going to\\n13:05 college\\n13:07 and so we're taking students from a very\\n13:09 diverse background and some who are\\n13:13 really\\n13:14 new at going into higher education\\n13:17 within their families and we're making\\n13:20 them well prepared to enter the job\\n13:23 market the workforce in this region in\\n13:26 new jersey new york and the tri-state\\n13:29 area as well as to be\\n13:31 national players as well and\\n13:34 potentially international\\n13:36 um because we have students\", 'video_id': 'vZLlpsUlchQ', '_id': 6947}, {'start': 3000, 'content': \"2:49 conferences mostly in and around\\n2:51 Amsterdam with by data\\n2:54 so what did you do as a data science\\n2:56 indicator you said you your\\n2:59 responsibilities included creating\\n3:01 courses yes that's good yeah yeah so at\\n3:05 the code 80 Driven Academy we teach a\\n3:07 lot of courses on every thing data\\n3:09 science so some are very generic like an\\n3:11 introduction to python for data analysts\\n3:14 or an introduction to data science for\\n3:17 instance but we also create a lot of\\n3:20 courses very specifically targeted\\n3:21 towards a specific audience so for\\n3:23 instance I created a deep learning with\\n3:25 NLP course or a an unsupervised learning\\n3:28 course and those are more detailed or\\n3:30 more specific topics and then gave me an\\n3:32 opportunity to really dive into that\\n3:34 topic and create good exercises and\\n3:36 assignments and material on that that\\n3:38 was really fun yeah I think I spoke with\\n3:41 folks from your company from go data\\n3:43 driven at the restaurant by data by Con\\n3:46 in Berlin and as far as I remember\\n3:49 you're doing education and consultancy\\n3:52 right that's yeah\\n3:54 so I was mostly a data science educator\\n3:57 for about two years but I strongly\\n4:00 believe that you can't be a good teacher\\n4:02 if you don't also have hands-on\\n4:03 experience so I I like to really when I\\n4:06 do courses or when I teach courses\\n4:08 really tell a lot of anecdotes about my\\n4:11 experiences and in my work because it\\n4:14 speaks more to the imagination of why\\n4:15 we're doing this than just talking about\\n4:17 the concepts so while I really enjoyed\\n4:20 it I do feel like after two years mostly\\n4:22 focusing on the educational side I I\\n4:25 need some hands-on experience and also I\\n4:27 was really missing this decoding bit so\\n4:29 that's uh so so the ideal situation for\\n4:32 me is to do both trainings and education\\n4:34 and also work as a data scientist and\\n4:37 combine that in some way do you still\\n4:40 teach\\n4:42 uh occasionally some courses but I'm\\n4:44 more focused on my lead data science\\n4:46 role at the moment\\n4:47 what do you do as a lead data scientist\\n4:51 um I'm with a company where\\n4:53 um I'm mostly focused on building a\\n4:55 community of practice there they just\\n4:57 went through a transition in their the\\n4:59 way that they organize their teams and I\\n5:01 want to make sure that all the data\\n5:03 scientists still communicate clearly\\n5:05 with each other get to exchange\\n5:06 knowledge but also increase the maturity\\n5:09 level of the data science products that\\n5:10 we produce so make sure that we are not\\n5:13 just everyone doing something on their\\n5:15 own time behind their own laptop but\\n5:17 bringing them together make sure that we\\n5:18 actually get to mature well-functioning\\n5:21 monitored data science products\\n5:24 yeah this is such an interesting topic\\n5:25 but I'm afraid or I want to ask more\\n5:29 about that intent if we run out of\\n5:31 questions uh yeah because the the main\\n5:33 topic for today is actually data center\\n5\", 'video_id': 't3HDdVWQzNM', '_id': 6132}, {'start': 70500, 'content': \"1:01:46 especially if you have a software\\n1:01:47 development background or some other\\n1:01:49 type of\\n1:01:50 architecture background and you're\\n1:01:52 upskilling into the role you can be very\\n1:01:54 very successful\\n1:01:55 because a lot of software engineering\\n1:01:58 best practices\\n1:01:59 are finding their way into machine\\n1:02:01 learning engineering machine learning\\n1:02:03 architecture and the more traditional\\n1:02:05 sort of what falls under the the better\\n1:02:07 known data scientist\\n1:02:09 model development type of roles\\n1:02:12 and so you can be successful coming into\\n1:02:15 one of those teams and being a\\n1:02:16 contributor\\n1:02:17 pretty early on but you do have to have\\n1:02:19 some experience\\n1:02:21 with architecture software development\\n1:02:23 best practices\\n1:02:24 of software engineering and eventually\\n1:02:27 transition into the ml architect role\\n1:02:30 it's not something that you should be\\n1:02:32 pushed out of or that you can't upskill\\n1:02:34 into but it's a longer journey\\n1:02:36 same thing with a researcher you know\\n1:02:38 it's not something that a data scientist\\n1:02:40 can't do you can come out of a master's\\n1:02:42 or phd role\\n1:02:44 having some experience in academia doing\\n1:02:46 publications or just doing applied work\\n1:02:49 and transition into a researcher role\\n1:02:52 so you can be successful coming out of\\n1:02:54 academia you can be successful coming in\\n1:02:55 from a research assistant or one of\\n1:02:57 those types of roles\\n1:02:58 it's not necessarily barricaded and\\n1:03:02 you know exclusionary but it's a longer\\n1:03:04 learning process than you would expect\\n1:03:07 for something like a data scientist who\\n1:03:08 you can train up pretty quickly\\n1:03:11 yes indeed and we talked about the posts\\n1:03:16 you made like when you made the\\n1:03:17 announcement and\\n1:03:19 one of the things you wrote there the\\n1:03:21 data science programs are still teaching\\n1:03:23 unicorn curriculum and producing people\\n1:03:25 with six inches of depth across\\n1:03:28 six different roles uh but data science\\n1:03:31 and machine learning field\\n1:03:32 is changing so most courses\\n1:03:34 certifications and programs\\n1:03:36 programs are two years behind\\n1:03:39 and yeah i'm wondering like it made me\\n1:03:43 think like when i read this\\n1:03:44 read this like what can actually\\n1:03:47 universities do\\n1:03:48 to address this if anything can they do\\n1:03:51 anything there\\n1:03:52 and well what to do about this mismatch\\n1:03:55 of\\n1:03:55 what we study and these three roles we\\n1:03:58 talked about\\n1:03:59 because uh they are pretty hands-on\\n1:04:01 right so you cannot just\\n1:04:03 read the textbook and uh go work as an\\n1:04:06 architect right\\n1:04:08 so like you have to to put a lot of\\n1:04:10 effort so how how\\n1:04:12 how can we bridge this gap and how can\\n1:04:14 universities help us\\n1:04:16 i see two routes to it internal to\\n1:04:19 companies a lot of\\n1:04:20 we don't look at the role of business\\n1:04:23 more\\n1:04:23 or as much as w\", 'video_id': 'xCjzA_8S4kI', '_id': 7341}]\n",
      "RES  ← search call_jMJ1f1QB51iFoRraOnlcDXqf [{'start': 55500, 'content': \"th um other\\n48:22 other students\\n48:24 um i mean i think this is invaluable um\\n48:27 i i would definitely do it again\\n48:30 would you maybe consider doing a data\\n48:32 engineering bootcamp i think there are\\n48:34 in berlin there is at least one maybe\\n48:36 two not as many as data science\\n48:38 bootcamps but there are data engineering\\n48:40 bootcamps as well would you maybe now\\n48:42 consider doing this kind of bootcamp or\\n48:44 you would still go with the data science\\n48:46 one i mean that's hard to say um because\\n48:49 at the time i think when i was doing the\\n48:51 data science bootcamp they try to fit a\\n48:52 little bit of everything a little bit of\\n48:53 data analytics data engineering and data\\n48:56 science of course\\n48:57 it sounded like that when you described\\n48:59 that so you were doing docker you were\\n49:00 doing machine learning you were doing\\n49:02 uh airflow there\\n49:04 it's uh actually a little but data\\n49:06 science is also a little bit of\\n49:08 everything i'd say you need to be\\n49:10 good at\\n49:11 you know you need to know\\n49:13 to some extent a lot of things yeah yeah\\n49:17 i mean i i think it would depend on the\\n49:18 person if if you were a person that\\n49:20 i mean at the time for me i think it was\\n49:22 good uh because um i wasn't sure like\\n49:24 what part of the data science fields i\\n49:26 want to get into whether it be analytics\\n49:28 predictive modeling or engineering\\n49:30 um so it was good to go to boot camp\\n49:32 that had a little bit of everything um\\n49:33 but i guess if you're a person that\\n49:34 knows your debt setup like oh i\\n49:36 definitely want to do any of this i\\n49:37 definitely want to do data engineering\\n49:38 then i guess those boot camps\\n49:40 would be great for you so i guess they\\n49:41 kind of like you know\\n49:43 serve your niche a little more\\n49:47 yes not everyone has this luxury of\\n49:49 knowing what exactly they want to do\\n49:51 after academia right so in academia\\n49:56 you you understood that you want to do\\n49:58 coding but what exactly what does it\\n50:00 mean to the coding right\\n50:01 yeah yeah exactly yeah i mean even\\n50:03 though i knew i didn't want to work in\\n50:04 academia anymore and i wanted to do more\\n50:06 i guess like analytics and code\\n50:08 eccentric things but i also wasn't 100\\n50:11 sure exactly what i wanted to do\\n50:14 yeah maybe can you tell us a bit about\\n50:17 the projects you did at spice what kind\\n50:19 of uh like at the end i know that you\\n50:21 have some individual projects when you\\n50:23 needed to work\\n50:24 yourself on some things i think you did\\n50:26 something related to twitter analytics\\n50:28 right\\n50:29 uh yeah um so it was essentially\\n50:31 learning how to build um um a data\\n50:34 pipeline using docker to fetch data from\\n50:37 a twitter api based on whatever or\\n50:40 whatever hashtags you're interested in\\n50:41 or parameters\\n50:43 and then um and and then program and\\n50:45 then uh coding uh that a tweet um you\\n50:48 know like one of those um those bots on\\n50:50 slack wou\", 'video_id': '0wANfIvum4U', '_id': 366}, {'start': 54000, 'content': \"by quite\\n47:00 fast if you don't know what you're doing\\n47:01 and if you let things run\\n47:03 um like all night or yeah you don't pay\\n47:05 attention to what you're executing those\\n47:08 credits can go by pretty fast well at\\n47:10 least it's not here 300 dollars yeah\\n47:12 that's true\\n47:13 that's that's good and then\\n47:16 in the worst case if 300 dollars are\\n47:20 gone is gone then you can just you know\\n47:21 create maybe a new account\\n47:24 if you have your three hundred dollars\\n47:26 and the aircon\\n47:27 then\\n47:28 yeah you don't have them anywhere\\n47:31 quite painful\\n47:32 yeah okay okay\\n47:35 so let's say you\\n47:36 again needed to go through the same\\n47:39 career transitioning so you work in\\n47:41 academia doing research your contract is\\n47:44 over and you want to go to programming\\n47:47 would you again go through a data\\n47:50 science bootcamp or you would have done\\n47:52 things differently\\n47:54 i mean in my personal opinion what i\\n47:56 remember when i was uh looking for jobs\\n47:58 in the job market um a lot of companies\\n47:59 they equated like online courses and the\\n48:02 data science bootcamp has the same like\\n48:04 they actually didn't really see a\\n48:05 difference\\n48:07 um i personally think i preferred um the\\n48:09 data science boot camp and and i would\\n48:10 do it again um just because um i had a\\n48:13 teacher to talk to um uh like a couple\\n48:16 different teachers to talk to and you\\n48:17 know um and customized projects and just\\n48:20 interacting and working with um other\\n48:22 other students\\n48:24 um i mean i think this is invaluable um\\n48:27 i i would definitely do it again\\n48:30 would you maybe consider doing a data\\n48:32 engineering bootcamp i think there are\\n48:34 in berlin there is at least one maybe\\n48:36 two not as many as data science\\n48:38 bootcamps but there are data engineering\\n48:40 bootcamps as well would you maybe now\\n48:42 consider doing this kind of bootcamp or\\n48:44 you would still go with the data science\\n48:46 one i mean that's hard to say um because\\n48:49 at the time i think when i was doing the\\n48:51 data science bootcamp they try to fit a\\n48:52 little bit of everything a little bit of\\n48:53 data analytics data engineering and data\\n48:56 science of course\\n48:57 it sounded like that when you described\\n48:59 that so you were doing docker you were\\n49:00 doing machine learning you were doing\\n49:02 uh airflow there\\n49:04 it's uh actually a little but data\\n49:06 science is also a little bit of\\n49:08 everything i'd say you need to be\\n49:10 good at\\n49:11 you know you need to know\\n49:13 to some extent a lot of things yeah yeah\\n49:17 i mean i i think it would depend on the\\n49:18 person if if you were a person that\\n49:20 i mean at the time for me i think it was\\n49:22 good uh because um i wasn't sure like\\n49:24 what part of the data science fields i\\n49:26 want to get into whether it be analytics\\n49:28 predictive modeling or engineering\\n49:30 um so it was good to go to boot camp\\n49:32 that had a little bit of everything um\", 'video_id': '0wANfIvum4U', '_id': 365}, {'start': 27000, 'content': \"and so on and so on and this\\n28:11 productivity is\\n28:12 super nice also in data science because\\n28:16 it's somehow from my point of view fills\\n28:19 a gap between technical implementation\\n28:21 engineering and\\n28:23 concepts mathematical concepts to the\\n28:25 business\\n28:26 and this really uh where i feel that\\n28:31 people could improve themselves to get\\n28:34 on business level\\n28:35 um and this productivity and curiosity\\n28:39 about business purposes\\n28:41 about business kpis will definitely help\\n28:44 uh to bring your model on next level and\\n28:47 estimate it in business\\n28:48 uh kpis and yeah so\\n28:51 this is what project management uh my\\n28:54 project management experience\\n28:55 uh bring me to the data science\\n28:59 yeah yeah and yeah thanks for mentioning\\n29:02 some of the\\n29:03 presentations we had on data talks club\\n29:05 and for those who are listening\\n29:07 or watching they are on our youtube\\n29:09 channel right now i might be busy to to\\n29:12 to put the links there but uh you can\\n29:15 just go to our channel after this talk\\n29:17 and\\n29:17 uh you will find so one was uh a talk by\\n29:20 vin\\n29:21 vashishta about monetizing machine\\n29:23 learning and\\n29:24 the other one from yelena somewhere love\\n29:28 about how your machine learning project\\n29:31 will fail so these two\\n29:32 and i think the elena stock is one of\\n29:34 our top most watched\\n29:36 talks so yeah check it out and i wanted\\n29:39 to ask\\n29:40 you also so you mentioned that um\\n29:43 one of the things that helped you most\\n29:45 were like this\\n29:48 planning skill so you were able to plan\\n29:50 a project because the data science\\n29:51 project is a project and\\n29:53 because you have you had experience\\n29:55 planning projects you can\\n29:57 take this experience and apply it to\\n29:58 data science projects\\n30:00 and then then see in this big picture\\n30:03 and i'm wondering for those who do not\\n30:06 have this um this background in project\\n30:09 management\\n30:10 maybe there is a simple course or a book\\n30:13 that they can take to to get this skill\\n30:17 this planning skill maybe you have some\\n30:18 recommendation for that\\n30:20 definitely and it's uh it's a\\n30:25 fortune that it's already developed i\\n30:28 would recommend to use\\n30:29 uh the standard of the industry in data\\n30:32 mining crisp dam\\n30:34 framework it's really convenient for\\n30:37 data science projects\\n30:38 and i think this is so far the standard\\n30:42 and i also use it it's\\n30:45 nice structured and you can\\n30:48 structure your project uh based on the\\n30:51 stage\\n30:52 and of the crisp dam framework um\\n30:56 it's it's really well designed and yeah\\n30:59 so i think it's one way to go\\n31:02 and it regardless either you come from\\n31:04 project management or from\\n31:06 from whatever it's nice to use in data\\n31:09 science\\n31:10 yeah yeah this is even though it's a bit\\n31:13 old uh\\n31:14 methodology i don't know it's 20 years\\n31:16 old i think it's\\n31:17 surprisingly it's surprising that it\\n31:20 still applies to projects\\n31:\", 'video_id': 'rBKezdb9jEc', '_id': 5115}, {'start': 39000, 'content': \":25 connections can refer you to some new\\n44:28 opportunities that's why as part of your\\n44:31 plan is connecting with the the the\\n44:33 right people new people and as well\\n44:36 reaching out to those people that you\\n44:38 already know but haven't been in touch\\n44:41 for so long and share with them your\\n44:44 your story uh what you are doing right\\n44:47 now uh and um yeah just connect with\\n44:50 them and share with them and if they\\n44:51 know anything then uh tell them if you\\n44:55 know any opportunity and so and just\\n44:57 share with me or have a chat have a\\n44:59 coffee with them connect with them again\\n45:01 yeah so that's part of the\\n45:04 networking I realized that we have a lot\\n45:06 of questions from the audience the\\n45:09 audience M yes it's actually 10 that's I\\n45:12 don't know if we will be able to cover\\n45:14 all of them but we can start and uh yeah\\n45:17 so I'll start with the first\\n45:19 question okay I left my job two years\\n45:22 ago and I started learning data science\\n45:23 and python how should I the things I\\n45:27 learned in the CV and projects I made in\\n45:30 the CV okay I see that uh I left my job\\n45:34 two years ago and started\\n45:38 learning okay you can put them uh in so\\n45:42 because you left your job two two years\\n45:44 ago so right now you don't have a\\n45:46 current experience so so I would put\\n45:50 first in my resume my skills so after\\n45:53 like the\\n45:54 summary I will put my skills and then I\\n45:57 will put my practical projects my\\n46:00 practical projects and then\\n46:02 experience because to make it the first\\n46:05 thing that they see is the projects that\\n46:08 you you are doing that's that's how I\\n46:11 would recommend another thing that I did\\n46:13 myself because I also left my job when I\\n46:16 transitioner to data science which is\\n46:19 instead of moving the section of um\\n46:21 projects so practical projects I kept\\n46:24 the professional EXP\\n46:26 experience but I added so my last job\\n46:29 ended in this year and from that uh time\\n46:33 I'm doing uh self-education so I put it\\n46:36 in the professional experience as well\\n46:39 uh self-education\\n46:41 self-employment and I mentioned some of\\n46:43 the projects that I\\n46:44 did that's another way also to do\\n46:49 it and the goal here is uh to make it um\\n46:54 the first thing that they see that I\\n46:56 have experience in this field and these\\n46:58 are my\\n47:00 projects thank you another question do\\n47:03 you know any service that can help with\\n47:06 doing research on companies vacancies\\n47:09 and requirements I think this is what we\\n47:10 talked about and you said okay like you\\n47:13 should come up with top five companies\\n47:15 that you think you will like and then\\n47:18 look at the job descriptions there\\n47:21 understand the requirements\\n47:24 and if I understand question correctly\\n47:26 is it asks if I can Outsource that yeah\\n47:32 okay that's not possible you have to do\\n47:35 it yourself but I think what they are\\n47:37 asking is a Ser service maybe a platform\\n47:40\", 'video_id': 'PchwbIs0tOg', '_id': 4632}, {'start': 21000, 'content': \"at this stage\\n21:03 you think like do I even need machine\\n21:06 learing here or it's more like\\n21:07 analytical project absolutely uh okay so\\n21:12 as soon as we uh take off the Inception\\n21:14 phase this is where the data science and\\n21:17 the data scientists and analyst come\\n21:18 together and we brainstorm about the\\n21:21 solution so we discuss about the how and\\n21:24 at this point we understand whether this\\n21:25 is a a data science project that would\\n21:28 involve um that would involve machine\\n21:31 learning or a data analytics whether\\n21:33 it's uh it's a hybrid between that the\\n21:36 two different uh sub teams uh in the\\n21:38 data science and\\n21:40 analytics um to be honest we do have um\\n21:44 some let's say idea when the business\\n21:47 stakeholders discuss about the problem\\n21:50 and we may have already decided that\\n21:52 this point that this is a data science\\n21:53 project or data analytics but at the\\n21:55 assumtion we're absolutely certain that\\n21:57 you you know what this is 100% the data\\n22:00 science um project for instance it's\\n22:03 just a confirmation that we had when\\n22:06 when we\\n22:07 started and depending whether it is a\\n22:10 data science project or it is not I\\n22:12 guess the next step would be different\\n22:14 right absolutely\\n22:16 yeah it's data science project then you\\n22:20 say okay like I'm a data scientist I\\n22:22 cannot help you then somebody else takes\\n22:24 this over right um not really I'm the\\n22:28 accountable for both data science and\\n22:30 analytics project the only difference is\\n22:33 that if it's a it's an analytics project\\n22:36 the technical lead that will work that\\n22:38 will work on the project is going to be\\n22:41 um a data analyst instead of a data\\n22:43 scientist uh I still hold the\\n22:45 accountability of making sure that the\\n22:47 product is is delivered end to\\n22:49 end so what's the next step or is it\\n22:52 different different\\n22:54 projects uh not really uh as soon as you\\n22:57 have have an idea uh and you have\\n22:59 defined the how of um of solving the uh\\n23:03 the problem statement um this is where\\n23:05 we move into the uh research and\\n23:08 development phase this is the Hardcore\\n23:11 um modeling steps um in data science\\n23:15 where we follow all the different agile\\n23:17 methodologies uh spring planning\\n23:19 standups retrospective all The Usual\\n23:21 Suspects are usually uh there where we\\n23:24 start tackling all the different uh\\n23:26 stories that we have defined in a in a\\n23:29 cound board for instance um and we\\n23:32 Define Sprints this is the goal for\\n23:35 Sprint one Sprint to and uh yeah this is\\n23:38 where we start build building uh\\n23:40 whatever that that solution might uh\\n23:42 look like uh we also make sure that the\\n23:44 stakeholders are closely uh working with\\n23:47 us because you have to make sure that um\\n23:51 it's a it's a common problem that we're\\n23:54 trying to tackle and you want to make\\n23:55 sure that the business stakeholders are\\n23:57 part of the team and they're not \", 'video_id': '1pExOVuCF8Q', '_id': 428}]\n",
      "RES  ← search call_eiqYtbfqURYQTfBbGoH7nnww [{'start': 55500, 'content': \"th um other\\n48:22 other students\\n48:24 um i mean i think this is invaluable um\\n48:27 i i would definitely do it again\\n48:30 would you maybe consider doing a data\\n48:32 engineering bootcamp i think there are\\n48:34 in berlin there is at least one maybe\\n48:36 two not as many as data science\\n48:38 bootcamps but there are data engineering\\n48:40 bootcamps as well would you maybe now\\n48:42 consider doing this kind of bootcamp or\\n48:44 you would still go with the data science\\n48:46 one i mean that's hard to say um because\\n48:49 at the time i think when i was doing the\\n48:51 data science bootcamp they try to fit a\\n48:52 little bit of everything a little bit of\\n48:53 data analytics data engineering and data\\n48:56 science of course\\n48:57 it sounded like that when you described\\n48:59 that so you were doing docker you were\\n49:00 doing machine learning you were doing\\n49:02 uh airflow there\\n49:04 it's uh actually a little but data\\n49:06 science is also a little bit of\\n49:08 everything i'd say you need to be\\n49:10 good at\\n49:11 you know you need to know\\n49:13 to some extent a lot of things yeah yeah\\n49:17 i mean i i think it would depend on the\\n49:18 person if if you were a person that\\n49:20 i mean at the time for me i think it was\\n49:22 good uh because um i wasn't sure like\\n49:24 what part of the data science fields i\\n49:26 want to get into whether it be analytics\\n49:28 predictive modeling or engineering\\n49:30 um so it was good to go to boot camp\\n49:32 that had a little bit of everything um\\n49:33 but i guess if you're a person that\\n49:34 knows your debt setup like oh i\\n49:36 definitely want to do any of this i\\n49:37 definitely want to do data engineering\\n49:38 then i guess those boot camps\\n49:40 would be great for you so i guess they\\n49:41 kind of like you know\\n49:43 serve your niche a little more\\n49:47 yes not everyone has this luxury of\\n49:49 knowing what exactly they want to do\\n49:51 after academia right so in academia\\n49:56 you you understood that you want to do\\n49:58 coding but what exactly what does it\\n50:00 mean to the coding right\\n50:01 yeah yeah exactly yeah i mean even\\n50:03 though i knew i didn't want to work in\\n50:04 academia anymore and i wanted to do more\\n50:06 i guess like analytics and code\\n50:08 eccentric things but i also wasn't 100\\n50:11 sure exactly what i wanted to do\\n50:14 yeah maybe can you tell us a bit about\\n50:17 the projects you did at spice what kind\\n50:19 of uh like at the end i know that you\\n50:21 have some individual projects when you\\n50:23 needed to work\\n50:24 yourself on some things i think you did\\n50:26 something related to twitter analytics\\n50:28 right\\n50:29 uh yeah um so it was essentially\\n50:31 learning how to build um um a data\\n50:34 pipeline using docker to fetch data from\\n50:37 a twitter api based on whatever or\\n50:40 whatever hashtags you're interested in\\n50:41 or parameters\\n50:43 and then um and and then program and\\n50:45 then uh coding uh that a tweet um you\\n50:48 know like one of those um those bots on\\n50:50 slack wou\", 'video_id': '0wANfIvum4U', '_id': 366}, {'start': 54000, 'content': \"by quite\\n47:00 fast if you don't know what you're doing\\n47:01 and if you let things run\\n47:03 um like all night or yeah you don't pay\\n47:05 attention to what you're executing those\\n47:08 credits can go by pretty fast well at\\n47:10 least it's not here 300 dollars yeah\\n47:12 that's true\\n47:13 that's that's good and then\\n47:16 in the worst case if 300 dollars are\\n47:20 gone is gone then you can just you know\\n47:21 create maybe a new account\\n47:24 if you have your three hundred dollars\\n47:26 and the aircon\\n47:27 then\\n47:28 yeah you don't have them anywhere\\n47:31 quite painful\\n47:32 yeah okay okay\\n47:35 so let's say you\\n47:36 again needed to go through the same\\n47:39 career transitioning so you work in\\n47:41 academia doing research your contract is\\n47:44 over and you want to go to programming\\n47:47 would you again go through a data\\n47:50 science bootcamp or you would have done\\n47:52 things differently\\n47:54 i mean in my personal opinion what i\\n47:56 remember when i was uh looking for jobs\\n47:58 in the job market um a lot of companies\\n47:59 they equated like online courses and the\\n48:02 data science bootcamp has the same like\\n48:04 they actually didn't really see a\\n48:05 difference\\n48:07 um i personally think i preferred um the\\n48:09 data science boot camp and and i would\\n48:10 do it again um just because um i had a\\n48:13 teacher to talk to um uh like a couple\\n48:16 different teachers to talk to and you\\n48:17 know um and customized projects and just\\n48:20 interacting and working with um other\\n48:22 other students\\n48:24 um i mean i think this is invaluable um\\n48:27 i i would definitely do it again\\n48:30 would you maybe consider doing a data\\n48:32 engineering bootcamp i think there are\\n48:34 in berlin there is at least one maybe\\n48:36 two not as many as data science\\n48:38 bootcamps but there are data engineering\\n48:40 bootcamps as well would you maybe now\\n48:42 consider doing this kind of bootcamp or\\n48:44 you would still go with the data science\\n48:46 one i mean that's hard to say um because\\n48:49 at the time i think when i was doing the\\n48:51 data science bootcamp they try to fit a\\n48:52 little bit of everything a little bit of\\n48:53 data analytics data engineering and data\\n48:56 science of course\\n48:57 it sounded like that when you described\\n48:59 that so you were doing docker you were\\n49:00 doing machine learning you were doing\\n49:02 uh airflow there\\n49:04 it's uh actually a little but data\\n49:06 science is also a little bit of\\n49:08 everything i'd say you need to be\\n49:10 good at\\n49:11 you know you need to know\\n49:13 to some extent a lot of things yeah yeah\\n49:17 i mean i i think it would depend on the\\n49:18 person if if you were a person that\\n49:20 i mean at the time for me i think it was\\n49:22 good uh because um i wasn't sure like\\n49:24 what part of the data science fields i\\n49:26 want to get into whether it be analytics\\n49:28 predictive modeling or engineering\\n49:30 um so it was good to go to boot camp\\n49:32 that had a little bit of everything um\", 'video_id': '0wANfIvum4U', '_id': 365}, {'start': 19500, 'content': \"4 what the data is is not actually there\\n19:36 which means that this is a noo and when\\n19:38 when that happens although it doesn't\\n19:40 happen frequently this is a fail F\\n19:42 scenario and then we say you know what\\n19:44 we cannot proceed that let's take the\\n19:45 second in\\n19:47 line but this happens later right so at\\n19:50 the business understanding step\\n19:51 absolutely you come with this definition\\n19:53 of done uh document for a project which\\n19:55 is like two three pages long right and\\n19:57 then I guess you proceed to The Next\\n19:59 Step which is you mentioned checking\\n20:02 data in\\n20:04 exactly so so as everybody has signed\\n20:07 off this uh document uh the business\\n20:10 stakeholders uh data scientist which is\\n20:12 uh me in that case data Engineers uh\\n20:14 every single person involved then we\\n20:16 proceed to the next phase which is this\\n20:18 is where the data\\n20:20 signy um invol starts to to kick in yes\\n20:25 Inception you can think of it as the\\n20:28 edav exploratory data analysis where we\\n20:31 try to ensure that we have everything\\n20:32 that we need uh that includes uh access\\n20:35 to the data if the data is already\\n20:37 present any um gdpr concerns that we\\n20:40 might encounter\\n20:43 um explore the data sources as in\\n20:46 different distributions and this kind of\\n20:48 um concern that we might have uh so yeah\\n20:51 that's Prett much\\n20:53 it is this uh like at which stage do you\\n20:57 actually so you said this is when data\\n21:00 science kicks in is this at this stage\\n21:03 you think like do I even need machine\\n21:06 learing here or it's more like\\n21:07 analytical project absolutely uh okay so\\n21:12 as soon as we uh take off the Inception\\n21:14 phase this is where the data science and\\n21:17 the data scientists and analyst come\\n21:18 together and we brainstorm about the\\n21:21 solution so we discuss about the how and\\n21:24 at this point we understand whether this\\n21:25 is a a data science project that would\\n21:28 involve um that would involve machine\\n21:31 learning or a data analytics whether\\n21:33 it's uh it's a hybrid between that the\\n21:36 two different uh sub teams uh in the\\n21:38 data science and\\n21:40 analytics um to be honest we do have um\\n21:44 some let's say idea when the business\\n21:47 stakeholders discuss about the problem\\n21:50 and we may have already decided that\\n21:52 this point that this is a data science\\n21:53 project or data analytics but at the\\n21:55 assumtion we're absolutely certain that\\n21:57 you you know what this is 100% the data\\n22:00 science um project for instance it's\\n22:03 just a confirmation that we had when\\n22:06 when we\\n22:07 started and depending whether it is a\\n22:10 data science project or it is not I\\n22:12 guess the next step would be different\\n22:14 right absolutely\\n22:16 yeah it's data science project then you\\n22:20 say okay like I'm a data scientist I\\n22:22 cannot help you then somebody else takes\\n22:24 this over right um not really I'm the\\n22:28 accountable for both data science and\\n22:30 \", 'video_id': '1pExOVuCF8Q', '_id': 427}, {'start': 21000, 'content': \"at this stage\\n21:03 you think like do I even need machine\\n21:06 learing here or it's more like\\n21:07 analytical project absolutely uh okay so\\n21:12 as soon as we uh take off the Inception\\n21:14 phase this is where the data science and\\n21:17 the data scientists and analyst come\\n21:18 together and we brainstorm about the\\n21:21 solution so we discuss about the how and\\n21:24 at this point we understand whether this\\n21:25 is a a data science project that would\\n21:28 involve um that would involve machine\\n21:31 learning or a data analytics whether\\n21:33 it's uh it's a hybrid between that the\\n21:36 two different uh sub teams uh in the\\n21:38 data science and\\n21:40 analytics um to be honest we do have um\\n21:44 some let's say idea when the business\\n21:47 stakeholders discuss about the problem\\n21:50 and we may have already decided that\\n21:52 this point that this is a data science\\n21:53 project or data analytics but at the\\n21:55 assumtion we're absolutely certain that\\n21:57 you you know what this is 100% the data\\n22:00 science um project for instance it's\\n22:03 just a confirmation that we had when\\n22:06 when we\\n22:07 started and depending whether it is a\\n22:10 data science project or it is not I\\n22:12 guess the next step would be different\\n22:14 right absolutely\\n22:16 yeah it's data science project then you\\n22:20 say okay like I'm a data scientist I\\n22:22 cannot help you then somebody else takes\\n22:24 this over right um not really I'm the\\n22:28 accountable for both data science and\\n22:30 analytics project the only difference is\\n22:33 that if it's a it's an analytics project\\n22:36 the technical lead that will work that\\n22:38 will work on the project is going to be\\n22:41 um a data analyst instead of a data\\n22:43 scientist uh I still hold the\\n22:45 accountability of making sure that the\\n22:47 product is is delivered end to\\n22:49 end so what's the next step or is it\\n22:52 different different\\n22:54 projects uh not really uh as soon as you\\n22:57 have have an idea uh and you have\\n22:59 defined the how of um of solving the uh\\n23:03 the problem statement um this is where\\n23:05 we move into the uh research and\\n23:08 development phase this is the Hardcore\\n23:11 um modeling steps um in data science\\n23:15 where we follow all the different agile\\n23:17 methodologies uh spring planning\\n23:19 standups retrospective all The Usual\\n23:21 Suspects are usually uh there where we\\n23:24 start tackling all the different uh\\n23:26 stories that we have defined in a in a\\n23:29 cound board for instance um and we\\n23:32 Define Sprints this is the goal for\\n23:35 Sprint one Sprint to and uh yeah this is\\n23:38 where we start build building uh\\n23:40 whatever that that solution might uh\\n23:42 look like uh we also make sure that the\\n23:44 stakeholders are closely uh working with\\n23:47 us because you have to make sure that um\\n23:51 it's a it's a common problem that we're\\n23:54 trying to tackle and you want to make\\n23:55 sure that the business stakeholders are\\n23:57 part of the team and they're not \", 'video_id': '1pExOVuCF8Q', '_id': 428}, {'start': 27000, 'content': \"and so on and so on and this\\n28:11 productivity is\\n28:12 super nice also in data science because\\n28:16 it's somehow from my point of view fills\\n28:19 a gap between technical implementation\\n28:21 engineering and\\n28:23 concepts mathematical concepts to the\\n28:25 business\\n28:26 and this really uh where i feel that\\n28:31 people could improve themselves to get\\n28:34 on business level\\n28:35 um and this productivity and curiosity\\n28:39 about business purposes\\n28:41 about business kpis will definitely help\\n28:44 uh to bring your model on next level and\\n28:47 estimate it in business\\n28:48 uh kpis and yeah so\\n28:51 this is what project management uh my\\n28:54 project management experience\\n28:55 uh bring me to the data science\\n28:59 yeah yeah and yeah thanks for mentioning\\n29:02 some of the\\n29:03 presentations we had on data talks club\\n29:05 and for those who are listening\\n29:07 or watching they are on our youtube\\n29:09 channel right now i might be busy to to\\n29:12 to put the links there but uh you can\\n29:15 just go to our channel after this talk\\n29:17 and\\n29:17 uh you will find so one was uh a talk by\\n29:20 vin\\n29:21 vashishta about monetizing machine\\n29:23 learning and\\n29:24 the other one from yelena somewhere love\\n29:28 about how your machine learning project\\n29:31 will fail so these two\\n29:32 and i think the elena stock is one of\\n29:34 our top most watched\\n29:36 talks so yeah check it out and i wanted\\n29:39 to ask\\n29:40 you also so you mentioned that um\\n29:43 one of the things that helped you most\\n29:45 were like this\\n29:48 planning skill so you were able to plan\\n29:50 a project because the data science\\n29:51 project is a project and\\n29:53 because you have you had experience\\n29:55 planning projects you can\\n29:57 take this experience and apply it to\\n29:58 data science projects\\n30:00 and then then see in this big picture\\n30:03 and i'm wondering for those who do not\\n30:06 have this um this background in project\\n30:09 management\\n30:10 maybe there is a simple course or a book\\n30:13 that they can take to to get this skill\\n30:17 this planning skill maybe you have some\\n30:18 recommendation for that\\n30:20 definitely and it's uh it's a\\n30:25 fortune that it's already developed i\\n30:28 would recommend to use\\n30:29 uh the standard of the industry in data\\n30:32 mining crisp dam\\n30:34 framework it's really convenient for\\n30:37 data science projects\\n30:38 and i think this is so far the standard\\n30:42 and i also use it it's\\n30:45 nice structured and you can\\n30:48 structure your project uh based on the\\n30:51 stage\\n30:52 and of the crisp dam framework um\\n30:56 it's it's really well designed and yeah\\n30:59 so i think it's one way to go\\n31:02 and it regardless either you come from\\n31:04 project management or from\\n31:06 from whatever it's nice to use in data\\n31:09 science\\n31:10 yeah yeah this is even though it's a bit\\n31:13 old uh\\n31:14 methodology i don't know it's 20 years\\n31:16 old i think it's\\n31:17 surprisingly it's surprising that it\\n31:20 still applies to projects\\n31:\", 'video_id': 'rBKezdb9jEc', '_id': 5115}]\n",
      "RES  ← research_tool call_8jEIH3ZrD0c5HZ2IDcDlpkhd stage=3 explored_keywords=[ResearchKeyword(keyword='data science bootcamps practical experience project-based learning', relevant_references=[Reference(document_id=6132, quote='at the code 80 Driven Academy we teach a lot of courses on everything data science', timestamp='3:09', relevance_to_keyword='This mention indicates a practical learning approach through structured courses tailored for hands-on experiences.', relevance_to_user_intent='It highlights the opportunities for immersive learning in data science via courses at the academy.'), Reference(document_id=366, quote='the projects you did at spice what kind of uh like at the end i know that you have some individual projects when you needed to work', timestamp='50:17', relevance_to_keyword='Individual projects at the bootcamp emphasize the importance of applying knowledge to real-world scenarios through hands-on work.', relevance_to_user_intent=\"This aligns with the user's request for bootcamps that encourage practical project-based learning.\"), Reference(document_id=5115, quote='the crisp dam framework... is a nice structured way to structure your project', timestamp='30:28', relevance_to_keyword='Refers to using structured methodologies like CRISP-DM in data science projects, fostering practical applications and project organization.', relevance_to_user_intent='Indicates how curricula may leverage established frameworks to enhance project-based learning.')])] verifiable_insights=[VerifiableInsight(insight='Data science bootcamps such as the Code 80 Driven Academy focus on practical applications and project-based learning, highlighting their success in preparing students for real-world challenges.', references=[Reference(document_id=6132, quote='at the code 80 Driven Academy we teach a lot of courses on everything data science', timestamp='3:09', relevance_to_keyword='This mention indicates a practical learning approach through structured courses tailored for hands-on experiences.', relevance_to_user_intent='It highlights the opportunities for immersive learning in data science via courses at the academy.')]), VerifiableInsight(insight='Individual and collaborative projects within data science bootcamps significantly enhance the learning experience, allowing students to apply theoretical knowledge to practical problems.', references=[Reference(document_id=366, quote='the projects you did at spice what kind of uh like at the end i know that you have some individual projects when you needed to work', timestamp='50:17', relevance_to_keyword='Individual projects at the bootcamp emphasize the importance of applying knowledge to real-world scenarios through hands-on work.', relevance_to_user_intent=\"This aligns with the user's request for bootcamps that encourage practical project-based learning.\")])] stage_summary='The findings indicate that data science bootcamps, particularly the Code 80 Driven Academy, prioritize experiential learning with structured courses and individual projects. The emphasis on frameworks like CRISP-DM further emphasizes the importance of organized methodologies in implementing practical projects, ensuring students not only learn theory but also how to apply it effectively in real-world contexts.' recommended_next_steps='Explore specific courses and methodologies offered by data science bootcamps to identify which focus most heavily on hands-on, project-based learning. Look for student testimonials or detailed curricula that showcase practical projects.' recommended_next_keywords=['top project-based data science bootcamps', 'curriculum for data science bootcamps', 'student experience in data science bootcamps', 'success stories from data science bootcamp graduates', 'data science bootcamp comparisons', 'intensive data science training programs']\n",
      "request\n",
      "user-prompt\n",
      "practical projects\n",
      "\n",
      "\n",
      "response\n",
      "tool-call\n",
      "clarify_tool_research_task {\"query\":\"How do I learn about data science with a focus on practical projects\"}\n",
      "\n",
      "\n",
      "request\n",
      "tool-return\n",
      "<class '__main__.ResearchInstructions'> initial_request='How do I learn about data science with a focus on practical projects' refined_request='I want to learn about data science focusing on practical projects and the resources needed for that.' user_intent='The user wants to learn data science through hands-on projects and needs information about relevant resources and learning paths.' queries=['best data science courses with practical projects', 'data science project ideas for beginners', 'top resources for hands-on data science learning', 'data science bootcamps focusing on practical experience', 'how to apply data science skills in real-world projects'] instructions='Explore resources including courses, tutorials, and project ideas that emphasize practical applications of data science.'\n",
      "\n",
      "\n",
      "response\n",
      "tool-call\n",
      "research_tool {\"stage\":1,\"stage_instructions\":\"Explore resources including courses, tutorials, and project ideas that emphasize practical applications of data science.\"}\n",
      "\n",
      "\n",
      "request\n",
      "tool-return\n",
      "<class '__main__.ResearchStageReport'> stage=1 explored_keywords=[ResearchKeyword(keyword='practical applications of data science', relevant_references=[Reference(document_id=6132, quote='at the code 80 Driven Academy we teach a lot of courses on everything data science', timestamp='3:09', relevance_to_keyword='This quote provides a context for learning practical data science through structured courses.', relevance_to_user_intent='The mention of the academy indicates opportunities for applying data science practically via courses offered.'), Reference(document_id=6131, quote='I created a deep learning with NLP course or an unsupervised learning course and those are more detailed or more specific topics', timestamp='3:25', relevance_to_keyword='Courses that are specifically designed for certain data science skills show direct pathways to practical applications.', relevance_to_user_intent=\"This aligns with the user's interest in detailed, practical applications in data science.\"), Reference(document_id=4621, quote='just take some time and okay maybe have a project even if so I finish data engineering I do a project', timestamp='28:02', relevance_to_keyword='Encouragement to engage in project work highlights the importance of actual coding and real-world applications.', relevance_to_user_intent=\"This reflects the user's interest in undertaking projects as a form of practical application of their data science skills.\")])] verifiable_insights=[VerifiableInsight(insight='The Code 80 Driven Academy offers a variety of data science courses including specific tracks in deep learning and unsupervised learning, focusing on practical applications and tailored learning paths.', references=[Reference(document_id=6132, quote='at the code 80 Driven Academy we teach a lot of courses on everything data science', timestamp='3:09', relevance_to_keyword='This quote provides a context for learning practical data science through structured courses.', relevance_to_user_intent='The mention of the academy indicates opportunities for applying data science practically via courses offered.')]), VerifiableInsight(insight='Hands-on experience and projects are emphasized as essential for effectively applying skills learned in courses, reinforcing the application of theoretical knowledge in practical scenarios.', references=[Reference(document_id=4621, quote='just take some time and okay maybe have a project even if so I finish data engineering I do a project', timestamp='28:02', relevance_to_keyword='Encouragement to engage in project work highlights the importance of actual coding and real-world applications.', relevance_to_user_intent=\"This reflects the user's interest in undertaking projects as a form of practical application of their data science skills.\")])] stage_summary='Initial findings highlight the availability of practical data science courses at Code 80 Driven Academy, emphasizing specialized tracks that allow learners to delve deeply into topics like deep learning and unsupervised learning. The insights stress the importance of pairing coursework with hands-on projects, which can enhance the applicability of theoretical knowledge in real-world settings.' recommended_next_steps='Explore specific courses or projects mentioned in the findings to pursue practical applications of data science. Additionally, consider looking into how to integrate personal projects with learning to solidify understanding.' recommended_next_keywords=['specific data science courses', 'project-based learning in data science', 'real-world applications of data science', 'hands-on data science projects', 'data science bootcamps', 'mentorship in data science', 'data engineering project ideas']\n",
      "\n",
      "\n",
      "response\n",
      "tool-call\n",
      "research_tool {\"stage\":2,\"stage_instructions\":\"Find data science project ideas for beginners that can be used as practical applications.\"}\n",
      "\n",
      "\n",
      "request\n",
      "tool-return\n",
      "<class '__main__.ResearchStageReport'> stage=2 explored_keywords=[ResearchKeyword(keyword='data science beginner project ideas', relevant_references=[Reference(document_id=2670, quote='If you want to look to find a project like you did to take part in an open source project it could be developing a course or maybe contributing to something.', timestamp='26:54', relevance_to_keyword='This quote emphasizes the importance of open source projects as valuable opportunities for beginners to apply their skills in real-world scenarios.', relevance_to_user_intent='This aligns with beginners seeking real-world project ideas to develop their data science skills.'), Reference(document_id=428, quote='As soon as we take off the Inception phase this is where the data science and the data scientists and analyst come together and we brainstorm about the solution.', timestamp='21:17', relevance_to_keyword='Highlights how brainstorming and collaboration can lead to innovative project ideas in data science.', relevance_to_user_intent='This indicates that projects derived from team collaboration can enhance learning experiences for beginners.'), Reference(document_id=4518, quote='As far as I know, the ones on Kaggle are like quite well prepared and clean, and everything, so I think if you just get a piece of data that at least resembles real life and then you do your best on top of it that is, you know enough of a project.', timestamp='1:00:50', relevance_to_keyword='Suggests using real-life data, like that from New York City Open Data, for building beginner-level projects irrespective of complexity.', relevance_to_user_intent='Encourages beginners to engage with real-world datasets to gain practical experience.')])] verifiable_insights=[VerifiableInsight(insight='Engaging in open source projects and collaboration is highly encouraged for beginners looking to gain hands-on experience in data science.', references=[Reference(document_id=2670, quote='If you want to look to find a project like you did to take part in an open source project it could be developing a course or maybe contributing to something.', timestamp='26:54', relevance_to_keyword='This quote emphasizes the importance of open source projects as valuable opportunities for beginners to apply their skills in real-world scenarios.', relevance_to_user_intent='This aligns with beginners seeking real-world project ideas to develop their data science skills.')]), VerifiableInsight(insight='Using real-world datasets, such as those from New York City Open Data or Kaggle, is crucial for beginners to develop practical data science projects.', references=[Reference(document_id=4518, quote='As far as I know, the ones on Kaggle are like quite well prepared and clean, and everything, so I think if you just get a piece of data that at least resembles real life and then you do your best on top of it that is, you know enough of a project.', timestamp='1:00:50', relevance_to_keyword='Suggests using real-life data, like that from New York City Open Data, for building beginner-level projects irrespective of complexity.', relevance_to_user_intent='Encourages beginners to engage with real-world datasets to gain practical experience.')])] stage_summary='Findings from this stage underscore the importance of practical applications through open-source projects and real-world datasets. Engaging in collaborative projects can enhance the learning experience for data science beginners, while working with datasets from sources like New York City Open Data or Kaggle can provide meaningful, hands-on experiences.' recommended_next_steps='To further enrich this exploration, investigate specific beginner-friendly datasets or project ideas that leverage these insights. Consider community forums or platforms specifically designed for sharing beginner data science projects.' recommended_next_keywords=['beginner data science project datasets', 'real-life data science projects', 'open source data science contributions', 'beginner-friendly data science tools', 'impactful data science projects', 'data analysis using real datasets', 'collaboration in data science projects']\n",
      "\n",
      "\n",
      "response\n",
      "tool-call\n",
      "research_tool {\"stage\":3,\"stage_instructions\":\"Find data science bootcamps that focus on practical experience and offer project-based learning.\"}\n",
      "\n",
      "\n",
      "request\n",
      "tool-return\n",
      "<class '__main__.ResearchStageReport'> stage=3 explored_keywords=[ResearchKeyword(keyword='data science bootcamps practical experience project-based learning', relevant_references=[Reference(document_id=6132, quote='at the code 80 Driven Academy we teach a lot of courses on everything data science', timestamp='3:09', relevance_to_keyword='This mention indicates a practical learning approach through structured courses tailored for hands-on experiences.', relevance_to_user_intent='It highlights the opportunities for immersive learning in data science via courses at the academy.'), Reference(document_id=366, quote='the projects you did at spice what kind of uh like at the end i know that you have some individual projects when you needed to work', timestamp='50:17', relevance_to_keyword='Individual projects at the bootcamp emphasize the importance of applying knowledge to real-world scenarios through hands-on work.', relevance_to_user_intent=\"This aligns with the user's request for bootcamps that encourage practical project-based learning.\"), Reference(document_id=5115, quote='the crisp dam framework... is a nice structured way to structure your project', timestamp='30:28', relevance_to_keyword='Refers to using structured methodologies like CRISP-DM in data science projects, fostering practical applications and project organization.', relevance_to_user_intent='Indicates how curricula may leverage established frameworks to enhance project-based learning.')])] verifiable_insights=[VerifiableInsight(insight='Data science bootcamps such as the Code 80 Driven Academy focus on practical applications and project-based learning, highlighting their success in preparing students for real-world challenges.', references=[Reference(document_id=6132, quote='at the code 80 Driven Academy we teach a lot of courses on everything data science', timestamp='3:09', relevance_to_keyword='This mention indicates a practical learning approach through structured courses tailored for hands-on experiences.', relevance_to_user_intent='It highlights the opportunities for immersive learning in data science via courses at the academy.')]), VerifiableInsight(insight='Individual and collaborative projects within data science bootcamps significantly enhance the learning experience, allowing students to apply theoretical knowledge to practical problems.', references=[Reference(document_id=366, quote='the projects you did at spice what kind of uh like at the end i know that you have some individual projects when you needed to work', timestamp='50:17', relevance_to_keyword='Individual projects at the bootcamp emphasize the importance of applying knowledge to real-world scenarios through hands-on work.', relevance_to_user_intent=\"This aligns with the user's request for bootcamps that encourage practical project-based learning.\")])] stage_summary='The findings indicate that data science bootcamps, particularly the Code 80 Driven Academy, prioritize experiential learning with structured courses and individual projects. The emphasis on frameworks like CRISP-DM further emphasizes the importance of organized methodologies in implementing practical projects, ensuring students not only learn theory but also how to apply it effectively in real-world contexts.' recommended_next_steps='Explore specific courses and methodologies offered by data science bootcamps to identify which focus most heavily on hands-on, project-based learning. Look for student testimonials or detailed curricula that showcase practical projects.' recommended_next_keywords=['top project-based data science bootcamps', 'curriculum for data science bootcamps', 'student experience in data science bootcamps', 'success stories from data science bootcamp graduates', 'data science bootcamp comparisons', 'intensive data science training programs']\n",
      "\n",
      "\n",
      "response\n",
      "text\n",
      "### Summary of Research on Learning Data Science through Practical Projects\n",
      "\n",
      "1. **Resources for Practical Learning**: \n",
      "   - The **Code 80 Driven Academy** offers various courses in data science with a focus on practical applications, including specialized topics like deep learning and unsupervised learning. Structured learning paths are available to enhance hands-on experiences.\n",
      "   - Engaging in **project work** is crucial for applying theoretical knowledge, reinforcing the need for practical projects to solidify skills learned during courses.\n",
      "\n",
      "2. **Project Ideas for Beginners**:\n",
      "   - Beginners are encouraged to take part in **open-source projects** to gain hands-on experience. Involvement in collaborative environments can often lead to innovative insights and provide exposure to real-world data challenges.\n",
      "   - Utilizing datasets from sources like **Kaggle** and **New York City Open Data** is recommended for beginners to engage in meaningful projects that resemble real-world data applications.\n",
      "\n",
      "3. **Bootcamps Focused on Practical Experience**: \n",
      "   - Data science bootcamps, such as the **Code 80 Driven Academy**, promote **project-based learning** where students work on individual and collaborative projects that are crucial for immersing themselves in practical data science applications.\n",
      "   - Curriculum often incorporates structured methodologies like **CRISP-DM**, which helps students organize projects effectively and ensure that they can apply their knowledge to solve real-world problems.\n",
      "\n",
      "### Recommended Next Steps:\n",
      "- Explore specific courses and datasets mentioned to further your practical skills in data science.\n",
      "- Investigate bootcamps that emphasize hands-on projects and see if they align with your learning goals.\n",
      "- Consider joining community forums or platforms where beginners share their projects for guidance and inspiration. \n",
      "\n",
      "### Additional Keywords for Further Exploration:\n",
      "- \"beginner data science project datasets\"\n",
      "- \"real-life data science projects\"\n",
      "- \"project-based learning in data science\"\n",
      "- \"intensive data science training programs\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = NamedCallback(orchestrator)\n",
    "\n",
    "message_history = []\n",
    "\n",
    "while True:\n",
    "    user_input = input('You ', )\n",
    "    if user_input.lower().strip() == 'stop':\n",
    "        break\n",
    "\n",
    "    results = await orchestrator.run(\n",
    "        user_prompt=user_input,\n",
    "        message_history=message_history,\n",
    "        event_stream_handler=callback,\n",
    "    )\n",
    "\n",
    "    new_messages = results.new_messages()\n",
    "    message_history.extend(new_messages)\n",
    "    print_messages(new_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3bd18064",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_reports: List[ResearchStageReport] = []\n",
    "\n",
    "for m in message_history:\n",
    "    for p in m.parts:\n",
    "        if p.part_kind == \"tool-return\" and p.tool_name == \"research_tool\":\n",
    "            if isinstance(p.content, ResearchStageReport):\n",
    "                prior_reports.append(p.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ed91ff07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResearchStageReport(stage=1, explored_keywords=[ResearchKeyword(keyword='practical applications of data science', relevant_references=[Reference(document_id=6132, quote='at the code 80 Driven Academy we teach a lot of courses on everything data science', timestamp='3:09', relevance_to_keyword='This quote provides a context for learning practical data science through structured courses.', relevance_to_user_intent='The mention of the academy indicates opportunities for applying data science practically via courses offered.'), Reference(document_id=6131, quote='I created a deep learning with NLP course or an unsupervised learning course and those are more detailed or more specific topics', timestamp='3:25', relevance_to_keyword='Courses that are specifically designed for certain data science skills show direct pathways to practical applications.', relevance_to_user_intent=\"This aligns with the user's interest in detailed, practical applications in data science.\"), Reference(document_id=4621, quote='just take some time and okay maybe have a project even if so I finish data engineering I do a project', timestamp='28:02', relevance_to_keyword='Encouragement to engage in project work highlights the importance of actual coding and real-world applications.', relevance_to_user_intent=\"This reflects the user's interest in undertaking projects as a form of practical application of their data science skills.\")])], verifiable_insights=[VerifiableInsight(insight='The Code 80 Driven Academy offers a variety of data science courses including specific tracks in deep learning and unsupervised learning, focusing on practical applications and tailored learning paths.', references=[Reference(document_id=6132, quote='at the code 80 Driven Academy we teach a lot of courses on everything data science', timestamp='3:09', relevance_to_keyword='This quote provides a context for learning practical data science through structured courses.', relevance_to_user_intent='The mention of the academy indicates opportunities for applying data science practically via courses offered.')]), VerifiableInsight(insight='Hands-on experience and projects are emphasized as essential for effectively applying skills learned in courses, reinforcing the application of theoretical knowledge in practical scenarios.', references=[Reference(document_id=4621, quote='just take some time and okay maybe have a project even if so I finish data engineering I do a project', timestamp='28:02', relevance_to_keyword='Encouragement to engage in project work highlights the importance of actual coding and real-world applications.', relevance_to_user_intent=\"This reflects the user's interest in undertaking projects as a form of practical application of their data science skills.\")])], stage_summary='Initial findings highlight the availability of practical data science courses at Code 80 Driven Academy, emphasizing specialized tracks that allow learners to delve deeply into topics like deep learning and unsupervised learning. The insights stress the importance of pairing coursework with hands-on projects, which can enhance the applicability of theoretical knowledge in real-world settings.', recommended_next_steps='Explore specific courses or projects mentioned in the findings to pursue practical applications of data science. Additionally, consider looking into how to integrate personal projects with learning to solidify understanding.', recommended_next_keywords=['specific data science courses', 'project-based learning in data science', 'real-world applications of data science', 'hands-on data science projects', 'data science bootcamps', 'mentorship in data science', 'data engineering project ideas']),\n",
       " ResearchStageReport(stage=2, explored_keywords=[ResearchKeyword(keyword='data science beginner project ideas', relevant_references=[Reference(document_id=2670, quote='If you want to look to find a project like you did to take part in an open source project it could be developing a course or maybe contributing to something.', timestamp='26:54', relevance_to_keyword='This quote emphasizes the importance of open source projects as valuable opportunities for beginners to apply their skills in real-world scenarios.', relevance_to_user_intent='This aligns with beginners seeking real-world project ideas to develop their data science skills.'), Reference(document_id=428, quote='As soon as we take off the Inception phase this is where the data science and the data scientists and analyst come together and we brainstorm about the solution.', timestamp='21:17', relevance_to_keyword='Highlights how brainstorming and collaboration can lead to innovative project ideas in data science.', relevance_to_user_intent='This indicates that projects derived from team collaboration can enhance learning experiences for beginners.'), Reference(document_id=4518, quote='As far as I know, the ones on Kaggle are like quite well prepared and clean, and everything, so I think if you just get a piece of data that at least resembles real life and then you do your best on top of it that is, you know enough of a project.', timestamp='1:00:50', relevance_to_keyword='Suggests using real-life data, like that from New York City Open Data, for building beginner-level projects irrespective of complexity.', relevance_to_user_intent='Encourages beginners to engage with real-world datasets to gain practical experience.')])], verifiable_insights=[VerifiableInsight(insight='Engaging in open source projects and collaboration is highly encouraged for beginners looking to gain hands-on experience in data science.', references=[Reference(document_id=2670, quote='If you want to look to find a project like you did to take part in an open source project it could be developing a course or maybe contributing to something.', timestamp='26:54', relevance_to_keyword='This quote emphasizes the importance of open source projects as valuable opportunities for beginners to apply their skills in real-world scenarios.', relevance_to_user_intent='This aligns with beginners seeking real-world project ideas to develop their data science skills.')]), VerifiableInsight(insight='Using real-world datasets, such as those from New York City Open Data or Kaggle, is crucial for beginners to develop practical data science projects.', references=[Reference(document_id=4518, quote='As far as I know, the ones on Kaggle are like quite well prepared and clean, and everything, so I think if you just get a piece of data that at least resembles real life and then you do your best on top of it that is, you know enough of a project.', timestamp='1:00:50', relevance_to_keyword='Suggests using real-life data, like that from New York City Open Data, for building beginner-level projects irrespective of complexity.', relevance_to_user_intent='Encourages beginners to engage with real-world datasets to gain practical experience.')])], stage_summary='Findings from this stage underscore the importance of practical applications through open-source projects and real-world datasets. Engaging in collaborative projects can enhance the learning experience for data science beginners, while working with datasets from sources like New York City Open Data or Kaggle can provide meaningful, hands-on experiences.', recommended_next_steps='To further enrich this exploration, investigate specific beginner-friendly datasets or project ideas that leverage these insights. Consider community forums or platforms specifically designed for sharing beginner data science projects.', recommended_next_keywords=['beginner data science project datasets', 'real-life data science projects', 'open source data science contributions', 'beginner-friendly data science tools', 'impactful data science projects', 'data analysis using real datasets', 'collaboration in data science projects']),\n",
       " ResearchStageReport(stage=3, explored_keywords=[ResearchKeyword(keyword='data science bootcamps practical experience project-based learning', relevant_references=[Reference(document_id=6132, quote='at the code 80 Driven Academy we teach a lot of courses on everything data science', timestamp='3:09', relevance_to_keyword='This mention indicates a practical learning approach through structured courses tailored for hands-on experiences.', relevance_to_user_intent='It highlights the opportunities for immersive learning in data science via courses at the academy.'), Reference(document_id=366, quote='the projects you did at spice what kind of uh like at the end i know that you have some individual projects when you needed to work', timestamp='50:17', relevance_to_keyword='Individual projects at the bootcamp emphasize the importance of applying knowledge to real-world scenarios through hands-on work.', relevance_to_user_intent=\"This aligns with the user's request for bootcamps that encourage practical project-based learning.\"), Reference(document_id=5115, quote='the crisp dam framework... is a nice structured way to structure your project', timestamp='30:28', relevance_to_keyword='Refers to using structured methodologies like CRISP-DM in data science projects, fostering practical applications and project organization.', relevance_to_user_intent='Indicates how curricula may leverage established frameworks to enhance project-based learning.')])], verifiable_insights=[VerifiableInsight(insight='Data science bootcamps such as the Code 80 Driven Academy focus on practical applications and project-based learning, highlighting their success in preparing students for real-world challenges.', references=[Reference(document_id=6132, quote='at the code 80 Driven Academy we teach a lot of courses on everything data science', timestamp='3:09', relevance_to_keyword='This mention indicates a practical learning approach through structured courses tailored for hands-on experiences.', relevance_to_user_intent='It highlights the opportunities for immersive learning in data science via courses at the academy.')]), VerifiableInsight(insight='Individual and collaborative projects within data science bootcamps significantly enhance the learning experience, allowing students to apply theoretical knowledge to practical problems.', references=[Reference(document_id=366, quote='the projects you did at spice what kind of uh like at the end i know that you have some individual projects when you needed to work', timestamp='50:17', relevance_to_keyword='Individual projects at the bootcamp emphasize the importance of applying knowledge to real-world scenarios through hands-on work.', relevance_to_user_intent=\"This aligns with the user's request for bootcamps that encourage practical project-based learning.\")])], stage_summary='The findings indicate that data science bootcamps, particularly the Code 80 Driven Academy, prioritize experiential learning with structured courses and individual projects. The emphasis on frameworks like CRISP-DM further emphasizes the importance of organized methodologies in implementing practical projects, ensuring students not only learn theory but also how to apply it effectively in real-world contexts.', recommended_next_steps='Explore specific courses and methodologies offered by data science bootcamps to identify which focus most heavily on hands-on, project-based learning. Look for student testimonials or detailed curricula that showcase practical projects.', recommended_next_keywords=['top project-based data science bootcamps', 'curriculum for data science bootcamps', 'student experience in data science bootcamps', 'success stories from data science bootcamp graduates', 'data science bootcamp comparisons', 'intensive data science training programs'])]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e805902a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prior_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c268eb27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
